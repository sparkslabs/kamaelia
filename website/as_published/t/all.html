<html><body>

<ul>
<li><a href=#abisource> abisource </a>
<li><a href=#adium> adium </a>
<li><a href=#amp> amp </a>
<li><a href=#aqsis> aqsis </a>
<li><a href=#ardour> ardour </a>
<li><a href=#argouml> argouml </a>
<li><a href=#asf> asf </a>
<li><a href=#bbc> bbc </a>
<li><a href=#beagle> beagle </a>
<li><a href=#blender> blender </a>
<li><a href=#boost> boost </a>
<li><a href=#bzflag> bzflag </a>
<li><a href=#bzr> bzr </a>
<li><a href=#cc> cc </a>
<li><a href=#clam> clam </a>
<li><a href=#codehaus> codehaus </a>
<li><a href=#coppermine> coppermine </a>
<li><a href=#coresystems> coresystems </a>
<li><a href=#crystal> crystal </a>
<li><a href=#cscs> cscs </a>
<li><a href=#daisy> daisy </a>
<li><a href=#debian> debian </a>
<li><a href=#detached> detached </a>
<li><a href=#django> django </a>
<li><a href=#drupal> drupal </a>
<li><a href=#dspace> dspace </a>
<li><a href=#eclipse> eclipse </a>
<li><a href=#eff> eff </a>
<li><a href=#etherboot> etherboot </a>
<li><a href=#exist> exist </a>
<li><a href=#fann> fann </a>
<li><a href=#fedora> fedora </a>
<li><a href=#ffmpeg> ffmpeg </a>
<li><a href=#fityk> fityk </a>
<li><a href=#freebsd> freebsd </a>
<li><a href=#freenet> freenet </a>
<li><a href=#freevo> freevo </a>
<li><a href=#fsijp> fsijp </a>
<li><a href=#gaim> gaim </a>
<li><a href=#gallery> gallery </a>
<li><a href=#gcc> gcc </a>
<li><a href=#geda> geda </a>
<li><a href=#geeklog> geeklog </a>
<li><a href=#genmapp> genmapp </a>
<li><a href=#gentoo> gentoo </a>
<li><a href=#ggi> ggi </a>
<li><a href=#git> git </a>
<li><a href=#gnome> gnome </a>
<li><a href=#gnucash> gnucash </a>
<li><a href=#gnu> gnu </a>
<li><a href=#gnustep> gnustep </a>
<li><a href=#google> google </a>
<li><a href=#haiku> haiku </a>
<li><a href=#handhelds> handhelds </a>
<li><a href=#haskell> haskell </a>
<li><a href=#iem> iem </a>
<li><a href=#ikiwiki> ikiwiki </a>
<li><a href=#inkscape> inkscape </a>
<li><a href=#internet2> internet2 </a>
<li><a href=#jikesrvm> jikesrvm </a>
<li><a href=#joomla> joomla </a>
<li><a href=#k3d> k3d </a>
<li><a href=#kde> kde </a>
<li><a href=#lanka> lanka </a>
<li><a href=#lispnyc> lispnyc </a>
<li><a href=#llvm> llvm </a>
<li><a href=#lurie> lurie </a>
<li><a href=#macports> macports </a>
<li><a href=#maemo> maemo </a>
<li><a href=#metabrainz> metabrainz </a>
<li><a href=#mixxx> mixxx </a>
<li><a href=#moin> moin </a>
<li><a href=#mono> mono </a>
<li><a href=#moodle> moodle </a>
<li><a href=#mozilla> mozilla </a>
<li><a href=#mysql> mysql </a>
<li><a href=#nescent> nescent </a>
<li><a href=#netbsd> netbsd </a>
<li><a href=#neuros> neuros </a>
<li><a href=#nmap> nmap </a>
<li><a href=#ogre> ogre </a>
<li><a href=#olpc> olpc </a>
<li><a href=#ooo> ooo </a>
<li><a href=#openmrs> openmrs </a>
<li><a href=#opensolaris> opensolaris </a>
<li><a href=#osaf> osaf </a>
<li><a href=#oscar> oscar </a>
<li><a href=#osgeo> osgeo </a>
<li><a href=#osuosl> osuosl </a>
<li><a href=#osvdb> osvdb </a>
<li><a href=#p9> p9 </a>
<li><a href=#pano> pano </a>
<li><a href=#parsec> parsec </a>
<li><a href=#php> php </a>
<li><a href=#planetmath> planetmath </a>
<li><a href=#plone> plone </a>
<li><a href=#postgres> postgres </a>
<li><a href=#psf> psf </a>
<li><a href=#psu> psu </a>
<li><a href=#rockbox> rockbox </a>
<li><a href=#ruby> ruby </a>
<li><a href=#samba> samba </a>
<li><a href=#scons> scons </a>
<li><a href=#scribus> scribus </a>
<li><a href=#scummvm> scummvm </a>
<li><a href=#silverstripe> silverstripe </a>
<li><a href=#sipcomm> sipcomm </a>
<li><a href=#smc> smc </a>
<li><a href=#squeak> squeak </a>
<li><a href=#squirrel> squirrel </a>
<li><a href=#stsci> stsci </a>
<li><a href=#svn> svn </a>
<li><a href=#swarm> swarm </a>
<li><a href=#ubuntu> ubuntu </a>
<li><a href=#umit> umit </a>
<li><a href=#videolan> videolan </a>
<li><a href=#vim> vim </a>
<li><a href=#wikimedia> wikimedia </a>
<li><a href=#wine> wine </a>
<li><a href=#winlibre> winlibre </a>
<li><a href=#wordpress> wordpress </a>
<li><a href=#wxpython> wxpython </a>
<li><a href=#wxwidgets> wxwidgets </a>
<li><a href=#xmms2> xmms2 </a>
<li><a href=#xmpp> xmpp </a>
<li><a href=#xorg> xorg </a>
<li><a href=#xwiki> xwiki </a>
<li><a href=#zope> zope </a>
</ul>
<a name='abisource' />
<h2> abisource </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Systematically Breaking and Fixing AbiCollab</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ryan Pavlik</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>J.M. Maurer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The AbiSource project provides a free, fast, powerful word processing application, AbiWord.  A live, real-time collaboration feature, AbiCollab, has been added to the development version, allowing an arbitrary number of users to work together on the same document at the same time.  While keeping all copies of the document in sync is of moderate difficulty when entirely separate parts of a document are edited, edits that are close to each other provide remarkable challenges in synchronization and usability: how do we maintain the integrity of the document for all viewers, yet not surprise any of them with unexpected, if technically &quot;correct,&quot; behavior?  I will systematically explore these corner cases, finding where synchronization is lost and where synchronization results in counter-intuitive behavior.  I will then work to resolve the problems that I find, so that AbiCollab is released with the next major release of AbiWord as a robust, stable addition, in addition to being highly innovative.<br>
In addition to my work on the AbiCollab algorithm, I will also use my knowledge of the Windows platform and my experience building and testing on Win32 to produce a solid Win32 GUI for the AbiCollab feature, which is currently Linux-only (GTK+).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Abiword: OpenXML importer</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Philippe Milot</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kamran Khan</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The cross-platform word processor AbiWord has great interoperability.  The project's website states: &quot;AbiWord is able to read and write all industry standard document types, such as OpenOffice.org documents, Microsoft Word documents, WordPerfect documents, Rich Text Format documents, HTML web pages and many more.&quot;<br>
<br>
However, there is a new format that will eventually become an &quot;industry standard&quot; which AbiWord does not support yet: Microsoft's OpenXML initiative.  This project aims to create a filter plugin that will import a &quot;.docx&quot; OpenXML document by translating it into AbiWord's native data model.<br>
<br>
The project will have two components: an extensible &quot;backend&quot; which does the work of converting &quot;.docx&quot; files, and the actual filter plugin, which will use the backend to integrate the functionality into AbiWord itself.<br>
<br>
Since the backend's design will be as modular as possible, one of the goals is to allow the eventual extension of its capabilities so that it will be able to convert both ways.  Once that is done, an export filter can hopefully be written easily to complete Abiword's compatibility with OpenXML.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>4. Implement annotations</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ernesto Rivera</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Martin Edmund Sevior</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Provide a complete solution to work with annotations in AbiWord.<br>
- Create, edit and remove annotations.<br>
- Create annotations from existing text or from “scratch”.<br>
- Allow AbiWord-generated annotations.<br>
- Allow users to show, hide and print them.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Interface service for the use of external grammar checkers in Abiword</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gabriel Bakiewicz</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Dominic Lachowicz</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Abiword currently offers a grammar checking tool to the user through a plugin that uses link-grammar as back-end. The only available language for checking is English, as supported by link-grammar. Moreover, the checking is slow and the results are not clear to the user, with no further information on the errors detected.<br>
<br>
I would like to enhance this tool by allowing to connect other open source checkers to Abiword. The change will make it possible for users to count on more developed tools, which have features such as explaining the errors found and suggesting a correction. Also, it will allow grammar checking on a higher range of languages, as supported by the different checkers.<br>

	</div>
 </td>
 </tr>
</table>
<a name='adium' />
<h2> adium </h2>
<table>
 <tr>
 <th>Title</th>
 <td>(Un)Lock groups</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andre Cohen</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brian Eric Ganninger</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Project Overview<br>
This project will add a new feature to the way groups are presented. Groups will be able to be unlocked from their vertical arrangement and float freely and locked to either a vertical or horizontal arrangement. In order to keep some sense of order, groups will be able to snap to both other groups and the edges of the screen. This will give users more freedom in the way they arrange all their currently open windows by taking advantage of all the free space on the screen.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Fix &amp; expand AppleScript</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Matthew Joseph Handley</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Peter Hosey</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Adium's AppleScript support is somewhat incomplete and buggy. I will implement a dictionary file that addresses many of the these problems and will provide Adium scripters will plenty of opportunities to expand the application. Hopefully, this will get more Applescripters excited about using Adium.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improving Adium&#39;s XMPP Support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andreas Monitzer</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robert August Fackler</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Since my project last year was scrapped after the fact due to the deprecation and simultaneous breaking of the Java Bridge by Apple, I'd like to re-implement most of the features it had into Adium again, since Adium's XMPP support is still very bare-bone.<br>
<br>
Due to vivid discussions with the Adium and libpurple developers, I've concluded that going with libpurple-based XMPP is the way to go.<br>
I reviewed the Pidgin 2.0 application and found it to have many features that are absent in Adium. These will have to be integrated into the user interface. Further, some missing features are known to be incompatible with Pidgin's philosophy. Sean agreed that we're allowed to add features to XMPP/libpurple, even when they don't benefit Pidgin itself.<br>
<br>
Features that are implemented in Pidgin I'd like to add to Adium are:<br>
* Full MUC support (roles, nick registration, nick change, channel setup, channel subject) -- this will probably require co-operation with whoever will work on the improved groupchat support<br>
* Forms support (required for many features) -- this is going to be complicated due to the nib-centrism of Cocoa<br>
* Console for directly sending stanzas and logging all XMPP communication<br>
<br>
Features that I'd like to implement in libpurple and add to Adium are:<br>
* Gateway support (registration, log on/off)<br>
* PEP (http://www.xmpp.org/extensions/xep-0163.html) -- This will be a bit complicated to implement, since there is no support for this in any server yet. However, there's an experimental patch to ejabberd for it, so maybe I can use that one for testing.<br>
* Based on PEP, implement some protocols that require this, like user tune (http://www.xmpp.org/extensions/xep-0118.html), user avatar (http://www.xmpp.org/extensions/xep-0084.html) and user nickname (http://www.xmpp.org/extensions/xep-0172.html)<br>
* fix OTR-support (http://trac.adiumx.com/ticket/5558)<br>
* http://trac.adiumx.com/ticket/4695<br>
* Discovery Browsing. This will probably need some previously unthought of user interface (the main reason why Pidgin refuses to implement it is the weird interface usually used for it). This would enable MUC channel listings, ad-hoc commands (http://www.xmpp.org/extensions/xep-0050.html), looking up gateways and other nice features.<br>
* Maybe Invisible Command, depending on whether this can be implemented using libpurple (it requires being silent to certain requests).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improved Bonjour Support for Adium</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Erich Kreutzer</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Andrew Wellington</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Adium instant messaging client supports many popular messaging protocols including AIM, Yahoo, Google Talk, and MSN.  Adium currently also supports other protocols including Bonjour, a protocol most widely used by Apple's iChat.  Unfortunately, Adium's current support for Bonjour messaging has numerous bugs and lacks important features.  This project aims to modernize Adium's support for Bonjour.<br>
&nbsp;Adium currently uses the libezv library to support messaging with iChat, however, important bugs such as the inability to send multiline messages and improper reporting of the current users online significantly detract from the usefulness of this library.  Thus, this project will fix these outstanding bugs.  Another function of this project will be to switch libezv to use Apple's well-maintained mDNSResponder.  Supporting file transfer between Adium and iChat over Bonjour is the third major goal of the project.  However, time permitting, the project will lay a groundwork for audio/visual chat using Bonjour.<br>

	</div>
 </td>
 </tr>
</table>
<a name='amp' />
<h2> amp </h2>
<table>
 <tr>
 <th>Title</th>
 <td>CD-Text support for the CDAudio plugin</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Calin Crisan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tony Vroon</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Audacious Media Player has evolved very much in the last few months, thus becoming a good and mature music player. It is the best alternative for XMMS - the most common player in the past 10 years, in Linux. The plugin-based infrastructure allows a great variety of media files to be played. Most of the plugins are fully functionable, while some of them lack certain features, or they are marked as &quot;ugly&quot; because of their code lookalike, their instability or usability. The main goal of this task is to implement suport for CD-Text (see: http://web.ncf.ca/aa571/cdtext.htm for more info) in the existing CDAudio plugin. To achieve this goal, the guidelines found at the previously given link will be used, as well as some code from the K3b project (http://www.k3b.org/).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Rewrite widgetcore as real GTK2 widgets</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Tomasz Moń</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>William Pitcock</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Synopsis<br>
--------<br>
<br>
This project aims to get rid of some leftovers from XMMS and BMP code. I would rewrite the widgetcore as real GTK2 widgets.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Additional NewVFS transports</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Cristian Măgherușan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>William Pitcock</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Project: Audacious Media Player - additional NewVFS transports<br>
<br>
Audacious uses a implementation of a virtual file system (called NewVFS) in order to abstract the file access. NewVFS transports currently enable audacious to play URL's for streaming content (such as http and https).<br>
<br>
In my SoC project I would like to add support for some streaming protocols that audacious is currently missing, including the following URL types:<br>
&nbsp;&nbsp;&nbsp;* lastfm<br>
&nbsp;&nbsp;&nbsp;* mtp<br>
&nbsp;&nbsp;&nbsp;* daap<br>
&nbsp;&nbsp;&nbsp;* ssh<br>
&nbsp;&nbsp;&nbsp;* smb<br>
If the time  allows, I would add support for even more as required by the community.<br>
<br>
Time Schedule:<br>
&nbsp;&nbsp;&nbsp;* In the first 1-2 weeks I'll get familiar with the source code and the devs crew. I'll try to understand how any other free software applications implement these features, and if possible 'steal' some ideas or code samples from them. I hope my my mentor will help me finish this stage as fast as possible<br>
&nbsp;&nbsp;&nbsp;* The next weeks I'll dig into the source and write code to implement the features.<br>
&nbsp;&nbsp;&nbsp;* The following 2 weeks I will do mainly bug-fixing.<br>
<br>
Shall I'll finish faster than the SoC deadline occurs (hopefully), I'll make myself useful by adding other features audacious is lacking, or improve the existing ones. Anyway I intend to remain an active developer afterwards since audacious is my main music player, and I'll like to make it become better.<br>

	</div>
 </td>
 </tr>
</table>
<a name='aqsis' />
<h2> aqsis </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Multi-threaded Implementation</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Manuel Antonio Fernandez Montecelo</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tristan Colgate</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 With the advent of multi-core computers even for basic desktops, parallelizing an application which needs huge amounts of CPU power can bring big performance benefits.  Using threads in applications to listen for incoming data (e.g. via sockets) has the benefits of not blocking the rest of application or not having to poll in a loop; but with N CPUs/cores an application with huge CPU usage can run up to N times faster (using a fraction 1/N of the time compared with single-threaded implementation) in the critical parts -- provided that is highly parallelizable, of course.<br>
<br>
One of the big problems of using threads is the different implementation of them in the different platforms.  However, this can be circumvented with the use of Boost.Threads (or maybe alternatives such as OpenThreads).<br>
<br>
This project aims to implement core parts (especially the rendering stages) in a multithreaded way, so the application can benefit from powerful hardware in a platform-independent and reliable way.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Deep Shadow Maps implementation for the rendering of coloured shadows and hair/fur shadows</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Zachary Carter</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Christopher James Foster</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to implement the deep shadow mapping algorithm as described by Lokovic and Veach [http://graphics.stanford.edu/papers/deepshadows/deepshad.pdf] as a new feature for the Aqsis renderer. This algorithm, like traditional shadow maps, stores a rectangular grid of pixels, but unlike standard shadow maps, the data stored at each pixel is a visibility function, rather than a depth value, representing the fraction of initial light energy that reaches a point at arbitrary depth. This is like having an alpha channel available as your shadow map at every z-depth, giving you semi-traasparent shadows and colored shadows without raytracing. Since these alpha maps themselves are not stored, only the functions used to compute them, storage for this algorithm is very low, but sampling can still be parallelized.<br>
I will correspond with students implementing multi-threaded functionality of the core REYES renderer so that shadow mapping is ready for threaded execution upon release.<br>

	</div>
 </td>
 </tr>
</table>
<a name='ardour' />
<h2> ardour </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Piano-Roll MIDI Editing Interface</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>David Edward Robillard</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Paul Davis</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Last year's SoC saw Ardour gain the ability to record MIDI data in addition to audio.  While the underlying functionality is there, in order to be competitive with professional sequencers a nice GUI interface for editing MIDI data is needed (and highly requested by Ardour users and the Linux audio community in general).<br>
<br>
This project includes the implementation of a piano-roll style MIDI note editing interface in Ardour, and the ability to send control messages (MIDI CC and NRPN) with an interface similar to the existing one for automation.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>n.m panning</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christian James Muise</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jesse Chappell</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 n.m panning<br>
<br>
Name: Christian Muise<br>
Email: christian (dot) muise (at) gmail (dot) com<br>
Site: http://www.haz.ca/<br>
<br>
## Proposal ##<br>
&nbsp;Panning a mono sound source to an arbitrary speaker setup, such as 5.1, is required by any studio level audio recording software. A properly written panner for Ardour to any of the standard home theatre setups would be a huge asset to the software.<br>
<br>
&nbsp;Having this capability would allow users of Ardour to mix sound for Dvd videos or even DVD-Audio mixdowns. Providing this feature to the Ardour user base is something that would take Ardour to a new level.<br>
<br>
<br>
## Why Me? ##<br>
&nbsp;The task of gearing an audio application to spacial panning is one that requires a great deal of mathematics and programming knowledge. This is primarily why I'd be perfect for this project. I have a strong mathematical background through the courses taken in University, and programming for audio is a huge interest of mine that I've not been able to tap into as of yet.<br>
<br>
&nbsp;I am currently a student in a Sonic Design program at Carleton University. Because I have a strong background in music and audio recording combined with my primary major in Computer Science, I would fit quite nicely with the Ardour team. I have used Ardour with Agnula quite a bit in the past, and I am currently shifting my home studio setup to use that OS with Ardour exclusively.<br>
<br>
<br>
## Why You? ##<br>
&nbsp;Having a hand in creating the software I will be using would be the best area for me to work in. I want to solidify a place in the open source community where I could be the most helpful and interested, and Ardour would be one of the best projects providing this.<br>
<br>
<br>
## Purchases ##<br>
&nbsp;For this project, the initial funding would be used to up my current setup from 2.0 to 5.1. This would simply involve purchasing new speakers for the Delta 1010 Soundcard currently being used. I feel that it is reasonable for the student to input some of the funding for the gear needed to complete the project.<br>
<br>
<br>
## Milestones ##<br>
May 28th: Project plan figured out, and code base reviewed.<br>
May 31st: 5.1 speaker setup purchased/placed<br>
June 21st: Mathematical research complete for panning<br>
July 9th: First draft of code for 5.1 complete<br>
July 17th: Mathematical code optimized for real-time<br>
Aug 2nd: Second draft of code complete for arbitrary speaker setups<br>
Aug 20th: Final implementation ready to be released<br>
<br>
<br>
## Bio ##<br>
&nbsp;I am currently finishing my 5th and final year of a Computer Science degree with a Minor in Math at Carleton University, Ottawa. I hold a leadership role in the Robotics Club, Game Dev Audio Group, ACM Contest Teams, and the student society for Computer Science. I have interests ranging from AI to audio to robotics, and spend most of my spare time trying to find slick ways of combining all of them into a single project.<br>
<br>
&nbsp;I was a successful applicant of Google's Summer of Code in both 2005 and 2006. While I have adopted a fair amount of Open Source solutions over the last few years, I have not yet had the opportunity to become part of a development community for which I would be well suited. This is my goal for Summer of Code, 2007. More info can be found on my website.<br>

	</div>
 </td>
 </tr>
</table>
<a name='argouml' />
<h2> argouml </h2>
<table>
 <tr>
 <th>Title</th>
 <td>UML2 for ArgoUML</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Pistol Constandache Bogdan Ciprian</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tom Morris</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Eclipse UML2 for ArgoUML<br>
<br>
Project Goals<br>
The goal of my project is to advance ArgoUML model subsystem to UML2.1.1 with the Eclipse UML2 project.<br>
<br>
Details<br>
The hole UML2 is too big for 3 months of summer, so I propose a subset of UML2. The main interfaces from argouml-core-model (ModelImplementation, ModelManagement and others that are required). Then I would choose an incremental approach on language units: Classes, Use Cases.<br>
Eclipse UML2 is suited for both Eclipse plugins such as ArgoEclipse and for standalone applications such as ArgoUML. I tested it by building a small standalone application in Java that uses Eclipse UML2. You can find details here: http://argouml.tigris.org/servlets/ReadMsg?list=dev&amp;msgNo=20781<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Extending ArgoUML to support UML Profiles</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Marcos Aurélio Almeida da Silva</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Linus Tolke</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 UML is a de facto standard in commercial software modeling. The language provides a rich set of constructors which enable the specification of systems ranging from simple information systems to sophisticated multi-threaded ones. Despite of the fact of being mainly target to specifying software systems the language also provides means to be adapted to other domains, as multi-agent systems, tests, and many others. This project aims to extend ArgoUML in order to support UML profiles, the proposed features include (but are not limited to): definition, application and management of profiles.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Sequence Diagrams improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christian López Espínola</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robert James Tarling</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The sequence diagrams subsystem in ArgoUML are in need of some work. It was coded a long time ago, and now it isn't consistent with the rest of the ArgoUML code. I want to refactor this decreasing the maintenance cost of the subsystem in the future.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>ArgoPDF – The PDF report generation tool.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Dmitry Churbanov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ion Savin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 During the development programmers need to have a report of the architecture of the future application. This report can also be useful for future development and not only for programmers.<br>
&nbsp;<br>
At this moment ArgoUML do not have the possibility to generate full-scale report of the designed architecture. ArgoPDF as a part of ArgoUML will make it easy to generate report as pdf file.<br>
While making a report, you will be able to compose title page by specifying different parameters.<br>
You will be able to choose the diagrams to include in the report.<br>
Setting up parameters will be easy through an intuitive graphical user interface.<br>
<br>
ArgoPDF will be implemented in Java using a free powerful java library for generation pdf files - iText (http://www.lowagie.com/iText/).<br>
<br>
ArgoPDF will be a part of already existed ArgoPrint subproject.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Alternative GUI layer in GEF library for ArgoUML project</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jian Zheng</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robert James Tarling</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The GEF project is developed to provide a graph editing library for other graph applications, e.g. ArgoUML. It contains several diagram elements and enables the users to interact with them for moving, resizing, reshaping, dragging and dropping, etc.<br>
<br>
The GEF project is based on swing and java2d libraries. This GSoC project aims to abstract away the Swing/Java2D functionalities in the GEF project into a separated package and provide an alternative GUI alyer.<br>

	</div>
 </td>
 </tr>
</table>
<a name='asf' />
<h2> asf </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Canonical XML Implementation on Apache AXIOM</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Saliya Ekanayake</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ruchith Fernando</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Apache Axis2 uses Axiom as its underlying object model which provides an efficient yet less memory-intensive object model. The current implementations of Canonical XML and Exclusive XML Canonicalization specifications of The Apache XML Project use DOM underneath. These implementations are used in Axis2 in providing WS-Security with great hassle due to the expensive conversion between DOM and Axiom.<br>
<br>
The intention of this project is to eliminate such conversion and to improve the efficiency for relying parties of XML canonicalization by implementing both specifications based on Axiom. Eventually it would provide a vital improvement to Axis2 as its WS-Security implementation heavily depends on XML canonicalization.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implementing Mail Transport (SMTP/POP3) support for SOAP 1.2 for Axis2/C</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Rajika Kumarasiri</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Saminda Wishwajith Abeyruwan</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This is an attempt to implement Mail Transport (SMTP/POP3) support for Apache Axis2/C. Currently Axis2/C has the HTTP transport as the general transport.<br>
<br>
At the end of the project Axis2/C will have the mail transport support in addition to the HTTP transport. The project is going to be done keeping extensibility in mind so that the other protocols(ex.IMAP4) can be plugged.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Unified expression handling and unified object model in Apache Cocoon</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Grzegorz Kossakowski</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Fagerstrom</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 As for any other web application framework, one of Cocoon's core functionality is expression handling. Simple yet powerful expression languages (ELs) enable developers creating Cocoon applications query for data they need in clean manner. Even though several ELs are already present in Cocoon their use is now incoherent and they operate on inconsistent Object Model (OM, discussed below). This is a serious obstacle for novice users and makes Cocoon applications more difficult to maintain. In order to address these issues I propose to:<br>
&nbsp;&nbsp;* revise EL handling implemented in Cocoon's template block and find out if improvements are needed<br>
&nbsp;&nbsp;* get rid of Avalon dependencies in EL and OM handling code<br>
&nbsp;&nbsp;* provide consistent, complete object model for expressions everywhere they are used<br>
&nbsp;&nbsp;* implement converter concept and provide basic converters' implementations<br>
&nbsp;&nbsp;* refactor at least portion of Cocoon samples so they use new ELs implementation<br>
&nbsp;&nbsp;* document new architecture, create migration guides and promote the use of new implementation across the community<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Streaming LOB support (for OpenJPA)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ignacio Andreu Dolset</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Patrick Linskey</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 OpenJPA is a 100% open-source implementation of the Java Persistence API (JPA), which is the persistence component for EJB in the Java EE 5 specification (part of JSR-220).<br>
<br>
JPA combines the best ideas of other persintence technology, such as Hibernate, JDO and TopLink<br>
&nbsp;<br>
The fields BLOB and CLOB of sql are translated for the Java programmer in the java.io.InputStream (for BLOBs) and java.io.Reader (for CLOBs) types, the objective of this project is to provide a serialization in database of these objects in a natural way.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Maven Diagram-Maker</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Piotr Tabor</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jason van Zyl</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My proposition is to create a software system that will allow,<br>
during the build process of a project, to automatically generate<br>
diagrams of chosen aspects of the project. I would like to provide two<br>
components: a graphical editor and a Maven plug-in.<br>
<br>
&quot;The Graphical Editor will offer live (WYSIWYG) preparation of a<br>
graphical presentation of the project by setting such properties as:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Type and subset of data, we want to present,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- What part of the data is to be presented,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- The method of presenting of each type of diagram nodes (that is,<br>
what attributes of the item will be displayed), and the general &quot;style&quot;<br>
of the presentation. I would like to provide UML-like design.<br>
&nbsp;&nbsp;&nbsp;&nbsp;- The general layout algorithm<br>
&nbsp;&nbsp;&nbsp;&nbsp;- The positions of selected locked nodes – which we want to put in a<br>
fixed area. All other nodes will be positioned automatically.<br>
The schema of the diagram created by the editor will be saved to an XML<br>
file.<br>
Additionally the editor may be used as a graphical browser (explorer) of<br>
chosen aspects of the project. The editor will use the Prefuse library<br>
(http://prefuse.org).<br>
<br>
The Maven Plug-in (maven-graph-plugin) – will be using the XML file<br>
prepared by the Graphical Editor and the current state of project to<br>
prepare images in various graphic formats (JPG, TIFF, PNG and others<br>
supported by the Sun JIMI library). The plug-in will be able to prepare<br>
the HTML &lt;map&gt; tag for the picture too (to create an active area on web<br>
page containing the image). The resulting file will be ready  to use in<br>
the next Maven phases by Doxia or other documenting tool.<br>
<br>
The maven-graph-plugin will cope with changes in the project made after<br>
generating the schema XML file.  This means that if an object from the<br>
XML file is no longer exists in the project, it won't be visible in the<br>
picture. It also means that if the object is new, it will be placed in<br>
the picture (in a place calculated by the general layout strategy set in<br>
the XML file).<br>
Additionally the user will be warned about any discrepancies between the<br>
expected and actual data and problems with finding space for a new<br>
object. The diagram generation will not modify the XML file, but will<br>
only try to interpret it for the current situation.<br>
<br>
During Google Summer of Code time I wish I prepare two connectors<br>
(possibilities to visualize an aspect of project):<br>
&nbsp;&nbsp;&nbsp;&nbsp;- Dependencies diagram connector – to visualize the chosen project's<br>
subset of the dependencies (internal or external, up to a configured<br>
depth or/and included in a given scope). It will be also possible to<br>
exclude some dependencies from the diagram.<br>
&nbsp;&nbsp;&nbsp;&nbsp;- Class diagram – to visualize the inheritance and composition<br>
aspects of the class hierarchy. The information will be obtained by<br>
reflection.<br>
<br>
Of course the mechanism of the connectors will be universal enough to<br>
make the addition of a new aspect of a project as simple as possible.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implementing “Dobly” Noise Reduction for SpamAssassin</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jianyong Dai</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Parker</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 * Project Description<br>
&nbsp;&nbsp;&nbsp;&nbsp;Bayesian filtering is a powerful machine learning tool frequently used in spam detection. However, unintentional or intentional noise could circumvent Bayesian filter (http://bnr.nuclearelephant.com). In unintentional case, it is normal that some common words appear in both spam and legitimate email, which makes spam emails look somewhat similar to legitimate emails. Furthermore, spam mail writer could intentionally inject some words which only appear in legitimate emails. In that, Bayesian filter will be deceived and misclassify a spam as a legitimate email.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Dobly Bayesian Noise Reduction (BNR) is a preprocessing step to eliminate these noises from email before presenting them to Bayesian filter. The basic idea of BNR is to remove words which are not informative in Bayesian filter and words not consistent with its context. Result shows that BNR will increase the accuracy of Bayesian filter by a wide margin.<br>
&nbsp;&nbsp;&nbsp;&nbsp;BNR is a feature of DSPAM system (http://dspam.nuclearelephant.com) and there is a reference implementation of BNR alone (http://bnr.nuclearelephant.com).<br>
&nbsp;&nbsp;&nbsp;&nbsp;The goal of the project is to add BNR into SpamAssassin in a proper way.<br>
<br>
<br>
* Benefit to SpamAssassin Community<br>
&nbsp;&nbsp;&nbsp;&nbsp;Increase the accuracy of Bayesian filter with affordable performance penalty and minimal administrative overhead<br>
<br>
<br>
* Deliverables<br>
&nbsp;&nbsp;&nbsp;&nbsp;Perl module for BNR, integration with existing Bayesian filter and learner, sql script for new data structure, documents for new configuration entries, performance document, etc<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Enhancing Batik&#39;s document viewer</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ivan Andjelkovic</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Cameron McCormack</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Batik's browser application has only the basic support for inspecting a document, through the DOM Viewer component.<br>
<br>
In my application I propose the possible ways of enhancing Batik's document inspector.<br>
This can be achieved by not only browsing the DOM tree, but also allowing the editing of the document through the DOM Viewer. Therefore, following options should be implemented:<br>
1. The user – requested option which would update the state of the DOM Viewer from the content of the document,<br>
2. The options for adding new elements and attributes, and editing the listed ones.<br>
<br>
The key is to use intuitive GUI interface and write a set of methods to support the manipulation of the document throught the GUI.<br>
<br>
The user should be able to add new nodes to the Viewer's tree, add new attributes in the attribute list or edit the value of the existing ones and see the changes on the canvas. After performing any of the changes, the document referred by a Viewer has to be refreshed.<br>
<br>
The final goal here is to enhance document manipulation through the DOM Viewer component, so the user can easily browse and edit the content of the document.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>The Persistent Database Connection Plugin</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Zhang Shunchang</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Parker</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Just as the bug reporter said: In the spamassassin system(http://spamassassin.apache.org/), every spamd instance (fork) requires a new connection to be created to the SQL server, then a query happens, and then the session is disconnected.  This is quite unnecessary and inefficient. Spamd should actually connect on startup, disconnect on shutdown, and just do queries through that open connection. So we need a persistent database connection plugin.<br>
Fortunately, Michael Parker have fixed the bug by adding a plugin<br>
(http://wiki.apache.org/spamassassin/DBIPlugin) that handles persistent database connection.<br>
However, due to the licensing problem(DBI,Apache::DBI is under GPL,http://www.gnu.org/copyleft/gpl.html), this plugin cannot be made into the main SpamAssassin codebase. we need an implementation under ASL(http://www.apache.org/licenses/).<br>
<br>
Main purpose:<br>
1.keep a persistent database connection<br>
2.implement the plugin under ASL<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Adding Functionality and Usability Improvements to Chainsaw</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Isuru Eranga Suriarachchi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Paul Smith</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Chainsaw is included in Apache/Log4j. It is a GUI based log viewer which is developed to load log events mainly through the 'Receiver' concept. Via these receivers, Chainsaw can load events generated by various frameworks like log4j, log4net, log4perl, log4cxx and java.util.logging. Other than that, Chainsaw can load log events using XML-formatted log files. Using both these mechanisms, Chainsaw can cater various applications. It's GUI features support a lot when it comes to debugging huge applications.<br>
<br>
Currently Chainsaw is lacking some important features which can improve the usability of the tool in a great deal. Tailing capability in the VFS log viewer is one of the major improvements that should be done. There are some other features to implement in areas like receiver creation panel, remembering filter and search expressions between Chainsaw restarts and memory usage as well. And also there will be more ideas arising as this project go on.<br>
<br>
This project would be an attempt to implement the required features in Chainsaw after some research to understand the best ways of improving the efficiency. This will improve the usability of the tool in a great deal.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>MyFaces Component Set Integration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Leonardo Alfredo Uribe Panesso</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Martin Marinschek</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The objective of this project is to improve the integration of the available components in MyFaces, being incorporated the capacity to define skins or styles for define a look n feel of the components in a web page, making a wiki tutorial about using tiles for layout MyFaces components, and solving some previously raised topics in jira of MyFaces that contribute to improve integration between different components available in MyFaces.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>MyFaces Component Generator</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bernhard Huemer</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Werner Punz</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The JSF APIs are quite powerful from a component developer's perspective, but as in the majority of cases the flexibility you need for full-fledged enterprise web applications implicates complexity in the daily usage. Ruby on Rails demonstrates that it is more advisable to favor convention over configuration, as this is exactly the principle why Ruby on Rails gained its popularity. Therefore JSF component developers should not have to mess around with writing boilerplate code, but rather modify and complement it where appropriate.<br>
<br>
Currently, if you want to implement a custom JSF UI component, the following three steps are required:<br>
- Create a Java class which inherits UIComponentBase either directly or indirectly. This UIComponent class contains the actual Java code representing the logic of the component. It accomplishes rendering either on its own or by using a seperate renderer.<br>
- Register the UI Component by adding the appropriate configuration entries in faces-config.xml. These entries are used both to initialize the JSF application and to provide the possibility for tool vendors to display custom components on a component palette.<br>
- Integrate your component with the desired view technology (i.e. JSP). This involves writing tag libraries and tag library descriptor files.<br>
<br>
The problem arises from the fact that you have to keep these three steps align with each other, but that's an annoying and time-consuming task (for example, it can be quite cumbersome to propagate changes appropriately). In the face of these difficulties it seems to be rather conventient to generate components and taglibs using an existing faces-config.xml. This principle is nothing new as similiar projects (for example, maven-faces-plugin and myfaces-build-tools) are already available, but none of these projects are feature-rich enough.<br>
<br>
The MyFaces Component Generator improves the ease of component development by using an approved method – convention over configuration. It generates components with default, meaningful behaviour, but of course only if you desire to, as you're still able to use custom templates to alter the generated outcome.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Design and implementation a better document inspector</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jasleen Singh</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Cameron McCormack</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 There is lack of a good SVG explorer on the Windows platform. Batik's browser application, Squiggle, allows a user to view and apply only limited transformations to a single document at a time. Also, error handling and document inspection is quite basic. This project will use the existing code base to implement a full-fledged explorer-like application which allows, in addition to existing features, directory navigation, multiple views (thumbnail, film-strip etc.), undo/redo, simple directory search and generally a better user interface than what we have today. The proposed browser will also have support for making changes to the DOM tree and viewing animated SVG files.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Convert Derby tests to JUnit and fix Derby bugs</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ravinder Reddy Pandiri</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Samuel Andrew McIntyre</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In computer programming, unit testing is a procedure used to validate that individual units of source code are working properly.<br>
&nbsp;A unit is the smallest testable part of an application. In procedural programming a unit may be an individual program, function, procedure, web page, menu etc, while in object-oriented programming, the smallest unit  is always a Class; which may be a base/super class, abstract class or derived/child class.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Units are distinguished from modules in that modules are typically made up of units.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;The goal of unit testing is to isolate each part of the program and show that the individual parts are correct. A unit test provides a strict, written contract that the piece of code must satisfy. As a result, it affords several benefits.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Unit testing allows the programmer to refactor code at a later date, and make sure the module still works correctly (i.e. regression testing). The procedure is to write test cases for all functions and methods so that whenever a change causes a fault, it can be quickly identified and fixed.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Readily-available unit tests make it easy for the programmer to check whether a piece of code is still working properly. Good unit test design produces test cases that cover all paths through the unit with attention paid to loop conditions.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Unit testing helps to eliminate uncertainty in the units themselves and can be used in a bottom-up testing style approach. By testing the parts of a program first and then testing the sum of its parts, integration testing becomes much easier.<br>
Unit Testing provides a sort of &quot;living document&quot;. Clients and other developers looking to learn how to use the module can look at the unit tests to determine how to use the module to fit their needs and gain a basic understanding of the API.<br>
<br>
<br>
Limitations:<br>
-----------<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unit testing will not catch every error in the program. By definition, it only tests the functionality of the units themselves. Therefore, it will not catch integration errors, performance problems or any other system-wide issues. In addition, it may not be easy to anticipate all special cases of input the program unit under study may receive in reality. Unit testing is only effective if it is used in conjunction with other software testing activities.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;JUnit is a unit testing framework for the Java programming language.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In this project I am going to Convert Derby tests to JUnit and fix bugs in Derby.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>jackrabbit-jcr-demo: μAssessment (muAssessment) Testing System</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Pavel Konnikov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jukka Zitting</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 An application programmer who is not familiar with JCR API but plans to use Jackrabit  should have an example of JCR API and Jackrabit usage. Therefore it is necessary to build up a proper application to put on a demonstration of JCR API features.<br>
<br>
Demo application requirements:<br>
<br>
- should illustrate JCR API features in full measure<br>
- should illustrate JCR API features complete<br>
- should deal with some non-trivial JCR API use cases along with general ones<br>
- shouldn’t use any extra frameworks (ex. Struts, Hibernate, etc.) in order to pay attention to JCR API features and not to eliminate people who are not familiar with frameworks in question at initial point; therefore the application must be built up with JSP + Servlets + Design patterns<br>
- as a basis for repository realization it is possible to chose both DB and XML-catalog<br>
- shouldn’t to be too large, that is to say that the application shouldn’t be overloaded with architectural components<br>
- any beginner should gain an understanding of demo application knowledge domain<br>
- it is necessary to assure that the application should deploy both on Tomcat and on some AS (Apache Geronimo is preferable)<br>
<br>
As a case in point the online-test system μAssessment (muAssessment) is suggested.<br>
<br>
Please visit http://www.konnikov.net/GSoC/2007/ for further information.<br>

	</div>
 </td>
 </tr>
</table>
<a name='bbc' />
<h2> bbc </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Motion estimation and mode decision in Dirac</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andrew Lewis</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Andrea Gabriellini</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Motion estimation and mode decision incur a large proportion of the<br>
costs in compressing video. I propose a project to utilise more<br>
efficient algorithms for these features in the Dirac reference encoder.<br>
The focus will be on selection of an algorithm/algorithms which provide<br>
excellent performance whilst being conducive to lower-level optimization<br>
in the Schroedinger implementation of Dirac by use of the liboil library.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>A file handle like interface to backgrounded Kamaelia components</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Patrick Thomson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Philip Sparks</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project will give an interface to kamaelia components which can be operated on in a similar way to file I/O, to enable easy kamaelia integration into non-kamaelia-component oriented systems.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>AIM/IRC client for Kamaelia</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jinna Lei</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Matt Hammond</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 [Taken from 'Synopsis' of the Detailed Description]<br>
This project has three parts. Part I is to implement support for the TOC protocol in Kamaelia and to extend the existing IRC capabilities.<br>
Part II is to bridge the AIM and IRC protocols, and create a client that deals with both of them uniformly.  The client should (a) be easy to extend to other protocols. (b) be a standalone client and be integrable with Kamaelia’s other components, and (c) present a single interface for messaging across all protocols supported. An AIM user Jane messaging an IRC user Bob should not have to be aware (after the initial setup) that Bob is using a different protocol. All Jane should know is that she is sending messages and receiving messages back.<br>

	</div>
 </td>
 </tr>
</table>
<a name='beagle' />
<h2> beagle </h2>
<table>
 <tr>
 <th>Title</th>
 <td>A Xesam-based D-Bus interface and some TextCache improvements for Beagle</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Arun Raghavan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Joe Shaw</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently, Beagle uses an XML-based interface over Unix sockets for it's communication. Specifically, clients talk to the Beagle daemon (beagled) with messages to (a) index data, and (b) perform queries using this interface. This project aims to use the search interface defined in the Xesam [1] specification over the D-Bus [2] message bus system.<br>
<br>
[1] http://wiki.freedesktop.org/wiki/XesamAbout<br>
[2] http://www.freedesktop.org/wiki/Software/dbus<br>
<br>
The advantage of such a system is that if each desktop search application, such as Beagle [3] or Tracker [4] supports this interface, then client applications do not need to write code to support each search backend that it wishes to support.<br>
<br>
[3] http://beagle-project.org/<br>
[4] http://www.gnome.org/projects/tracker/index.html<br>
<br>
Additionally, it is also desirable to see if such an interface would provide performance benefits over the current XML-over-Unix interface, in which case it could also serve as a replacement to the existing system.<br>
<br>
Besides this, the project also includes improvements to the TextCache system (used to store partial text from documents for generating &quot;snippets&quot;), particularly with respect to the amount of disk space used.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Thunderbird backend rewrite</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Pierre Östlund</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Debajyoti Bera</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The objective is to rewrite the Thunderbird backend to make it more efficient in every way possible. Straightening out various bugs will also be of highest priority. To make the integration between beagle and Thunderbird more apparent, an extension will be written for Thunderbird so beagle-search can open emails and contacts directly in Thunderbird.<br>

	</div>
 </td>
 </tr>
</table>
<a name='blender' />
<h2> blender </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Proposal to implement deep shadow maps and a tiling disk cache in Blender.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Joseph Eagar</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Martin Poirier</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This proposal is to implement deep shadow maps, including mipmapping, motion blur, colored shadows and filtering, in Blender.  Also, a generic disk cache mechanism will be implemented.<br>
<br>
Deep shadow maps are an advanced technique to make high-quality shadows. They work by storing additional samples and transparency info inside of the shadows, allowing for advanced techniques such as mipmapping and motion blur to be applied to shadow maps.<br>
<br>
Since deep shadow maps take a great deal of memory, a generic tiling disk cache will also be implemented.  This system will simply swap shadow map tiles to disk as needed to keep RAM consumption below a user-defined limit.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Blender audio system cleanup and upgrade</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Csaba Hruska</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robert C. Holcomb Jr.</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The main purpose is to remove every other sound code references from lender source than SoundSystem library.<br>
The other task is removing unneccessary dependencies (fmod, openal) from SoundSystem code with keeping API unchanged.<br>
The only used library is SDL, because it`s good multiplatform support. Openal will be replaced with verse project`s audio system code (code is available in verse blender source).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>A GLSL Shader Editing and Preview System for Blender</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>José Miguel da Silva Torres Lima</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brecht Van Lommel</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Blender is a powerful Free Software application for 3D modelling, animation, rendering, post-production, interactive creation and playback.<br>
<br>
The aplication features many unique and expressive tools for 3D artists like the node-based material editor and compositor, integrated multi-resolution sculpting tools, multi-layer UV mapping and render baking and integrated video sequencing.<br>
<br>
This project's goals are: to implement support for improving Blender's current material display in the 3D View window, using GLSL programmable hardware shaders; extend Blender's 3D View real-time material preview to support node-based materials by implementing a system to combine shader fragments that represent each node of the graph at real-time and, from those fragments, generate GLSL shaders; create a GLSL shaders representation for Blender's material nodes.<br>
<br>
Further objectives, if the remaining time allows are: to create a generic GLSL shader node, allowing users to create their own shader in Blender's Text Editor window; to allow to import/export GLSL code for a material node network and to integrate it with Blender's scripting system and the forthcoming PyNodes API.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Mesh bevel and offset tools/modifiers</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Levi Schooley</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Geoffrey Bantle</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Tools to create beveled edges are very important in technical modelling and rendering. However, it is also important that the artist have as much control over the process as possible. During modelling, the artist should be able to bevel selected faces/edges/vertices, choose the appropriate beveling method, and accurately set and view the final result in real-time. Also, a mesh-wide technique for producing a beveled result would be very helpful, mainly for rendering. This would be best implemented as a modifier with options to bevel based on edge crease values, vertex weights, and percentages (based on face joining angles and face area sizes).<br>
<br>
In addition, based on the fact that there is a shared interest and perhaps even similar algorithms, the creation of a parallel offset tool would be a great benefit to technical modelling. A parallel offset tool increases or decreases the area/volume of a mesh while attempting to keep the points on the resulting surface as equidistant as possible to the original surface.<br>

	</div>
 </td>
 </tr>
</table>
<a name='boost' />
<h2> boost </h2>
<table>
 <tr>
 <th>Title</th>
 <td>User-friendly graphs and their measures</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andrew Sutton</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jeremy Siek</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This proposal discusses two additions to the Boost Graph library: the implementation of user-friendly, general purpose classes for simple directed and undirected graphs, and the implementaiton of several graph measures.  Specifically, the graph classes are provided to improve the usability of Boost.Graph by providing implementations of common cases (hence lowering the entry barrier). The development of different graph measures can provide statistical insight into the structure of arbitrary graphs. These statistics may be used to help choose, at runtime, more efficient algorithms depending the traits of those graphs.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>FastCGI and SCGI-compatible CGI library</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Darren Garvey</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Christopher M Kohlhoff</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This proposal is for an extensible CGI library for C++. Despite C++ being historically regarded as somewhat 'overkill' for CGI programming, the language can in fact provide efficient, elegant and flexible solutions to many problems in the web application domain. With CGI programming unwaveringly popular and the scale and complexity of web programs ever increasing, there is a distinct need for a library to aid developing these programs using C++.<br>
<br>
Furthermore, alternative implementations of CGI, such as FastCGI and SCGI – which significantly aid writing scalable CGI programs – have very poor support in C++, something the proposed library aims to remedy. The Boost libraries (esp. Boost.Asio) are fundamental to this library's design as it exists now (essentially as an incomplete FastCGI library).<br>
<br>
The scope of the library is intentionally limited to CGI-specific functionality in order to avoid controversy (for instance, no html output formatting such as in perl's CGI.pm). It is also intended to be protocol-independent. That is, to allow a program to be written as a CGI program and for it to be allowed to run as a FastCGI program, for example, with only trivial alterations.<br>
<br>
Take the following 'Hello world' example:<br>
<br>
int main()<br>
{<br>
&nbsp;&nbsp;cgi::request req; // initialise the environment, as one would expect<br>
&nbsp;&nbsp;req.header(&quot;Content-type: text/plain&quot;);<br>
&nbsp;&nbsp;req&lt;&lt; &quot;Hello, world&quot;;<br>
&nbsp;&nbsp;return 0;<br>
}<br>
<br>
The above is a complete CGI program. The proposed library will ship with FastCGI and (possibly) SCGI drivers - provisionally called 'services' - as well as a standard CGI service. The following is a complete FastCGI program, which will handle multiple requests synchronously (ie. removing process startup/shutdown costs):<br>
<br>
int main()<br>
{ // Note: syntax is not final<br>
&nbsp;&nbsp;cgi::fcgi_service service;<br>
<br>
&nbsp;&nbsp;cgi::request req(service); // this works just like a standard cgi request object<br>
&nbsp;&nbsp;while( req.accept() ) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;req.header(&quot;Content-type: text/plain&quot;);<br>
&nbsp;&nbsp;&nbsp;&nbsp;req&lt;&lt; &quot;Hello, world&quot;;<br>
&nbsp;&nbsp;}<br>
&nbsp;&nbsp;return 0;<br>
}<br>
<br>
The above follows the style of the FastCGI reference library, although more responsive and realistic variations of the above are planned (and partly implemented already). These variations will aim to take full advantage of modern C++ techniques.<br>
<br>
More information can be found at http://cgi.sf.net<br>
I can be contacted directly at lists.drrngrvy [ @ ] googlemail [.] com<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Signal Network library</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Stjepan Rajko</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Douglas Gregor</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Signal Network library aims to facilitate the implementation and interconnection of objects into signal networks using Boost.Signals. To understand the concept of signals (data generators / senders) and slots (data consumers / receivers), please see the Boost.Signals documentation and the associated tutorial.<br>
<br>
This is a proposal for development of the Signal Network library as a part of Google Summer of Code and evential inclusion into Boost. Depending on what is preferred, the Signal Network library can be included into Boost.Signals or considered as a separate library.<br>
<br>
The Signal Network library is to provide<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;* a concise operator based syntax that facilitates construction and readiblity of signal networks<br>
&nbsp;&nbsp;&nbsp;&nbsp;* mechanisms that facilitate construction of signal network components<br>
&nbsp;&nbsp;&nbsp;&nbsp;* implemented building-block components that are applicable to a wide range of signal networks<br>
&nbsp;&nbsp;&nbsp;&nbsp;* detailed documentation (tutorial, examples and reference) of all of the above<br>
<br>
The development platforms are<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;* OS X / Xcode with Apple's branch of GCC<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Windows / MSVC8.0<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Visualization Of Arrays And STL Containers</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jacob Robert Voytko</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Joaquín María López Muñoz</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 As a species, humans gather a majority of their input visually. However, there are an unlimited number of problems that programmers face on a day-to-day basis with computers of a numerical nature. Graphs are the best bridge between the two worlds: they allow for a quick and logical visualization of numerical data that humans are able to quickly comprehend. However, the C++/STL library does not provide a quick and easy way for a visualization of numerical data to occur, and neither does Boost. I propose writing a minimal SVG class that can write in the SVG format along with helper functions to help users visualize data stored in arrays as well as common STL containers. There will also be a subclass, svg_plot, that acts as a user interface for the graph data. The user will be able to customize how they would like the graph to be styled, and the data to be displayed.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Boost.Extension and Reflection</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mariano Gabriel Consoni</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Hartmut Kaiser</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The project that I propose is centered in adding to Boost a library that allows the programmer to include extensions/plugins. Additionally this will be the start point to implement reflection concepts.<br>
<br>
My proposal has two parts:<br>
<br>
- Bring Boost.Extensions [1] to completion and enhance it.<br>
<br>
As I will say in the next sections, I wanted to add to Boost a library that allows an application to have dynamic plugins/extensions within an infrastructure.<br>
<br>
A member of the Boost mailing list told me about a library by Jeremy Pack called Extension. Jeremy and I agreed that the best approach would be to complete and enhance this library. In short, the<br>
completion consists in preparing the library to be sent for review in Boost. The enhancements are several, and will be described later.<br>
<br>
- Implement Reflection [2] using Extensions functionality<br>
<br>
The Extensions functionality is the perfect platform to implement Reflection in C++. I've analyzed several papers about this topic and having Extensions complete will be great to start building this new<br>
features. Also, the Boost Community showed a great interest saying that it would be a great addition to Boost. Discussing Reflection with Jeremy we agreed that it could be very useful to use the dynamic (run-time) method loading features in Extensions to give reflection functionality to normal C++ classes. I'll detail this<br>
point later.<br>

	</div>
 </td>
 </tr>
</table>
<a name='bzflag' />
<h2> bzflag </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Proposal for the Development of a Graphical BZW 2.0 Editor</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jude Nelson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David Trowbridge</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 At the time of this writing, there does not exist a graphical BZFlag world map editor that supports all extensions defined by the BZW 2.0 format.  While some existing editors come close, it is usually the case that they (a) do not fully support 'phydrv,' 'define,' 'group,' etc., (b) require the users to have a programmer's understanding of the file format to make use of all of its features, (c) are not well documented, or (d) are obsolete.  This is problematic to the BZFlag community in that it hinders less technically-inclined users from developing worlds that make use of the BZW 2.0 features, or even developing worlds at all.  To increase the world developer base, a new BZW editor needs to be created.  It should allow users to quickly create worlds in a visual manner, provide GUIs to easily manipulate all features of BZW 2.0, provide intuitive, interactive visualizations of all of BZW 2.0's data, and allow for easy extendibility to ensure future BZW compatibility.  Additionally, to encompass a larger user base, it will be developed using cross-platform toolkits, allowing it to be easily ported between operating systems and ideally support the same target operating systems as BZFlag itself.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Random level generator plugin for BZFlag</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Kornel Kisielewicz</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Remenak</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Even the best game gets boring when it runs out of content. The traditional solution for that is creating a community of modders/map developers. This solution tough has it's weaknesses. The other solution is random map generation.<br>
<br>
Random map generation is older than most players think. It probably started with the game Rogue, from which it wandered into the roguelike community. These in turn spawned one of the most popular games in history - Diablo.<br>
<br>
Although BZFlag implements a poor man's random map generator as default, most players prefer to play on user made maps. The reason is simple -- the primitive scattering algorithm implemented in BZF's random map generation is neither good looking, nor interesting gameplay wise. Yet creating a nice looking and fun to play map by hand is a non-trivial task. To really enjoy playing BZFlag you need to search for good levels in the community, and even those get boring after a while because you learn their layout. Moreover, players who know the map well have an unfair advantage when playing against people who see the map for the first time.<br>
<br>
Hence my idea of providing a complex and state of the art random map generation plugin for BZFlag, that will generate good-looking AND exciting/challenging levels to play. Additionally it will be based on a big set of parameters allowing the creation of pre-prepared generator data for different flavors of levels, or user defined generation. The goal is to provide a map system of near-infinite replayability.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Headless client w/ RoboCode &amp; scripting (for AI)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jørgen Pedersen Tjernø</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Christopher Sean Morrison</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to develop a headless AI agent for BZFlag.<br>
The main feature is that it will expose a 100% RoboCode API to loaded java source, meaning it will take advantage of already created RoboCode AIs.<br>
<br>
The implementation will happen in 5 phases:<br>
&nbsp;- Phase 1: Rip out GUI code<br>
&nbsp;&nbsp;&nbsp;~2 weeks<br>
&nbsp;- Phase 2: Implement Java support, enhance console/administration support<br>
&nbsp;&nbsp;&nbsp;~2 weeks<br>
&nbsp;- Phase 3: Implement full support for RoboCode API, expand it (still backwards compatible) to support BZF-specific features (e.g. jumping).<br>
&nbsp;&nbsp;&nbsp;~4 weeks<br>
&nbsp;- Phase 4: Bug fixing<br>
&nbsp;&nbsp;&nbsp;N/A<br>
&nbsp;- Phase 5: Safety net<br>
&nbsp;&nbsp;&nbsp;~4 weeks<br>
<br>
Deliverables:<br>
&nbsp;- Fully headless client.<br>
&nbsp;- 100% support for RoboCode API.<br>
&nbsp;- BZFlag specific extensions of the RoboCode API.<br>
&nbsp;- CLI/text-based administration.<br>
Potential deliverables:<br>
&nbsp;- Support for other languages (using SWIG).<br>
&nbsp;- Remote administration (telnet?).<br>
&nbsp;- Extensions to the RoboCode API to support chat.<br>
&nbsp;- Configuration files (instead of commandline arguments).<br>
<br>
See the detailed description for the details on the implementation.<br>

	</div>
 </td>
 </tr>
</table>
<a name='bzr' />
<h2> bzr </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Bazaar Integration for Visual Studio</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Klaus Hartke</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Wouter van Heyst</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of the project is to bring the wonderful world of friendly distributed version control to Visual Studio 2005.<br>
<br>
The project's deliverables are a class library written in C# exposing bzrlib to all .NET languages running with Mono or Microsoft's .NET, and a Visual Studio source control provider based of that library integrating Bazaar into Visual Studio 2005. The library could easily be reused to integrate Bazaar also into other IDEs like MonoDevelop.<br>
<br>
Seamless Visual Studio integration could be a great selling point to attract users of other version control systems for migrating to Bazaar.<br>

	</div>
 </td>
 </tr>
</table>
<a name='cc' />
<h2> cc </h2>
<table>
 <tr>
 <th>Title</th>
 <td>OpenOffice.org Writer add-in for publishing CC licensed documents</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Cassio de Albuquerque Melo</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Nathan R. Yergler</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 IP issues are becoming critical in all areas. Adobe has recognized that by developing XMP platform. Creative Commons is an important way of adding IP licensing information to a document's metadata. Despite being a requested feature for OpenOffice.org for more than two years, nothing has materialized.  [http://www.openoffice.org/issues/show_bug.cgi?id=66656 filed in June 2006; http://www.openoffice.org/issues/show_bug.cgi?id=29404 filed in May 2004]. We can't wait anymore. The goal of this project is to provide a tool for supporting the process of licensing documents. Microsoft Office has a Creative Commons plug-in to put IP metadata in its documents. I propose a similar Creative Commons add-in for OpenOffice.org that would allow license information to be embedded in OpenOffice.org documents. [http://www.openoffice.org/issues/show_bug.cgi?id=29404 is an example of one way this tool could be used.] Having a simple way to add Creative Commons licenses will help to spread those licenses much more broadly.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Indexing Embedded License Claims in Tracker</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jason Kivlighn</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jon Phillips</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Working under Creative Commons, I will extended the Tracker search and indexing engine to support the extraction of license claims.  Because of the various forms that the license may take, I will build support based on the recommendations of Creative Commons, as outlined at http://creativecommons.org/technology/usingmarkup.  If possible, I will discuss and extend these recommendations for new formats.<br>
<br>
The project will have two parts 1) Extracting the license claims from a variety of formats, and 2) Indexing the license claims in a consistent form, providing users the ability to search for works based on their license.<br>
<br>
In addition to indexing license claims, other metadata can also be indexed.  For example, because XMP is a format for arbitrary metadata, metadata not related to licenses will also be made available; rather than ignoring this extra information, it could also be indexed as appropriate or made available for indexing in the future.  In other words, I will extend Tracker in the process of indexing license claims.  Specifically, I will also add the ability for Tracker to read XMP sidecar files.  At the very least, the project will result in Tracker gaining support for indexing license claims embedding in MP3, OGG, PDF, HTML, and XML formats.<br>

	</div>
 </td>
 </tr>
</table>
<a name='clam' />
<h2> clam </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Real-time spectral transformations</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hernán Ordiales</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Pau Arumí Albó</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Revamp all CLAM SMS transformations. Turn real-time all those still aren't and have them working on Network Editor. For example: Harmonizer, Morph and Time Stretch. Make nice prototypes for use them with Prototyper and have special focus on some. Also make real-time Voice2Midi and all those widgets which can be needed.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Plugin system for a dynamically extensible framework</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andreas Calvo Gómez</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Pau Arumí Albó</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 CLAM provides a dynamic and intuitive way to interact with audio plugins and generate some results.<br>
<br>
This projects aims to bring together some audio plugin standards that exists in the present and make them available for the CLAM networks. And also to provide the ability to treat a CLAM network as a standard plugin.<br>
<br>
Moreover, it also will provide a generic interface for all kind of plugins in order to manage and provide more detailed information of them.<br>
<br>
More can be found here: http://iua-share.upf.edu/wikis/clam/index.php/Devel/Plugins_TODOs<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Real-time synthesizer using SMS models</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gregory Ryan Kellum</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Pau Arumí Albó</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Modern software-based musical instruments tend to be centered around the keyboard paradigm in which sound synthesis is controlled merely by discrete pitch and amplitude values.  This paucity of information, however, places severe limits on the kinds of music that can be made with such instruments, and for this reason the term “electronic music” has become synonymous with different styles of dance music. I propose to create a real-time synthesizer that can be controlled by continuous values for pitch, amplitude and brightness.  This project would be realized using the CLAM library for audio analysis and synthesis and would further the goals of this project by providing an example application illustrating the use of spectral modeling synthesis.  Spectral modeling synthesis is a variety of sound synthesis that is particularly well suited to the stated task, because it creates models of recorded sounds which can be manipulated in interesting ways without noticeable loss of sound quality.<br>
<br>
In the first stage of the project, I will create a database of samples to be used by the synthesizer.  I will make recordings of an ebow playing a guitar string with pitches at different levels of amplitude and brightness.  (An ebow is a device which creates a magnetic field which can be used to make steel strings vibrate.)  I will derive spectral models of these recordings using CLAM’s SMSTool, and I will save segments of these recordings with uniform parameter values in SDIF format.<br>
<br>
In the second stage I will design the database for managing these SDIF files.  It will allow clients to query the database using values for pitch, loudness and brightness and retrieve in real-time the best fitting segment for a given set of query values.  Due to the requirement of real-time processing, the database will likely have to make use of either caching or sample pre-loading.<br>
<br>
In the third stage I will design the synthesis engine that will be responsible for interpolating between segments and resynthesizing the audio from its spectral representation.  Given the nature of the sound source, it is possible that a sinusoidal model will give an adequate representation of the sonic material, and therefore, the complexities of resynthesizing the residual portion of the signal can be avoided.  I assume that this would be preferable as one of the goals of this project is to create a simpler, more understandable version of a previous CLAM project named SALTO which performed a full-blown sinusoid plus residual resynthesis of saxophone recordings.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Clam for speech</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ebrahim &quot;Abe&quot; Kazemzadeh</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Xavier Amatriain</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This application will detail my interests in the CLAM project and<br>
explain what I can offer the project as a participant in the summer of<br>
code. My main interest is in speech processing and recognition.  This<br>
gives me a partial overlap in interests in the audio processing<br>
capabilities of CLAM, as well as other interests that could add to<br>
CLAM's capabilities and user base.  Specifically, I am familiar with<br>
many of the DSP techniques used in CLAM, but with more of an emphasis<br>
on speech than music.  This slight difference in focus applies both at<br>
the DSP level, as well as the user interface level, since linguists<br>
and speech scientists have different needs from a user interface as<br>
well as the DSP behind it: at the DSP level, there are warpings to the<br>
spectrum to simulate the auditory system, and the LPC model is based<br>
on an articulatory model, for example, and at the user interface<br>
level, there are certain displays that linguistics prefer, like black<br>
and white spectrograms and multi-tiered transcriptions, to name a few.<br>
Given my background in linguistics (BA), computer science (MS, working<br>
on PhD), and EE/signal processing (2 speech processing courses), the<br>
project idea that I am most interested in is the vowel synthesizer .<br>
Below in the detailed description I will explain my past experience<br>
building a LPC/source-filter based vowel synthesizer in Matlab for my<br>
speech processing class.  I'll also explain other ideas I have, both<br>
to further develop this project, and other ideas I have for<br>
incorporating speech recognition abilities into CLAM, such as singing<br>
synthesis, .  I will also describe facilities available to me at my<br>
university that may be helpful.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Enhancing CLAM&#39;s chord detection algorithm for real-time use</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Roman Goj</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David García Garzón</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will improve chord extraction in CLAM (C++ Library for Audio and Music) for real-time usage. Before the start of the summer, as part of my studies,  I will perform research on the current state of this specific area of audio digital signal processing. Then I will try to compare the most promising algorithms by implementing them in CLAM. I will also try to improve the visualization of the results. As a by-product of the research phase I would also like to explore the possibility of adding instrument recognition in the future.<br>

	</div>
 </td>
 </tr>
</table>
<a name='codehaus' />
<h2> codehaus </h2>
<table>
 <tr>
 <th>Title</th>
 <td>SwingXBuilder for Groovy</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>James Williams</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Guillaume Laforge</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The SwingX builder will be an extension to the Swingbuilder class currently included in Groovy. More and more applications are using the SwingLabs components in production applications. Although one is able to use the SwingX components in Groovy using Java code, this means is verbose compared to the SwingBuilder and very un-Groovy.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>JAXB2 implementation for Castor</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Joachim Grüneis</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Werner Guttmann</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Castor is a pretty cool XML and database binding framework. Currently it lacks an implementation of the Sun JAXB2 standard and I want to help to implement it on top of todays Castor implementation.<br>
<br>
There are a lot of very interesting details at implementing JAXB2 for Castor:<br>
Today Castor itself can run under Java 1.3.1, 1.4.2 and 1.5.0 - but JAXB2 will required Java 1.5.0 features to be used in the heart of Castor (at un-/marshalling) - so Castor will need to get more 'plugable'<br>
Castor already has a defined and approved XML - Java mapping, how to implement the JAXB style as a second possibility without harming existing installations<br>
A source generator from schema to Java exists, but it doesn't support classes with annotations - the new implementation needs to generate annotated Java<br>
Today, mapping information can be provided in a variety of possibilities but not via Java annotations - the extensions will allow that mapping information is read from Java annotations<br>
A possibility to generate a schema definition from Java classes needs to be introduced.<br>
The bindings definition of JAXB needs to be supported by schema compiler.<br>
The JAXB API specification needs to be supported<br>
<br>
The implementation of JAXB2 for Castor will be a Java project which results in an own library on top of Castor. Castor libraries are used by the 'JAXB2 for Castor' implementation which just provides the new implementation for users which want to rely on the standard. In addition Castor itself will also need to be modified to support features the JAXB standard requires either by implementing them in Castor itself or by providing the possibility to plugin JAXB specific algorithms.<br>

	</div>
 </td>
 </tr>
</table>
<a name='coppermine' />
<h2> coppermine </h2>
<table>
 <tr>
 <th>Title</th>
 <td>AJAX Support in Coppermine with an API</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nitin Gupta</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Dr. Tarique Sani</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Coppermine as I see it today is implemented in PHP and most of its application logic resides at the server. Also, Coppermine is basically a user application and derives its USP from user experience and the easy of use. However, given the advent of new technologies such as Javascript and AJAX, I strongly feel that the front-end of Coppermine can be greatly improved to provide a far better user experience. Another major advantage of client-side operations is that the load on the server decreases drastically, since the client browser does most of the layout processing, while the server merely acts as a query engine. Examples of improvements possible through Javascript/AJAX are:<br>
(1) The whole page does not have to be reloaded when one moves from one picture to the next picture in the same gallery.<br>
(2) Predictive caching of pictures can be done so that the user does not even have to wait for the next picture and therefore save her browsing time.<br>
(3) In the forums area and the comments section of pictures, the entire page does not refresh when a comment is added or modified. All operations are handled asynchronously.<br>
<br>
The integration of client-side operations into Coppermine would require the client to query/ call functions on the server directly, and therefore, would allow the development of a comprehensive API to interface with Coppermine, which can then be wrapped around any other programming language (including Java, GTK). This can be visualized by say creating a server module to upload pictures, which is called by Javascript through AJAX. This server module is basically providing an API to the outside world to interface with Coppermine - infact, it allows remote interfacing from any web service or application.<br>
<br>
My proposal entails the development of an API for Coppermine, and instead of the development of a GTK client for it, develop an interface for the same through AJAX and Javascript, so as to allow a smooth experience to the users of the application.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Users can create albums in admin allowed categories (Big feature)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Sander Weyens</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Thu Tu</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I would like to develop the ability of users creating albums in admin allowed categories.<br>
<br>
I am using coppermine for about 3 years now, and it think it is time for me to contribute to the project.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>JCpg: a Java based Cpg management and synchronisation application</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Frank Cleynen</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Aditya Mooley</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Overview<br>
--------<br>
JCpg is a java based application which allows a Coppermine Photo Gallery (Cpg) user to manage his photos offline. When an internet connection is established, the program will automatically synchronise the galleries.<br>
<br>
It will be possible for a user to offline manage galleries, albums, photocollections and even do some basic photo editing.<br>
<br>
It would be very handy for people to be able to do this kind of management everywhere they are, even when no internet connection is available. Using Java, the user will even be able to run the application on all of his operation systems with just one version.<br>
<br>
Used technologies and protocols:<br>
•	I will either use Swing or SWT for the creation of the GUI. I read a lot of articles comparing both technologies and I’m not convinced that SWT is faster than Swing but SWT is more easy to use.<br>
•	For the datatransmissions and folder settings I will use the FTP protocol.<br>
•	The Java API to communicate with the user’s SQL databse.<br>
•	Java 1.5.0 or Java 1.6.0. This depends on when Apple will release the JDK 6 for OS X.<br>
<br>
Main features in first stage:<br>
•	managing galleries<br>
•	managing albums<br>
•	managing photocollections<br>
•	basic photo editing<br>
<br>
Goals in the first stage:<br>
•	learning more about Swing and SWT to make the GUI not Java standard (grey).<br>
•	learning more about network programming in Java.<br>
•	making a better and more userfriendly gallery management script of Cpg.<br>
•	deliver JCpg V1.0.<br>
<br>
Links<br>
----<br>
Tracker: http://ardella.madoka.be/jcpg<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Gallery Export, Tagging, and Beefed up Search Features For Coppermine Photo Gallery</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Daniel Roy Hammond</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Joachim Mueller</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will add three features to the Coppermine photo gallery system.  All focus on separate areas of the system but are all united in improving user experience and overall functionality of the system.<br>
<br>
I will create the ability to export the gallery into a format that is useful for offline viewing.  I will allow the person exporting the ability to select specific albums or the entire gallery to export.  Also, since this feature may be used for many different purposes, I will create the option to export the albums in multiple formatted html files, or as a directory structure mirroring the categories and albums containing the image files alone, useful for backing up the data of a Coppermine gallery, printing large quantities of photos, creating a slideshow, and countless other uses.<br>
<br>
Secondly I would like to add photo tagging support to the Coppermine photo gallery system.  Coppermine already supports assigning keywords to photos, and allows for searching based on keyword.  However, keywords can be cumbersome when used to identify people in photos.  I would like to provide a way for users to 'tag' specific parts of a photo (as is available on several web photo gallery services), such as a person or thing, and users to search the gallery by tags and have an optional 'tagcloud' for these tags possibly integrated with the keywords ‘tagcloud’.<br>
<br>
Finally, I would like to improve the search function.  I will add support for searching album titles and categories.  In addition I would add the ability of the search to handle string queries enclosed in quotes such as, “George Washington” (as most major search engines handle queries).  Time permitting I will also add an advanced search option with more search methods including regular expressions.<br>
<br>
All three of these improvements will lead to a general increase in user experience of those visiting Coppermine powered galleries, and open up coppermine powered galleries to uncountable uses off-line.<br>

	</div>
 </td>
 </tr>
</table>
<a name='coresystems' />
<h2> coresystems </h2>
<table>
 <tr>
 <th>Title</th>
 <td>LBdistro - A LinuxBIOS Distro Maker</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alan Carvalho Assis</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stefan Reinauer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently, a lot of people are willing to install LinuxBIOS in theirs motherboards, but there is two main problems:<br>
* LinuxBIOS is not supported by all motherboards;<br>
* The installation process is very complex.<br>
<br>
The first problem will be fixed soon since the motherboard manufactures become interested in LinuxBIOS. Since LinuxBIOS has a lot of advantages when compared to tradicional BIOSes, we believe that users are the main piece in this process, claiming for motherboards with LinuxBIOS support. Companies that depends on more powerful BIOSes or need to make some custom BIOS may help in this process as well.<br>
But the other problem remains.<br>
<br>
My proposal is to develop a software solution that will solve the second problem. This tool will help end users creating a LinuxBIOS distro to flashes on theirs motherboards. Nowadays, the process to create a LinuxBIOS and root file system is painful. Until it works, tons of compilation and waste of time with tests are necessary.<br>
<br>
The software will supply a menu based interface so that users can choose between applications and features to be integrated with LinuxBIOS.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Booting Windows and other Operating Systems in LinuxBIOS</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Augusto Pedroza</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stefan Reinauer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project consists of implementing an efficient way of booting Windows Vista/XP/2003 under LinuxBIOS. Three different approaches have been suggested: using a dedicated LinuxBIOS loader, using kexec/kboot or fixing ADLO (Add-on layer). When choosing one of these, I will take into<br>
consideration the one which, besides supporting Windows XP, can be easily adapted to support windows vista and its possible future modifications.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>New:  Winflashrom: Windows port of LinuxBIOS&#39; flashrom utility</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Darmawan Mappatutu Salihun</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stefan Reinauer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The LinuxBIOS project has been gaining momentum in recent years. More and more platforms implement LinuxBIOS as their core firmware; replacing the more conventional BIOS from vendors such as Award-Phoenix,Inc. and American Megatrends (AMI). Nonetheless, it lacks Windows-based utility to flash the BIOS binary to the motherboard flash ROM because LinuxBIOS development mainly conducted within Linux operating system.<br>
&nbsp;&nbsp;In order to bring LinuxBIOS into a wider audience, it’s important to port some of its components to Windows especially the BIOS flashing utility. This utility is named Flashrom within the LinuxBIOS code base. The nature of a BIOS flashing utility is to gain direct access to the hardware. Therefore, it’s important to port such a utility due to the fact that it can not be executed reliably within virtual machine such as VMware.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Porting Flashrom to windows will benefit many Windows-based firmware developers and any system programmers familiar with Windows-based software development but not experienced enough in Linux-based software development. Winflashrom seeks to become the windows-port of the Flashrom utility within the LinuxBIOS project. It will support both console-based interface and a GUI.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Winflashrom will be composed of a Windows kernel-mode driver interface and a user-mode application that interacts with the kernel-mode driver. The kernel mode driver provides direct access to the BIOS flash ROM chip and other relevant chips in the motherboard, while the user-mode application provides the console interface and the GUI. A completed Winflashrom would certainly help the development of Windows support in LinuxBIOS as a whole because it provides a “direct link” between Windows and the BIOS binary produced by the LinuxBIOS project.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Open Firmware payload for LinuxBIOS</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jens Thomas Freimann</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stefan Reinauer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I have some experience with Forth and Open Firmware and would love to work on making Linuxbios work with the available open source implementations of open firmware like the OLPC implementation, SLOF, etc.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Adding LinuxBIOS support to Grub2 and making LinuxBIOS configuration easy</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Patrick Georgi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stefan Reinauer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to work on two milestones:<br>
<br>
1. Get Grub2 to run as LinuxBIOS payload<br>
This combination enables very flexible booting right from the flashrom, with support for several filesystems and executable formats.<br>
Given that grub2 can be expected to become a de-facto standard in the open source operating system area, this work opens the door to wider LinuxBIOS deployment.<br>
<br>
While working on this, I will port both projects to Solaris, where necessary.<br>
<br>
I expect this milestone to take 3-4 weeks<br>
<br>
<br>
2. Build a configuration editor for LinuxBIOS 3<br>
Currently, configuring LinuxBIOS3 involves writing a file by hand which defines the properties of the hardware and the firmware that should be built for it.<br>
The goal of this milestone is a java based editor to create this configfile. It will be based on Swing or AWT and should also support the user beyond syntax issues, by providing building blocks (eg. known combinations as provided by chipsets) and janitorial checks for potential issues, warning the user.<br>
Such a tool would help mainboard vendors a lot with supporting their combination of chipsets, and I'm not sure that there are similar highlevel tools available for other BIOS systems.<br>
It could be used as webapplet for a remote firmware building service, if there is interest in that.<br>
<br>
I expect that I can provide a working editor by the end of the SoC period, but can't give a definite schedule without detailed discussion about the feature set.<br>
<br>
<br>
If these two milestones don't fill the 3 months, I would work on whatever the mentors think is interesting.<br>
One thing that I would consider interesting is building more payloads, like one for OpenFirmware support.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>(U)EFI payload for LinuxBIOS based on TianoCore</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>YI XIONG</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stefan Reinauer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 (U)EFI shares a significant market in the firmware area. It is absolutely necessary to get the (U)EFI implementation to work as the LinuxBIOS payload. There are two open source (U)EFI implementation, GNUFI and TianoCore. The former is still in the development progress and there is no official release till now. And the TianoCore is comparatively stable, even the EDKII of TianoCore supports the gnu tool-chain for building. I will introduce the feature that an (U)EFI implementation runs as the LinuxBIOS payload referring to the TianoCore. The following tasks are needed for this goal in general:<br>
1. To figure out the platform/hardware dependent module and the platform/hardware independent modules in the TianoCore, and the interfaces between them.<br>
2. To figure out the rules/methods/interfaces that how the payload and the LinuxBIOS interoperate.<br>
3. To develop the new module of LinuxBIOS to replace the platform/hardware dependent module of TianCore. Specifically to encapsulate the original module of LinuxBIOS to form the new interfaces to support the EDK foundation source codes.<br>
4. To develop the new interfaces for the interoperation between the EFI payload and LinuxBIOS<br>
Maybe the 3rd and 4th tasks can be unified together when complete the 2nd task.<br>

	</div>
 </td>
 </tr>
</table>
<a name='crystal' />
<h2> crystal </h2>
<table>
 <tr>
 <th>Title</th>
 <td>World editor</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Seth Yastrov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Frank Richter</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Crystal Space, being a 3d engine, deserves a good art pipeline so that applications using it can focus on creating assets, not editing world files by hand. Having worked on several game projects using CS over the past 2 years, I have experienced directly the difficulty of getting art into the engine. I would like to help take a huge step in improving it by creating a usable world editor.<br>
<br>
The editor should have a completed framework by the end of the work period, including a working plugin system, undo/redo system, selection system, tool system, save/load functionality, scene browser, factory browser, and property editor. Also, basic selection and transform tools will be implemented. Any remaining time will be used to polish the user interface or implement tools for other CS features, such as terrain.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>COLLADA Conversion Library and Utility</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Scott Johnson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Christoph Mewes</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 COLLADA is a 3D computer graphics digital asset schema [1].  It is a file format description designed with computer gaming and interactive applications in mind.  The major function of the schema is to provide the necessary tools so that applications can easily, efficiently, and dynamically share media and digital assets.  The primary goal of this project is to develop and implement an importer for the Crystal Space 3D SDK such that it can use files created in the COLLADA schema.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Artificial Intelligence Module</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mauricio Hollando</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jorrit Tyberghein</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Artificial Intelligence Module<br>
<br>
The project which I propose tries to cover to basic actual needs of the Crystal Space projects, AI and path finding (which I would include within the AI module). A good AI module would be a great step to the project since it is (in my opinion) a critical part of any serious game engine.<br>
<br>
I wish to create a complete, solid, AI module that could be useful to many projects with small or medium demands on AI and physics. I also wish to leave very good documentation on my achievements so there could be further advancements within the same projects (even by myself if that's possible).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Framework for platform specific optimizations</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Michael John Gist</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Marten Svanfeldt</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The current code-base in CrystalSpace has critical code paths optimized mainly by choice of algorithm and in some cases in the implementation; however this is in pure C++. In most cases this is okay or even as good as we will get, but there are a number of places where we could benefit from correct usage of platform specific optimizations such as SSE on Intel and AltiVec on PPC. As the code is generally platform independent and supports a wide range of hardware this poses a number of challenges when it comes to abstraction and using the right implementation.<br>
<br>
This project would develop a framework within which platform specific routines can be developed for critical code, and a right set of routines be selected both during compile and at runtime, determined by CPU feature set and target OS support.  As a sort of &quot;proof-of-concept&quot;, it would also optimize one or more chosen places to use this framework.<br>

	</div>
 </td>
 </tr>
</table>
<a name='cscs' />
<h2> cscs </h2>
<table>
 <tr>
 <th>Title</th>
 <td>GridSweeper Extension &amp; Completion</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ed Baskerville</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Rick Riolo</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Scientists that model complex systems on the computer often need to perform hundreds or thousands of simulation runs using different parameters. Modern grid computing systems have the potential to make such batches of simulations very easy, but no widely available software exists to integrate the two. GridSweeper, an open-source project begun during Summer of Code 2006, will provide scientists with a straightforward interface for running simulation batches. Some work remains before the software is useful and complete. This year's project is to complete that work.<br>
<br>
The GridSweeper code currently includes support for several kinds of parameter sweeps, including simple lists, ranges, stochastic sampling, and arbitrary combinations thereof. Code also exists to extend GridSweeper with adapter plug-ins for different kinds of model programs, and with plug-ins to provide support for different file transfer systems. Job submission is done via the Distributed Resource Management Application API (DRMAA).<br>
<br>
This year's project will add more sophisticated user interfaces, allowing the user to create, modify, and save batches from the command-line or from a graphical interface. It will also include several plug-ins for different types of model programs. Finally, the project will include testing, documentation, and packaging of the GridSweeper project.<br>
<br>
The original 2006 proposal is available here:<br>
<br>
http://code.edbaskerville.com/gridsweeper/proposal.html<br>
<br>
and development progress is being tracked here:<br>
<br>
http://code.edbaskerville.com/<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>I-SPOC</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Michael J Bommarito II</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Scott E Page</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The primary benefits of I-SPOC are likely to be derived from its facilitation of accessibility, organization, and communication.  Models must be easily downloaded and cross-linked with results/literature.  Models must also easily be organized into multiple taxonomies, such as discipline(s), methodology (ABM/GA/CA), and qualitative focus (equilibrium/non-equilibrium).  Lastly, and perhaps most importantly, communication both specific to single models and in general should be as easy as possible, while still providing for features such as LaTeX typesetting.  In order to most effectively accomplish these objectives, I propose the implementation of a Drupal site.<br>
<br>
To provide for the modeling side, a critical mass of basic models should be developed to both attract and sustain interest in the project.  I propose the implementation of a number of archetypal models in each of the major disciplines (social dynamics, biology, economics, physics, political science), as well as an active attempt to engage authors of recently published modeling material (e.g. arxiv,SSRN,RePeC) in the process.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Seeding the I-SPOC</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ryan Henderson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Scott E Page</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I would create some initial SPOCs and MOREs as proposed on your ideas page.  Not only complex systems models like the tribute system and landscape theory described in Axelrod's books, but also nonlinear physical systems such as a 3-body problem or free pendulum; I believe including example SPOCs beyond the scope of complex systems will increase the cross-disciplinary appeal of the I-SPOC project since academics from fields like physics, applied mathematics, chemistry etc. are also relying more heavily on computation, though not<br>
all such code is necessarily related to complex systems analysis.<br>
<br>
It is important that prototype SPOCs contain code in a number of different languages (Java, C, Matlab, Python...) possibly even the<br>
same code in different languages; one of your stated goals is replication and re-implementation, and having example SPOCs with code in different languages will help back it up.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>I-SPOC</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Terrence Charles Stewart</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Rick Riolo</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 As researchers study more and more complex systems, the theories they generate become more and more complex.  This has led to the rise of computational modeling as a method for investigating and understanding such systems.  However, computational modeling research produces results that are not well suited to the standard academic publication format.  Researchers need to be able to experience models created by other researchers, and need to be able to expand on and modify them, looking at different situations or changing them in new ways.  This cannot be done via a high-level summary of by the model and the results found within a static publication.<br>
<br>
There have been a number of suggestions to resolve this problem, including one by Humphreys &amp; O'Leary (2002) that every modeler should set up a version of their model on a publicly accessible computer, so that other researchers could log in and use the model.  Instead of taking this approach, the I-SPOC proposal from the Center for the Study of Complex System is to form an online repository where models and their associated papers and data can be stored, along with instructions for running and using these models, and any links to newer, older, or similar models can be kept track of.  This allows for a simple, direct way to get access to the work of other researchers, allowing for greater collaboration, and more comparisons between models and expansions of existing models.  This also opens up the possibility of testing models, which is especially important considering Axelrod's finding that when attempting to replicate models, there is consistent “ambiguity in the published descriptions, ... gaps in the published descriptions, ... [and] situations in which the published description was clear, but wrong” (Axelrod, 2003).<br>
<br>
This proposal is to build an online repository system following the requirements described in<br>
http://www.cscs.umich.edu/~rlr/SoC/uploads/Main/SPOC-Description-From-2007-11-12.pdf<br>
This will allow for the submission and updating of these SPOCs (Scientific Paper with Open Communication).  Important features include version control for tracking changes over time, feedback on issues involved in installing and running models, and links to other related models.  The intent is to allow computational models to be a rigorous, reproducible, and easily accessible aspect of modern scientific research.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Urbance: An agent-based approach to Architectural Design</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Dawn Thomas</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Rick Riolo</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The proposal is for the development of a mathematical model,methods, and libraries to analyze Urban design, as well as patterns of Urban growth and various feature associated with it using MASON. Primary deliverable will be the model along with the system as a library which would make modeling of urban space and its elements easy for future analysis in the field of Computer Aided Urban Design/ Analysis.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The urban system is an intrinsically dynamic environment – a constant struggle for equilibrium between constraints &amp; requirements, a platform where diverse interactions take place between agents of numerous but finite variety.  The constraints maybe dynamic or static. The requirements are a constantly changing set which is often dependent on the present situation thus inducing the concept of feedback. Such a system of agents – who provide constraints and requirements  in a heterogeneous &amp; dynamic environment with a constant feedback system could be interpreted as a complex system. Hence urban system needs to be interpreted and analyzed using mathematical methods and techniques in the field of complex system analysis.<br>
<br>
Application of such a multi-agent based approach in the field of Urban development provides an opportunity to look at urban growth patterns, profile and form in a completely new light. Drawing analogies from the functioning of Urban System as interactions in a multi-agent environment, a simulation of the same can be used to develop solutions for the Urban Design problem.<br>

	</div>
 </td>
 </tr>
</table>
<a name='daisy' />
<h2> daisy </h2>
<table>
 <tr>
 <th>Title</th>
 <td>HTML diff</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Guy Van den Broeck</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Bruno Dumon</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of the &quot;HTML diff&quot; project is to provide a Java library that compares XML files. The minimum inputs are 2 XML files, and the minimum output file is a Java representation of the basic operations that turned the first data structure into the second.  This output can be converted to an XML-based representation or, given the proper formatting guidelines into an html file with a certain syntax to denote changes.<br>
In addition, distance metrics can be computed that allow the user to quantify by how much 2 files differ. This enables them to distinguish minor from major changes, and tells them what the (chronological) relationships are between 3 files.<br>

	</div>
 </td>
 </tr>
</table>
<a name='debian' />
<h2> debian </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Implementing Mole, infrastructure for managing information</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jeroen van Wolffelaar</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Martin Michlmayr</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My application is about implementing Mole:<br>
<br>
http://wiki.debian.org/Mole<br>
<br>
Mole is a set of scripts, mostly in python, to manage many kinds of<br>
information. Although designed with Debian QA purposes and goals in mind, this<br>
could also find many other uses, being pretty generic infrastructure.<br>
<br>
Mole provides at least the following:<br>
- A means to accept submitted information, with optional access control and<br>
&nbsp;&nbsp;moderation<br>
- A means to store both transient and constant information (&quot;data&quot;)<br>
- A means to retrieve this information quickly and efficiently in both<br>
&nbsp;&nbsp;micro-queries and as whole datasets, including easy mirroring<br>
- A web interface for easy browsing of the available information<br>
- A means to coordinate the generation of information<br>
<br>
This is very generally spoken mole. To make things a bit more concrete, one<br>
example:<br>
<br>
- Mole would accept (by mail, HTTP post, or otherwise) build logs for building<br>
&nbsp;&nbsp;source package in current unstable/testing in a standard or rather a<br>
&nbsp;&nbsp;specifically tweaked environment<br>
- It would store it in its database in an efficient form, keeping some<br>
&nbsp;&nbsp;configured amount of older versions too<br>
- It would maintain a list of source packages that don't have such log yet, or<br>
&nbsp;&nbsp;which log is older than a configurable amount of time, and provide worker<br>
&nbsp;&nbsp;machines that can do such rebuilding with a todo-list. Mole would<br>
&nbsp;&nbsp;automatically keep track such that double work is prevented.<br>
- Via for example a web interface people can query results of specific<br>
&nbsp;&nbsp;packages, but one can also retrieve the full database.<br>
<br>
This approach is very powerful, because mole &quot;jobs&quot; can be stacked. To continue<br>
with the above example, a different job could keep track of such logs that<br>
didn't get 'judged' yet, and have a worker judge them for<br>
&quot;succesful/not-succesful&quot;, and store those qualifications in a result table.<br>
<br>
Additionally, data-providers do not need to be computer programs, they can also<br>
be humans. For example, the job could be &quot;file bugs on failed logs/mark a<br>
failed log as &quot;wrongly failed&quot;. Data can also be abount non-package things,<br>
such as bugs, or mirrors. It can itself also be something else than quality<br>
tests, examples would be mere extraction of data such as .desktop files for<br>
auto-installers, SLOC-counts for funny statistics, or (user-supplied)<br>
screenshots and reviews.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Automated Upgrade Testing Using QEMU</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ian Haken</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lars Ivar Wirzenius</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 When upgrading packages, especially between releases, it is possible for conflicts to occur as a result of dependency problems, version conflicts, and more. In order to identify these problems early, the overall goal of this project will be to create a system which runs an automated test upgrade and logs the results. It will do so by creating a Debian environment from scratch running within a QEMU virtual session. The initial environment will be built using packages from a selected repository, and within the live system it will then be upgraded using packages from a second repository. Problems encountered during this upgrade will be logged and reported in order that they can be fixed early or before official releases. This is often hard to do on live systems as it requires submitting the system to danger of a failed upgrade, and it requires having a system in the desired initial release version.<br>
&nbsp;&nbsp;&nbsp;In the final version I hope to include additional features such as selecting specific version of packages from each repository so that bug reports of package upgrade problems can use a list of installed packages to reproduce the problem and identify the causing element more easily. It could also be used for debugging in general if one wanted to easily reproduce the Debian system on which an ellusive bug occurs.<br>
&nbsp;&nbsp;&nbsp;This tool can be used by developers for the above reasons, and it could also be used by system administrators, as well, for the purpose of running it as a test before upgrading their live systems. In this way, administrators would be able to prevent a conflict from occurring the midst of an upgrade, and what's more notify Debian developers so that this problem can be resolved without leaving their existing system in a half-upgraded state.<br>
&nbsp;&nbsp;&nbsp;Furthermore, thanks to the versatility of QEMU, one would be able to test upgrades for many target CPU types including x86, x86_64, ARM, SPARC, PPC, and MIPS, all from an x86, x86_64, or PPC host system.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Piuparts improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ana Beatriz Guerrero López</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Luk Claes</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this project is to improve piuparts to help Debian's Quality Assurance efforts and make piuparts easier to use for Debian maintainers in order to spread its use to package checking.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>BitTorrent Proxy for Debian Archive</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Cameron Dale</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Anthony Towns</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project will be to expand on the BitTorrent application to work<br>
effectively with large, constantly updating collections of files<br>
such as the Debian archive. BitTorrent is a peer-to-peer file<br>
sharing application designed to reduce the costs of hardware,<br>
hosting and bandwidth resources for the original distributor by<br>
allowing downloading peers to share downloaded data with others.<br>
This project proposes to create a backend or proxy to the Debian<br>
package distribution tool apt, which will allow for the downloading<br>
of packages from other users of Debian in a BitTorrent-like manner,<br>
thus reducing the costs incurred by the archive's host.<br>
<br>
Upon completion and widescale deployment of the service, the<br>
bandwidth and hardware costs of providing a very large Debian<br>
archive to hundreds of thousands of users will be dramatically<br>
reduced.<br>
<br>
Though the idea of implementing a BitTorrent-like solution to<br>
package distribution seems good, there are some problems with the<br>
current way that BitTorrent distributes files that make it<br>
unsuitable for the Debian archive. First, the Debian archive is a<br>
very large repository of packages, including many different versions<br>
and architectures. A normal user will only want to download a very<br>
small subset of the entire archive, whereas it is normal in<br>
BitTorrent to download the entire torrent. Secondly, the archive is<br>
made up of a distribution of file sizes, many of which are smaller<br>
than the smallest piece size used by BitTorrent today. Some<br>
enhancements will be needed to allow for the downloading of small<br>
packages without wasting large amounts of bandwidth. Finally, the<br>
archive is frequently updated, though only a very small portion of<br>
it at a time. BitTorrent is currently not designed to handle updates<br>
to files, nor multiple versions of files. Solutions to all of these<br>
problems will need to be found.<br>
<br>
More information is available here:<br>
<br>
http://www.cs.sfu.ca/~camerond/personal/GoogleSoCDebian.html<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Bug Triage and Forward Tool</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gustavo Rezende Montesino</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Loïc Minier</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The teams and maintainers responsible for big sets of packages in Debian, like X.Org, GNOME, KDE, Kernel, etc. frequently lack the manpower to keep their packages up-to-date and still triage all bugs reported against them. Usually, these teams are running up against huge backlogs of bug reports, and some reports may remain unanswered for a long period of time, which in turn may cause the reporting users to think their reports aren't useful, and stop to submit bugs. This loss of bug reports may lead to the reduction of the quality of the Debian distribution and of the upstream software, as a good amount of these bugs need only to be forwarded and fixed by the upstream developers. This was recently discussed in the debian-project mailling list [1].<br>
<br>
To address this problem, I propose the development of a tool to facilitate the triaging of bug reports, rising the productivity of the limited time the maintainers have to triage the bugs and offering a friendly tool to make basic bug triaging an attractive way for users to introduce themselves in Free Software development.<br>
<br>
[1] http://lists.debian.org/debian-devel/2007/02/msg00643.html<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Bug Submission and Manipulation Web-based User Interface for debbugs</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Margarita Manterola Rivero</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stefano Zacchiroli</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Debian Project has its own Bug Tracking System (called debbugs, or just BTS), which includes many nice features, but one important drawback: it's driven completely by email.  Lots of users and developers would benefit from the ability of being able to manipulate and submit bugs directly with a web interface.<br>
<br>
The aim of this Summer of Code project is developing a web-interface for debbugs which is not read-only as the current one, but which enables manipulation of bugs both in form of new submissions and in form of all the other actions which are possible on previously reported bugs.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>OVAL Agent for Debian</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Pavel Vinogradov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Javier Fernandez-Sanguino</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The project goal is to develop a technique for Debian-based clusters security status managment. Notwithstanding the presence of the tools providing local security updates checking (i.e. update-notifier, integrated with the GNOME desktop, or cron-apt), there is no essential way to manage tens or hundreds of systems.<br>
&nbsp;This project is based on Open Vulnerability and Assessment Language, which is an international information security community standard to promote open and publicly available security content, and to standardize the transfer of this information across the entire spectrum of security tools and services. OVAL includes a language for data definition and interpretator which collect information from a computer for testing, to evaluate and carry out the OVAL definitions for that platform, and to report the results of the tests.<br>
&nbsp;Only the generic implementation of OVAL agent is present to the moment, but it may be adapted for the Debian distribution. And implementation of OVAL server will provide centralized managment of the entrie network security status.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>A modular lintian-like CD-image testing tool</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Martín Hernán Ferrari</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Steve McIntyre</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Debian Project routinely builds CD and DVD images of specific distributions, like Debian stable, Debian testing and Debian unstable. Each one of those in different &quot;flavours&quot; that fit different needs (business card, net-inst, full archive) and for different target architectures [1]. Also there are images for various Custom Debian Distributions like Skolelinux, and even live-CD systems.<br>
<br>
Many of those images are built weekly or even daily, this results in a *lot* of ISO files.<br>
<br>
As verifying that the built images work is currently a manual process, there is too much work spent in this task. Also, images meant for a release need more presumption of correctness, as it would be very bad publicity to ship a broken image.<br>
<br>
To alleviate this situation, a modular lintian-like CD-image testing tool is proposed.<br>
<br>
[1] http://lists.debian.org/debian-cd/2006/12/msg00068.html<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GUI frontend for live-helper for building live Debian systems</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Chris Lamb</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Baumann</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Live-helper is a utility to build CD, DVD, netboot and USB-stick live images of Debian, a GNU/Linux operating system. It boasts support for multiple architectures, auto-building images, amongst many other features.<br>
<br>
Live-helper is extremely flexible, allowing interested parties to create their own system completely specific to their needs, including support for custom package lists, kernel parameters, encryption, additional commands to configure the live system etc.<br>
<br>
My proposal is to construct a graphical user interface that can be used in conjunction with live-helper to build Debian Live systems, allowing editing of existing configurations and including a 'wizard'-style walkthrough for the first-time user.<br>
<br>
Providing less experienced users with the opportunity to easily create live distributions will generate more exposure for live-helper, providing more valuable feedback for its developers and ultimately helping Debian's image as an extremely flexible and free operating system.<br>
<br>
The GUI will be written in Python using the pygtk GTK+ bindings.<br>

	</div>
 </td>
 </tr>
</table>
<a name='detached' />
<h2> detached </h2>
<table>
 <tr>
 <th>Title</th>
 <td>TI-83 Plus Logo Interpreter</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Benjamin Moody</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Marinus Johannes Warmer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to write a Logo interpreter for the TI-83 Plus and related<br>
calculators.  This will serve as an alternative programming<br>
environment which is at once easy for beginners to learn and far more<br>
powerful than the builtin &quot;TI-BASIC&quot; language used on these<br>
calculators.  I will aim for &quot;pseudo-compatibility&quot; with the popular<br>
UCBLogo dialect, so that it will be possible, with some care, to run<br>
the same programs on the PC and on the calculator.  Although I will<br>
not have time to implement the entire UCBLogo library in the course of<br>
a summer, by the end of the summer I hope to have a functional<br>
interpreter that can run some interesting programs.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Hook Manager application for TI-83+/84+</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andrew Janata</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brandon Wilson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 There are several very useful applications for the TI-83+ series which make use of the system's hook facilities. However, most of these applications don't share hooks well together, or only share hooks with a few other programs. Hook Manager would make the hooks be fully under the user's control.<br>
<br>
Several useful applications for the TI-83+ calculator series make use of the system's integrated hook facilities.  Unfortunately, most of these applications will not share the hooks with other applications for the TI-83+, or if they do, only with a limited subset.  The Hook Manager project seeks to create a program that places the user in full control of the system hooks.<br>
<br>
Hook Manager would manage the system's hooks, allowing multiple applications' hooks to be chained together in any order specified by the user. These hooks would be detected from currently active hooks. An editor will allow the user to (de)activate and reorder hooks at any time.<br>

	</div>
 </td>
 </tr>
</table>
<a name='django' />
<h2> django </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Generic views for RESTful web services</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andreas Stuhlmüller</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Malcolm Tredinnick</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will implement a general method offering a public and private API for existing Django models. New generic views will simplify data retrieval and modification via different web services in a resource-centric REST architecture, providing model data in formats such as XML, JSON and YAML with very little custom code.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Integrate package managment into Django and build a public repository website</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jannis Leidel</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>James Richard Bennett, Jr.</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 For further updates look at http://jannis.leidel.info and http://code.google.com/p/django-package/<br>
<br>
Django is one of the major web frameworks that emerged within the last years and created a solid user and developer base. It simplifies the development process by providing tools to reduce repetition, abstracting common web paradigms and still being hackable. Until today that attracted a wide section of programmers, from novices to pros.<br>
<br>
As the code base is constantly moving towards the 1.0 release, more and more people are using Django to build small projects and websites, just as well as commercial applications like intranet services and content managment systems are realized with it, too. Good for them:<br>
<br>
&nbsp;&nbsp;Reinventing the wheel with Django is perfectly easy – every Django beginner wrote a todo list or weblog applicaton :)<br>
<br>
But this is not the end of the road for user participation. The community should be able to uncover more web ideas for contrib apps, combine the already written views and templates to more effecient apps and simply share their products with other users.<br>
<br>
The implementation of a package system would lower the threshold for Django and Python beginners significantly because it reduces the hassle of the current installation procedure.<br>
<br>
My task is to do the groundwork for an application which manages Django application packages and integrates tightly with the Django code.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implementing Check Constraints on Models</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Thejaswi Puthraya</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Simon Blanchard</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 * To implement check constraints on models.<br>
<br>
The various check constraints to be implemented:<br>
1)Range Based Check Constraints<br>
2)Value Based Check Constraints<br>
----------------------------------------------------------------------<br>
Most Database engines like Postgresql, Sqlite, Firebird etc have built in support for check constraints. So for these database engines the check constraints can be implemented at the database level whereas for MySQL (which does not support check constraints),it has to be implemented at the application level (ie in Django).<br>
<br>
Example 1: Range based Constraint<br>
<br>
from django.contrib.constraints import CheckConstraints<br>
<br>
class Product(models.Model):<br>
&nbsp;&nbsp;product_name = models.CharField(maxlength=50)<br>
&nbsp;&nbsp;discount = models.IntegerField()<br>
&nbsp;&nbsp;check_discount = CheckConstraints(discount__gte = 0 AND discount__lt = 100)<br>
&nbsp;&nbsp;price = models.IntegerField()<br>
&nbsp;check_price = CheckConstraints(price__between = [0,10000] AND price__gt = discount)<br>
<br>
<br>
Discount and price can only be a non-negative value. Also it checks for discount &lt; 100 and if price &gt; discount and price is between 0 and 10,000.<br>
<br>
The various Range based constraints being<br>
<br>
&nbsp;* greater than gt &gt;<br>
&nbsp;* lesser than lt &lt;<br>
&nbsp;* equal to eq =<br>
&nbsp;* not equal to neq &lt;&gt;<br>
&nbsp;* lesser than or equal to lte &lt;=<br>
&nbsp;* greater than or equal to gte &gt;=<br>
&nbsp;* between between (expects a range)<br>
<br>
Range based constraints can be used to check for constraints for more than one column (as seen in the example above).<br>
<br>
Example 2: Value Based Constraints<br>
<br>
from django.contrib.constraints import CheckConstraints<br>
<br>
class Person(models.Model):<br>
&nbsp;&nbsp;first_name = models.CharField(maxlength=50)<br>
&nbsp;&nbsp;last_name = models.CharField(maxlength=50)<br>
&nbsp;&nbsp;check_name = CheckConstraints(last_name__neq = first_name)<br>
&nbsp;&nbsp;gender = models.CharField()<br>
&nbsp;&nbsp;check_gender = CheckConstraints(gender__upper__in = ['MALE','FEMALE'])<br>
<br>
This prevents both first_name and last_name being the same and the upper case value of gender must either be a MALE or a FEMALE.<br>
<br>
The Value based constraints being<br>
<br>
&nbsp;* IN to check whether the input is in a given list<br>
&nbsp;* LIKE to check if the operand resembles a value (regexps are possible)<br>
<br>
Example:<br>
<br>
from django.contrib.constraints import CheckConstraints<br>
<br>
class Manufacturer(models.Model):<br>
&nbsp;&nbsp;&nbsp;name = models.CharField(maxlength=50)<br>
&nbsp;&nbsp;&nbsp;check = CheckConstraints(name__like='Merced%')<br>
<br>
&nbsp;* NULL to check if the given value is a Null or not (already implemented)<br>
&nbsp;* UNIQUE to check for uniqueness of column in the table (already implemented)<br>
<br>
Example 3:<br>
<br>
from django.contrib.constraints import CheckConstraints<br>
from datetime import date<br>
<br>
class Project(models.Model):<br>
&nbsp;&nbsp;proj_name = models.CharField(maxlength=50)<br>
&nbsp;&nbsp;check_name = CheckConstraints(proj_name__like='World_Online%')<br>
&nbsp;&nbsp;start_date = models.DateField()<br>
&nbsp;&nbsp;check_start_date= CheckConstraints(start_date__gte = date(2007,01,01))<br>
&nbsp;&nbsp;end_date = models.DateField()<br>
&nbsp;&nbsp;check_date = CheckConstraints(start_date__lte = end_date)<br>
<br>
The above model checks if project name contains World_Online at the beginning of the proj_name, the project start date is after January 1st 2007 and project end date is after the start date. Simple database based validations done with three small lines in Python (also these lines are similar to the field set lookups, so not much of learning required).<br>
<br>
When are these check constraints invoked?<br>
<br>
These check constraints are called whenever a model object is created or edited.<br>
<br>
Benefits of Check Constraints:<br>
<br>
&nbsp;* Allows the programmer to write constraints in Python (without having to know SQL)<br>
(Sticking to Django's philosophy, purists will not be disappointed.)<br>
&nbsp;* Check constraints are used to ensure the validity of data in a database and to provide data integrity. If they are used at the database level, applications that use the database will not be able to add invalid data or modify valid data so the data becomes invalid, even if the application itself accepts invalid data.<br>
<br>
&nbsp;* Check constraints provide better data integrity. As check constraints are always executed whenever the data in the column upon which they are defined is to be modified.<br>
<br>
&nbsp;* Check constraints promote consistency. Because they are implemented once, in the table DDL, each constraint is always enforced. Constraints written in application logic, on the other hand, must be executed by each program that modifies the data to which the constraint applies. This can cause code duplication and inconsistent maintenance resulting in inaccurate business rule support.<br>

	</div>
 </td>
 </tr>
</table>
<a name='drupal' />
<h2> drupal </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Project quality metrics system</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andrew Morton</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Angela Byron</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose work on enhancing Drupal's Project module to add a system that computes a number of quality metrics to assist in rating projects. These metrics will help users determine which of the many contributed modules and themes are being actively developed and maintained.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implementation of Jabber/XMPP communications interface for Drupal</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Maxim Khitrov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>James Walker</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This proposal is about implementing an Extensible Messaging and Presence Protocol (XMPP aka Jabber) interface for Drupal, which would allow the system to interact with its users via instant messaging. The primary goal of the project will be to implement XMPP extension XEP-0060 (Publish-Subscribe), along with its dependencies, using only PHP and no external jabber software. This will give Drupal users the ability to choose IM as an alternative, to e-mail, medium through which various system messages are delivered.<br>
<br>
Initial development will concentrate on one-way communications, with messages being sent from Drupal to its users. Eventually, it is my hope to extend the framework into a fully-functional XMPP server, allowing for two-way communications and a whole new way of interacting with a content management system.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>RCS abstraction for the Project module</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jakob Petsovits</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Andy Kirkham</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Synopsis<br>
<br>
The Project module, together with its companion project_release.module, makes extensive use of the CVS module in order to accomplish revision control system (RCS) integration. In order to get drupal.org's new release system done in time, the Project module has been made even more dependent on CVS specifics, making it hard to impossible to use Project's functionality together with other revision control systems.<br>
<br>
During the Summer of Code, I want to decouple the Project module from the CVS module and move CVS specifics into an RCS independent API. At the end, cvs.module should only be one of several possible backends for the RCS API, so that supporting other revision control systems like Subversion, Mercurial or Git can be achieved with reasonable effort. As an additional advantage, other projects like Case Tracker can also make use of the RCS API in order to integrate revision control functionality while sharing as much code as possible.<br>
<br>
What is specifically not planned for this project (though possible in case that the existing deliverables take less time than expected) is Subversion support itself. I decided to leave this task out because all the knowledgeable developers that I contacted estimate more time needed for the groundwork than what it would originally look like. So I'll concentrate on just getting the Project module to be RCS independent - which, according to dww, is the majority of the work - and leave actual Subversion support to a future project.<br>
<br>
<br>
Motivation<br>
<br>
Getting rid of the hard dependency on CVS will benefit a lot of people who want to use the Project module together with their internally used revision control systems. drupal.org itself makes heavy use of the Project module, and if drupal.org ever wants to switch to a more modern revision control system (like Subversion which is frequently in the talks) then RCS abstraction is a basic requirement for such a switch. However, as mentioned above, writing the actual Subversion support itself is not in scope of this project.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>New Drupal Core Theme</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Klaas Van Waesberghe</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Theodore Serbinski</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Design a new core theme<br>
<br>
<br>
Synopsis<br>
<br>
Although Drupal has a very nice core theme (Garland) since version 5 it would be great to offer an additional theme that's more suitable for customization. Think CSS Zen Garden (http://www.csszengarden.com/), where most of the design changes can be done by only editing the CSS.<br>
Of course the design should also be pleasing to the eye, yet it should offer something different than the current blog oriented Web 2.0 theme. Making a more authentic look (see http://www.simplebits.com/) will make Drupal look more professional and classy.<br>
<br>
<br>
Motivation<br>
<br>
This project was proposed on the Drupal website (http://drupal.org/node/124067).<br>
I've installed Drupal several times already. One of the most time consuming things during deployment is tweaking the default theme or using it as a base for a new theme. That's why I think it is interesting to develop an additional core theme that doesn't only use a different style but also makes customization or using it as a base for a new theme easier.<br>
<br>
<br>
Project<br>
<br>
I will split up the project in the following parts:<br>
- Design a mock-up in Photoshop<br>
- Make an XHTML/CSS mock-up from the Photoshop version supported across most modern browsers<br>
- Implement the layout in a PHPTemplate theme<br>
- If possible and needed enhance certain areas with JQuery or the Drupal Color module<br>
<br>
Because many people have had their share of Web 2.0 or &quot;kiddy&quot; layouts I thought it would be interesting to use a more authentic look, similar to what Dan Cederholm did with his personal website SimpleBits (http://www.simplebits.com/) or Cork'd (http://corkd.com/). This style tends to make a website look more serious or professional and it will make a visitor feel more comfortable.<br>
Before making the actual design using a graphical tool I will outline the layout of the page and choose a color palette that is both modern and close to Drupal's  current style. When that's finished I will start designing the mock-up for the main content types Drupal uses (main page, node, admin dashboard, forum, list of articles, generic blocks, etc.). Attention will be given to Drupal specific features and how to make them more usable (eg. primary/secondary navigation, search box, left/right column, etc.).<br>
<br>
Once the design mock-up is finished an XHTML/CSS version will be made. It's crucial that the XHTML is semantically correct and offers enough hooks for customizing the theme using only a CSS file (see http://www.csszengarden.com/). This should be applied to all the default content types and blocks Drupal offers.<br>
Next to that additional stylesheets will be included for mobile view or printing. A nice feature to add might be different stylesheets for a fluid, fixed or hybrid layout.<br>
The CSS files will be very well structured and class and id names will be chosen appropriately in order to ease quick customization of the theme.<br>
<br>
When the XHTML/CSS is done a PHPTemplate should be made, overriding most Drupal template hooks in order to make the theme feel consistent across all Drupal features and default modules.<br>
<br>
If time permits the new theme will use the same approach as Garland regarding colors. There will be a feature enabling Drupal webmasters to easily edit the theme's colors without knowing any XHTML or CSS.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Taxonomy Manager</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Matthias Hutterer</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Nicholas Thompson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A new module which provides a powerful interface for Drupal’s core taxonomy module for managing terms.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Extend Case Tracker Module</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Anthony Oliver</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jeff Eaton</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Make Case Tracker Module more like a project manager.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Designing a new core theme for Drupal</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Buddhika Amila Sampath</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Theodore Serbinski</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this project is to build an aesthetically pleasing core theme for Drupal.<br>
<br>
Despite the numerous elegant sites that have been created and beautiful themes developed, Drupal is perceived by many to be lagging behind other CMSs when it comes to 'look and feel'. One of the main strengths of Drupal could itself be the reason for this problem: flexibility. A generic theme will have to incorporate each aspect of Drupal whereas a typical site would only need 20% - 30% percent of these features. Also, designing without knowing the target audience, content and marketing goals is a difficult task, and the results may not be applicable to many situations.<br>
<br>
A good core theme would have to address the needs of applicability, customizability and flexibility to ensure easy adoption by the users. It will have to be usable, standards compliant, and accessible. Garland is a good example of how these goals could be achieved, and how effort put in to design could really pay off. It would be wonderful for both Drupal and Drupal users if there were more options to choose from, without compromising on the features. That's where a new core theme would be very useful.<br>
<br>
The project to create a new theme would be done in four phases:<br>
<br>
1. Initial Research: I will need to educate myself better on the Drupal project itself, the processes, the designers and their views, as well as the requirements of a core theme.<br>
2. Visual Design: Based on my initial understanding of the requirements, I will create the first mockup of the design. This would be improved through an iterative process where I would work closely with the mentor and the relevant experts and community members. As a relative newcomer to Drupal, I would need the guidance and assistance of Drupal designers to ensure the design meets the needs of the community.<br>
3. HTML Template: The finalized mockup would be converted to an HTML template. I would use valid, semantically correct XHTML markup, and valid CSS. Drupal has good accessibility features out-of-the-box[1], so I will make sure we improve on them.<br>
4. PHPTemplate theme:  In the final phase of the project, I will work on converting the HTML template in to a fully-fledged Drupal theme. As in earlier phases, I would rely on the assistance of my mentor and other Drupal experts to make sure the project has a successful result.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>SVG Drawing support for Drupal</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Balazs Dianiska</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Simon Hobbs</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 SVG is a modern vectorgraphic standard to handle graphics on the web. Drupal so far lacks both a general drawing API, and specific drawing APIs, like SVG, or GD. My goal is to implement<br>
<br>
a) a general drawing module, a geometry library, upon which I am intending to build an<br>
b) SVG drawing API.<br>
<br>
Clearly these two are a bit separated fields, the SVG drawing will require a well-thought basic geometry library, the drawing module.<br>
<br>
===Drawing API===<br>
<br>
A general, well-thought drawing API can make it easier for later toolkits (GD) to build graphic applications for Drupal. This API will include descriptions and definitions of basic shapes, primitives (lines, shapes, text) as well as a &quot;canvas management&quot;, the ability to handle multiple grouped objects.<br>
<br>
<br>
===SVG toolkit===<br>
<br>
I am looking forward to implement an SVG toolkit in Drupal, because I believe it has multiple features that this great CMS can use well. It is open, XML based, basically platform independent (though implementations might lack, but support is available in form of plugins for browsers where it is not built in), and vectorgraphic. Exploiting its capability for asynchronous transfer one is only limited by his/her fantasy what kind of graphically rich applications can be built upon it. Ranging from statistics display to geographic applications the limit is only the human mind.<br>
<br>
I personally also see a huge opportunity in helping the scientific community with this implementation - where the demand is often to search in big databases an interface displaying only the canged information can be extremely helpful. Providing new ways to display information and integrating it with Drupal CMS will make it easier for students to interact, to get involved in scientific projects, and also for research groups to interact and work together better.<br>
<br>
The SVG API will follow the 1.1 specifications, will have the functions for turning SVG on/off, handle the drawing and distorting of shapes.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>RSS/Atom Aggregation for Drupal Modules and Install Profile</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Aron Novak</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ken Rickard</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Project description<br>
<br>
There are at least five different modules in Drupal that deal with<br>
RSS/Atom aggregation and node creation in Drupal. All of these<br>
modules are slightly different with some sharing similar or the same<br>
parsers and others using the same third party parser. All of these<br>
modules may have something to offer, as well as may need the same<br>
missing pieces to become an ideal aggregator API.<br>
<br>
Work with the leech module itself proved the need for adaptive<br>
leeching - knowing how often to check a feed for new items based on<br>
the probability that the feed would have new items. This is needed<br>
because if you have 1,000 feeds and they are all checked on the hour<br>
every hour during cron, this causes problems. There are other modules<br>
that work to offer ways around this shortcoming, but this is just one<br>
example of where further improvement can be made.<br>
<br>
The project will include a review of features across this module<br>
pool, as well as consider ideas on how to improve some of the common<br>
problems these modules face. The end result will be the following:<br>
<br>
1) A review of the existing aggregator solutions and a matrix of<br>
their features.<br>
<br>
2) A consolidated aggregator module/API that takes the best features<br>
and aspects from the pool. This will answer some of the common<br>
challenges facing all aggregators, such as adaptive leeching, parser<br>
selection and capability, node creation, and feed item element<br>
handling (how to store which items within the Drupal architecture).<br>
<br>
3) An install profile to assist with the installation of the<br>
aggregator module, as well as complimentary modules for running a<br>
news tracking website.<br>
<br>
An additional positive result, though not the focal point of this<br>
project, will be more insight into caching needs with websites that<br>
aggregate and store a lot of information.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Scalability, Load Balancing, and High Availability</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Scott Hadfield</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Khalid Baheyeldin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project aims to provide new techniques for enhancing scalability and identifying bottlenecks in the Drupal project. In addition, I also hope to provide any resources necessary (including documentation, tools, and modules) to load balance Drupal across multiple servers and implement fail over servers.<br>
<br>
The three core aspects of this project are as follows:<br>
<br>
1. Develop a system to automatically load test Drupal sites.<br>
&nbsp;* Automatic generation of test data. There are a number of areas that may cause Drupal to slow down. Most modules will work smoothly until they have data they need to use. This tool will likely use and build on the generate scripts that come with the devel module to populate a site with test data. It will also incrementally add more data to the site, running benchmarks at each increment. This will help to identify modules that may work smoothly with a small amount of data, but degrade exponentially as data increases.<br>
<br>
&nbsp;* Build stress tests to run on the system. The stress tests will be targeted towards both specific modules and more general tests on an entire Drupal site. The SimpleTest module framework may be useful for building these tests.<br>
<br>
&nbsp;* Automatic testing of different combinations of modules. To determine which modules may be slowing down a site it can be useful to enable different combinations of modules to test against. This tool will automatically:<br>
&nbsp;&nbsp;1. enable modules one at a time<br>
&nbsp;&nbsp;2. enable each module by itself (dependencies will also be enabled)<br>
&nbsp;&nbsp;3. test groups of modules that are related. This will be based off of dependencies and user specified rules.<br>
&nbsp;After each iteration or change to the site, the site will be benchmarked and a report will be generated.<br>
<br>
2. Identify bottlenecks in Drupal core and submit patches to correct the issues. During testing of the above tools bottlenecks may be identified in Drupal core, core modules, and popular contrib modules. Patches will be written to help eliminate those issues. For more serious issues that can't be resolved with simple patches, recommendations will be made to resolve the issues.<br>
<br>
3. Provide resources to allow administrators to setup Drupal to scale horizontally across multiple servers and use fail over servers. This will come in the form of documentation, tools, and patches to help administrators configure their sites.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Drupal BitTorrent Tracker module</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christopher P. Bradford</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Károly Négyesi</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Drupal BitTorrent Tracker project looks to provide Drupal users the power of the BitTorrent protocol when moving large files from their website to their visitors. The main outcome of this project will be a BitTorrent “invisible tracker” that integrates with Drupal through a module. The module will allow for the addition and removal of torrents, IP address management (banning IP addresses or ranges) and statistical presentation concerning information about the tracker (current seeders, leechers, swarm speed, active torrents, etc.). Special emphasis will be placed on minimal database interaction and ease of use. A user of the website should be able to download a .torrent file and use their client of choice without the worry of tracker failure. The same ease of use should be available to the administrator who should be able to add and remove torrents as well as view statistics concerning the tracker in real-time. With this module, Drupal users will be able to offer secure, fast, and large downloads to their users.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Drupal automated staging toolkit project proposal</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Allister Beharry</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Rok Žlender</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Drupal automated staging toolkit is a proposed set of code libraries, file schemas and parsers, and code generators, for automatically creating a Drupal site with specific module code versions, sample users and data, and a specific LAMP stack configuration for hosting the Drupal site. The toolkit also has the ability to stage this generated site on an existing physical server location, and also as a self-contained virtual machine consisting of a minimal Linux environment, required LAMP software, and the Drupal site.<br>
<br>
The automated staging toolkit is designed to be part of an automated unit- and regression testing environment, by providing testers with a simple, fast way to automatically generate a complete Drupal site running specific code versions, and using specific LAMP server configurations. It is also intended for use as part of a performance and scalability testing environment by providing the ability to rapidly build and then benchmark the effects of different application, web and database server configurations on Drupal site performance and scalability.<br>
<br>
This toolkit will be used in the following way:<br>
1. The tester creates or reuses an XML(or other structured) file using a schema describing the Drupal site code-tree, including modules installed/enabled/disabled, and the versions of each module to be used.<br>
2. The tester creates or reuses an XML file using a schema describing           the LAMP stack web server, PHP/application server, and database server configuration; e.g Apache vs. Lighttpd, mod_php vs.FastCGI, choice of op-code cache, MySQL vs. PostgreSQL, and so on.<br>
3. The tester creates or reuses an XML file using a schema describing the sample users and content data the site will contain.<br>
4. The parsers take each file and generate scripts in a lightweight language (Python or Ruby or PHP-CLI.) These scripts, when executed, use functions in the code libraries to download Drupal modules, generate database scripts and datasets, and write server configuration files.<br>
5. Given a physical server target location, the Drupal modules, database scripts and server configuration files are deployed to the designated server location, to produce a new, ready-to-test Drupal site.<br>
<br>
Time and resource permitting, a builder in the toolkit will also use the generated Drupal site and servers' configuration as input to build a self-contained virtual machine image in Xen, VMWare, or potentially the Amazon EC AMI format. This virtual image can also be be used in testing environments, including advanced performance testing scenarios such as evaluating clustering, distributed database topologies, and alternative storage and computing models like Amazon S3 and Elastic Cloud. The ability to rapidly generate self-contained Drupal virtual machine images will also be extremely valuable to Drupal consultants and solution providers for marketing, prototyping and demonstrating Drupal solutions to potential clients, and large organizations and ASPs like CivicSpace looking to take advantage of the massive benefits of virtualization technology from VMware, Xensource, Amazon, and the like.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>SMS Framework</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>William L. White</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ian Ward</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The SMS Framework project will improve and expand the SMS technology integrated into Drupal powered applications and websites and make it easier to incorporate SMS elements into Drupal websites. To carry this project out, I will research existing SMS solutions for Drupal, identify shortcomings, and build a driver based API that can be ex-tended to work with common SMS service providers and integrated into Drupal core and contributed modules.<br>
An improved SMS framework for Drupal will enable individuals and organizations to seamlessly and easily combine elements of mobile and online campaigns on their Dru-pal websites. This will be very helpful to nonprofit, advocacy, and political organizations.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Auto Completion of links</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gartheeban Ganeshapillai</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kaustubh Srikanth</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Synopsis:<br>
&nbsp;&nbsp;Although drupal is selfsufficient for any corportate site<br>
&nbsp;&nbsp;development, having to search and find the internal references<br>
&nbsp;&nbsp;while preparing documents is a drawback in using it for a site<br>
&nbsp;&nbsp;full of articles and documents like Wikipedia. My project<br>
&nbsp;&nbsp;solves that by looking for keyterms in the text, and listing<br>
&nbsp;&nbsp;them categorized by the relevant key terms. This enables the<br>
&nbsp;&nbsp;user to maintain the line of thought undistracted.<br>
<br>
Benefits to Community:<br>
&nbsp;&nbsp;I believe this will make drupal more user-friendly,<br>
&nbsp;&nbsp;especially document-writer-friendly and reduces the time spent<br>
&nbsp;&nbsp;in searching for internal references and let the user worry<br>
&nbsp;&nbsp;about the content than the connections.<br>
<br>
&nbsp;&nbsp;The project can be tested for its success based on the<br>
&nbsp;&nbsp;fulfillment of the requirements described above,<br>
&nbsp;&nbsp;compatibility with most of the browsers and the<br>
&nbsp;&nbsp;adoption of the service by the drupal community, which<br>
&nbsp;&nbsp;I never doubt.<br>

	</div>
 </td>
 </tr>
</table>
<a name='dspace' />
<h2> dspace </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Statistics</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Federico Paparoni</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Richard Jones</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Statistics interface will provide a complete overview about informations published on the DSpace platform.<br>
<br>
It will be possible to know all the stats related to the user visit, for example:<br>
<br>
- Number of hits per day/month<br>
- Number of pages per day/month<br>
- Popular pages<br>
- Number of hits per page<br>
- Number of hits per Community<br>
- Number of hits per Collection<br>
- Number of hits per Item<br>
<br>
Upon these informations it is possible to create different views.<br>
<br>
To provide these informations, there is a simple API, that can be used everywhere in the DSpace platform. The basic object for this API is LogEvent, a class that maps the standard informations for an event system.<br>
<br>
Informations about events are saved into the DB and then there different way to show these statistics, in a simple and configurable way.<br>
<br>
It will be saved also informations about user of the website, using MaxMind - GeoIP Java API (http://www.maxmind.com/app/java).<br>
<br>
All the informations collected by this application will available under different formats.<br>
<br>
At the URL http://wiki.dspace.org/index.php/Google_Summer_of_Code_Statistics is available detailed description of the project<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>DSpace Versioning</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Robert Graham</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mark Robert Diggory</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will create a branch to the DSpace codebase representing the effort to support versioning among Items. Versioning here is a linear series of revisions and not various representations of the same content. This is a very commonly requested feature among users of DSpace and the whole effort is in line with the recommendations of the DSpace Architecture Review Group.<br>

	</div>
 </td>
 </tr>
</table>
<a name='eclipse' />
<h2> eclipse </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Improve multi-monitor support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Benjamin Muskalla</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kimberly Horne</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 With the price of computer monitors dropping, more and more people choose to work in a multi-monitor environment.  Working in this way can be very helpful when there are large quantities of information you need to process  at one time.  One of the best examples: software development. Working on projects in Eclipse on a dual or triple screen display is possible – but not that efficient as with other IDEs out there.  Though useful, detached views become difficult to work with when you have many of them.  Detaching multiple views (to move to to another screen) is an easy task – but to arrange them, you need to do it manually. It should be possible to have the same functionality that is exposed in the workbench:  sashes!<br>
<br>
Another common task for an application today is a fullscreen mode. As seen in other development environments, this can help to concentrate on the source code itself instead of being distracted by all the views, icons and other things around the editor area. Also, the size of the editor component can be improved by disabling the toolbar, statusbar and window border in fullscreen mode. This is not only useful with multi monitor setups but also for single monitor environments.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Plug-in Dependency Visualization</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Robert Ian Bull</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Chris Aniszczyk</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Understanding dependencies between plug-ins in Eclipse is a complex task.  The current plug-in dependency analysis tools available in Eclipse are restricted to simple tree views with drill-down support.  Throughout this summer, I propose to add visualization support to the Eclipse Plug-in Development Environment (PDE) in order to help provide cognitive support to developers as they analyze their plug-in dependencies.  I intend to complete the plug-in view that I started in the fall of 2006 by adding new dependency filters, improved navigation support, and the ability to highlight plug-in dependency analysis paths.<br>
<br>
This project proposal serves two purposes. Firstly, in brings plug-in visualization to the PDE, and secondly, it provides exemplary tools for the Zest framework.  Zest is an Information Visualization Toolkit for Eclipse.  While Zest was initially developed to provide visualization support for Mylar, its usefulness is now being realized in several Eclipse projects. By creating exemplary tools based on Zest, this will improve the visibility of Zest and ultimately bring a lightweight visualization framework to the Eclipse platform.<br>
<br>
Deliverables:<br>
Complete the PDE View and add 3 plug-in filters:<br>
&nbsp;o Filter by JRE Version<br>
&nbsp;o Filter by Enabled / Disabled<br>
&nbsp;o Filter by Regular Expression (on bundle name)<br>
<br>
Add dependency path analysis (show why a plug-in is required by highlighting dependency paths).<br>
<br>
Add improved navigation support<br>
&nbsp;o Forward and back button support<br>
&nbsp;o Add search support for the list of show plug-ins<br>
<br>
Currently, views that depend on GEF cannot be shipped with the Eclipse platform.  I intended to complete a full refactoring of the plug-in view to remove all GEF related dependencies, relying solely on Draw2D.  Once this is completed, I will investigate the possibility of making the plug-in available in the Eclipse Platform (either as part of the SDK or as a separate download) along with the Draw2D jars.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Eclipse Web Interface</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Michael William Robb</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Nick Boldt</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project aims to add the ability to externally invoke commands in Eclipse via a web browser.<br>
<br>
For example, this could enable a site to provide a link which would cause Eclipse to fetch and open a source code file in a single click. A sample link might look similar to the following:<br>
<br>
&lt;a href=&quot;http://localhost:56789?command=open_file&amp;filepath=http://someWhereOnTheWeb/foo.java&quot;&gt;open this file in Eclipse!&lt;/a&gt;<br>
<br>
Eclipse will listen for these requests and, when received, invoke the command in one of the currently running Eclipse instances.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Provide an Eclipse IDE generation environment derived from a language grammar</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Miguel Garcia</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ed Merks</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I plan to extend Chris J Daly’s Gymnast (described in Language Toolkits Technology Exchange, EclipseCON 2005) so that it supports:<br>
<br>
a.1) generating EMF-compliant classes for Concrete Syntax Tree nodes. With that, using OCL (Object Constraint Language) becomes possible to check the well-formedness of CSTs before transforming them to ASTs. The author of such transformation may thus employ QVT-style technology, e.g. ATLAS ATL.<br>
<br>
a.2) generating an LPG grammar in addition to those already supported (ANTLR and JavaCC).<br>
<br>
a.3) generate a visitor to unparse a CST into a pretty-printed representation, re-using hints specified in the existing Gymnast grammar format. For example,<br>
<br>
sequence ifConstruct :<br>
&nbsp;&nbsp;&nbsp;&nbsp;“if” expr<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;“then” expr<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;“else” expr<br>
&nbsp;&nbsp;&nbsp;&nbsp;“endif”<br>
<br>
would result in unparsing following a similar layout.<br>
<br>
<br>
a.4) generate a text editor with usability features. The design patterns to generate have been harvested while implementing the Emfatic extension for EMF Generics. These usability features include:<br>
<br>
Outline view, Mark occurrences, folding,<br>
Hovers displaying declaration for a given usage,<br>
Live problem and warning markers, Navigable hyperlinks,<br>
“File New” wizard, AutoEdits such as SmartBrace (i.e. automatically completing with a closing terminal),<br>
User-provided templates,<br>
Syntax-aware Content Assist.<br>
Refactoring will be explored (at the very least, by updating usages-for-declarations)<br>
<br>
A common theme consists in making the most out of the input specification. For example, the type-checking rules for expressions in a DSL are usually not specified declaratively. OCL (Object Constraint Language) can uniformly be used to specify static semantics and type-checking rules, as shown in:<br>
http://www.sts.tu-harburg.de/~mi.garcia/pubs/2007/mdsdHeute/garcia-emfgen-2.pdf<br>
<br>
Tips on processing OCL are reported in my Eclipse Technical article (under review), at:<br>
https://bugs.eclipse.org/bugs/show_bug.cgi?id=167543<br>
<br>
Once the extensions a.1) to a.4) have been implemented, an IDE for Gymnast will be bootstrapped with the Gymnast generator. Additionally, a case study will be undertaken to validate the approach, i.e. an IDE will be generated for one of:<br>
<br>
b.1) an ExecutableUML-style language but EMF-based<br>
<br>
b.2) EJB3QL, building upon the metamodel described in<br>
http://www.sts.tu-harburg.de/~mi.garcia/pubs/atem06/ EJB3QLpaper.pdf<br>
<br>
b.3) a human-readable notation for UML2<br>
<br>
Preparing developer documentation (and community articles) is an integral part of the planned tasks.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Framework to develop simple Eclipse plugin using PHP</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Toomas Römer</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ahti Kitsik</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Framework to develop simple Eclipse plugin using PHP. Create a framework that could support developing simple Eclipse plugin using a PHP To Java bridge (Like Caucho's Quercus and other JSR 223 engines). Develop and document a sample plugin in PHP, so that PHP developers could create simple plugins.<br>
<br>
The idea is taken from the Eclipse SOC 2007 Ideas page http://wiki.eclipse.org/index.php/Google_Summer_of_Code_2007_Ideas<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improve Mylar&#39;s new users experiences</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Balazs Brinkus</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mik</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Project title: Improve Mylar's new users experiences<br>
<br>
Project description:<br>
<br>
The project's goal is to write a plug-in which presents for the new users Mylar from the basics to the every days use. And for the other users it will help too with the built-in help.<br>
<br>
The plug-in contains:<br>
* a welcome page which contains:<br>
&nbsp;* new &amp; noteworthy information<br>
&nbsp;* tutorials<br>
&nbsp;* in the overview menupoint a link to the Mylar description text<br>
&nbsp;<br>
* cheat sheets which show the use of Mylar through examples:<br>
&nbsp;* each presentation of the 3 views (task list, repositories, activity) (properties and basic using)<br>
&nbsp;* focus working<br>
&nbsp;* connecting to the database and adding new repository (to all connectors)<br>
&nbsp;* adding new query<br>
&nbsp;* modifying query<br>
&nbsp;* opening, activating, synchronizing task<br>
&nbsp;* making and using local tasks<br>
&nbsp;* categorizing the tasks<br>
<br>
* filling the built-in help from the wiki page informations:<br>
&nbsp;* User Guide<br>
&nbsp;* FAQ<br>
&nbsp;* Tips &amp; Tricks<br>
&nbsp;* Information for the developers: references, components description<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Java Executable Wrapper Plugin for Eclipse</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Zhang, Rui</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Gunnar Wagenknecht</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 After we written a java application by Eclipse, we should type a command like &quot;java myapp.class&quot; or &quot;javaw -jar myapp.jar&quot; to run our application. Though we can write a .bat file on Windows or write a shell script on Linux to do the job, it feels not very convenience.<br>
<br>
The aim of this project is to develop a plugin for Eclipse to wrap compiled Java applications and give out a excutable file. It is supposed to support both Windows and Unix-like Systems.<br>
<br>
There are some similar tools:<br>
1.exe4j(http://www.ej-technologies.com/products/exe4j/overview.html). Exe4j can integrate Java applications into the Windows operating environment. It is a business software and it need to pay to get a license.<br>
2.JSmooth(http://jsmooth.sourceforge.net/index.php). JSmooth is also a Java Executable Wrapper. It also creates native launchers on only Windows operating system. JSmooth is free software under GPL.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Test Message Generator for the Eclipse Open Health Framework</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Srdan Bejakovic</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Marcelo Paternostro</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently, there are several large efforts to develop a comprehensive IT healthcare infrastructure that would allow interoperability and sharing of information within and across healthcare organizations and regions. The Eclipse Open Healthcare Framework (OHF) is an open-source approach to this problem that relies on Eclipse's tooling environment.<br>
<br>
I propose to build a token-based XML generator that allows the mass generation of messages for test purposes, a project within the scope of the OHF. These test messages have to be manually generated right now, and providing this feature would help ensure that messages and their models are effectively tested before being officially released to healthcare application vendors. This testing is particularly essential in healthcare, where errors can cost lives.<br>
<br>
This project would extend the Message Instance Editor, an OHF tool produced by the Health Level 7 (HL7) V3 Eclipse Tooling group (H3ET). The Message Instance Editor is used by international standards bodies such as HL7 and governments (the UK National Health Service) to generate, edit, and validate healthcare messages that conform to the HL7 version 3 specification. Users of the Message Instance Editor have requested the ability to generate batches of example messages based on the schema-like constraints imposed by the HL7 Model Interchange Format (MIF). Therefore, my project would:<br>
<br>
&nbsp;&nbsp;&nbsp;1. Create an XML representation of an example message template.<br>
&nbsp;&nbsp;&nbsp;2. Create a new wizard that would allow a user to generate example   messages based on the template and HL7 message models (from a MIF file).<br>
&nbsp;&nbsp;&nbsp;3. Allow replaceable tokens to be defined within example message templates that are replaced by example data.<br>
&nbsp;&nbsp;&nbsp;4. Allow configuration and declaration of these tokens.<br>
&nbsp;&nbsp;&nbsp;5. Allow the user to configure the behavior of the batch message generation.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>WebDAV EFS Implementation</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Reid Holmes</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Gunnar Wagenknecht</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will implement an EFS implementation for WebDAV to allow Eclipse platform users to use remote WebDAV repositories as mount-points for projects and files. This will benefit any user of Eclipse who wants the flexibility to store their files in this way. Being able to treat remote repositories as if they were local is beneficial to many development groups including web designers, server-application developers, and anyone creating Eclipse plug in update sites.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Mylar synchronous context sharing, based on Mylar and ECF integration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jevgeni Holodkov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mik</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This is about Mylar synchronous context sharing among team members by means of Mylar and ECF integration. The goal of such context sharing is to provide more seamless knowledge sharing process, allow sharing context synchronous even if the used connector does not support context sharing or no connectors used at all.<br>
<br>
The synchronous context sharing means that it is possible to share context on fly with a friend who is currently online and you are discussing some issue. It will be possible to create a task for new context or assign this context to an existing one.<br>
<br>
Technically, the solution will use ECF to handle all communication details. I will try to employ current Mylar’s context sharing functionality. This solution will provide SWT-based user-interface for context sharing and I will also include the rainy scenarios handling, such as “no connection with friend” or “file resources are out of sync”.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Eclipse search plugin: providing a better, faster, more relevant Eclipse search.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Çağatay Çallı</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Francois Granade</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Background:<br>
Searching is one of the most commonly used features of Eclipse. However, this feature has mediocre performance compared to text processors like VIM or Emacs. In some cases, like searching for a string in compressed Javascript files (the whole file is one big line), lack of a good search tool becomes prominent.<br>
<br>
Purpose:<br>
Aside from quirks in text search that need to be fixed, like the case of files that are not well-structured (e.g. compressed Javascript files in one line), other improvements can be done by integrating the search process with Google Code Search and other resources.<br>
<br>
Developing an Eclipse search plug-in that improves performance and relevance is the main concern. By proper integration with online code repositories, this tool will also speed up learning and code observations within Eclipse itself.<br>
<br>
Project Description:<br>
<br>
Inspecting and making use of Lucene, OpenGrok and other search tools and algorithms, I'm planning to create a plug-in that can speed up text-based search in Eclipse.<br>
<br>
When the search plug-in reachs maturity, I want to enable support for Google Code search and support for other possible code repositories. For this feature, I'm going to create a mechanism to add more repositories as search locations (example: adding new websites to Firefox search bar). These repository info files will be easy to compose and the plugin would enable composing such files. At last, I intend to support CVS code search.<br>
<br>
Project Schedule:<br>
<br>
Today to May 1 - I'm going to focus on research about existing defects, possible algorithms to apply and learning about Lucene, OpenGrok and other new solutions to the problem. I'll try to code crude prototypes of these possible solutions.<br>
<br>
May 2 to May 22 - After discussing possible solutions with my mentor,  I'll identify the solution approach and organize myself to code that solution<br>
<br>
May 23 to July 16  - I at least expect to see a basic search tool that works fast and provides good results when it works (in the use cases I have finished implementing). After the midway evaluation of my mentor at July 16, I'll know which parts to improve from this point.<br>
<br>
July 17 to August 1 - In the light of my mentor's advice, I'll focus on fixing important weaknesses of the tool. Upon fixing these weaknesses, I'll try to prepare further documentation for other developers.<br>
<br>
August 2 to August 20 - I will be implementing prototypes of extra features such as integration with Google Code search and CVS code search support. As I plan to always keep myself focused on the correctness of core features of the plug-in, I will test these core text search features further.<br>
<br>
August 21 to August 31 - Upon receiving final feedback from my mentor, I'll polish the online/repository search capabilities of the plug-in in the first week of this period. In the remaning time, I'm planning to test,fix,document and discuss the beta version of the plug-in with the community.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Add the ability to write plugins using jruby or groovy.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Anton Arhipov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Wayne Beaton</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Groovy is ideal choice for a seasoned Java developer for its speed of prototyping and flexibility for development. As in case of Eclipse support for Groovy plug-in development, the biggest benefit of on-the-fly plug-in code writing/changing, as one don't have to start a separate Eclipse instance while testing my plug-in under development. This would rapidly improve the speed of lightweight plug-in development.<br>
<br>
This project aims to add ability to write plugins in JVM-based scripting language, like Groovy and JRuby. But it could be a starting point for any other JVM scripting language, like BeanShell or Jython.<br>
<br>
The main results to be reached:<br>
- An Eclipse extension/plug-in to (re)load (Groovy) scripts on the fly.<br>
- Command line console support. (This could look like in case Apache Derby ij plug-in)<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Support seamless debugging between JDT and CDT (Java &lt;&gt; JNI &lt;&gt; C)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mariot Chauvin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Philippe Ombredanne</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Eclipse is an extensible framework to build modular applications, which relies on OSGi component architecture. Originally developed to provide an IDE extensible in terms of functionalities and supported languages with plugins, Eclipse can now be used as a Rich Client Platform (RCP). The success of the Java Development Toolkit (JDT) plugin has leaded the development of numerous plugins. For instance the C/C++ Development Toolkit (CDT) plugin allows developers to use it as IDE for project in C or C++ language. The use of Eclipse as a generic IDE is possible due to the notion of perspective (a perspective corresponds to a certain disposition of the graphical elements) which adapts the user interface to the kind of project.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Java Native Interface (JNI) is a programming interface to call native methods or to embed java virtual machine in native applications. JNI is often used to interact with existing native application, to add platform-specific functions, or to improve time-performance (by supposing native methods faster than java code).<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Currently, when users work on a java project using JNI and native code, they have to switch between perspective, which is not practical. Another point to improve is the debugging of this kind of project, by allowing developers to follow native method calls into native code and go back.<br>
<br>
* Goals of the project<br>
&nbsp;&nbsp;&nbsp;&nbsp;- create new or &quot;mixed&quot; perspectives to manage project using C/C++ and Java<br>
&nbsp;&nbsp;&nbsp;&nbsp;- add the possibility to follow native methods calls into native code<br>
<br>
* Roadmap<br>
&nbsp;&nbsp;&nbsp;&nbsp;- Announce the project and check the existing work (see http://cdtdoug.blogspot.com/2006/09/jdtcdt-cant-we-just-get-along.html). Get feedback from CDT and JDT community and discuss with them about the project [until May 28]<br>
&nbsp;&nbsp;&nbsp;&nbsp;- Implement the work on perspectives first and then the native method calls follow-up [until beginning or mid of August]<br>
&nbsp;&nbsp;&nbsp;&nbsp;- Integration and tests with the help of the Eclipse community<br>

	</div>
 </td>
 </tr>
</table>
<a name='eff' />
<h2> eff </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Fixing Tor Server&#39;s Windows Buffer Problems</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christian King</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Nick Mathewson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Tor is an important tool for maintaining privacy on the Internet. Too keep the Tor network healthy, many servers are required. With many homes having ready broadband access, even relatively non-technical people have the ability to contribute. This bug effectively prevents these people from participating, cutting off a large source of servers for the Tor network.<br>
<br>
I propose to fix this bug by adapting libevent to the Winsock API (instead of using select()) in such a way as to use overlapped IO and fix the buffering problem. As part of this process I will develop a stress tester (probably in conjunction with TorFlow) for use not only with this bug, but for regression testing and performance-based stress testing.<br>
<br>
These changes would be written in the languages required to interface with existing code - C for Tor and libevent, python for the stress testing client (with TorFlow), and documentation, coding style and testing standards would be maintained.<br>
<br>
For more information on this bug, see: http://wiki.noreply.org/noreply/TheOnionRouter/WindowsBufferProblems<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Distributed Storage for Tor Hidden Service Descriptors</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Karsten Loesing</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Roger Dingledine</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Tor provides a mechanism for responder anonymity via hidden services. As a part of these, Tor provides storage on its central directory servers to allow publishing and retrieving rendezvous service descriptors. This proposal suggests to replace the centralized approach by a distributed storage of descriptors to the larger set of onion routers. Benefits include (1) better load balancing which is vital for the further growing of the network, (2) a more scalable way to publish descriptors, and (3) extensibility of hidden services to features like human-readable names or client authentication. As possible drawback can be seen that new threats arise due to decentralization that need to be discussed and handled.<br>
<br>
In this project a structure is applied to the network of onion routers, based on concepts known from distributed hash tables and consistent hashing systems. Every participating router is made responsible for a limited set of descriptors. It is not necessary to maintain an own routing table, but possible to rely on the router list managed by the Tor directory. Some amount of replication needs to be added to overcome node failures and untrustworthy routers. This prevents the worst security threats, as descriptors are signed and have a limited time-to-live. Thus, they cannot be forged or replayed. Preliminary measurements show that routers exhibit a very low churn rate which makes them a perfect field for consistent hashing. The purpose of this project is to extend the current Tor sources to a running prototype that contains a distributed storage of rendezvous service descriptor.<br>

	</div>
 </td>
 </tr>
</table>
<a name='etherboot' />
<h2> etherboot </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Port gPXE to ARM architecture</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alexey Zaytsev</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Brown</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The gPXE, while designed to be portable, currently only<br>
runs on the ia32 and the ia64 cpus. Yet it's still<br>
desirable to get it running on some of the other platforms,<br>
like the ARM.<br>
<br>
I'm willing to port the gPXE to the ixp42x cpu family, adding<br>
support for the Intel IXP42X Development Board and maybe a<br>
number other popular devices based on this cpu.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>16-bit i386 backend for gcc</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Daniel Verkamp</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>H. Peter Anvin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 GCC currently only supports generating 32-bit code for the i386 platform.  Etherboot requires 16-bit real-mode code in some places, some of which is written in C.  Currently, this is accomplished with a hack (.code16gcc), but this produces larger code than necessary.  My proposed project is to add a 16-bit i386 backend to GCC to obviate the need for this hack and reduce code size.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>porting Etherboot drivers to gPXE</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Udayan Kumar</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Martin Connor</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 gPXE is a rewrite of Etherboot project  with several major improvements. One of the goals, is to update Etherboot network interface card drivers to work with gPXE. This will require making API changes to allow existing drivers to work with the new gPXE API.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Reducing Code Size</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Holger Lubitz</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Brown</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This proposal is based on the ideas for reducing code size which have been posted on the Etherboot Project ideas page.<br>
<br>
The ideas presented there are<br>
<br>
a) using gcc function attributes where applicable to allow further optimizations, possibly looking into register parameters as well<br>
<br>
b) looking for symbols not referenced outside their object, making them candidates for either static declaration or elimination<br>
<br>
My first step would be setting up a code xref tool like LXR or OpenGrok, to get a better feel for the control flows and general structure, as well as the most used functions.<br>
<br>
Then the above ideas would be tested for their potential of code reduction. For the functions, this would probably mean going through the list one by one, looking if they are candidates for pure, const, regparm, maybe even noinline, nonnull or the like. As already mentioned on the ideas page, I expect a lot of experimentation in this phase to find out what helps and what doesn't.<br>
<br>
Time and resources permitting, as a third step general code profiling could help identifying functions with potential for further reduction in size.<br>
<br>
If those ideas turn out to be viable, the result should be a patch set to include the attributes and static declarations, which hopefully delivers a notable reduction of code size.<br>

	</div>
 </td>
 </tr>
</table>
<a name='exist' />
<h2> exist </h2>
<table>
 <tr>
 <th>Title</th>
 <td>XQuery API for Java</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Chérif  B. YAYA</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Adam Retter</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of the project is to implement a driver that enables developers to access an eXist Xquery engine from a Java application. The implementation will follow version 1.0 of the XQuery Api for Java which attempts to provide a common way for Java developers to interact with XQuery engines. Over the years, XMl has become the predominant data interchange format and the eXist library provides developers with an easy and powerful way to manage, store and query their XML based databases. I believe that an XQJ driver for the eXist library will prove to be very valuable for the open source Java community as well as the eXist community.<br>
<br>
An eXist Database can be deployed essentially in two ways : either as en embedded library that runs in the JVM of the client application or as a standalone server possibly located on a remote host. A different XQJ driver is therefore needed for each one of those use cases.<br>
<br>
Deliverables : 2 XQJ driver packages for eXist engines<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&gt;A local connection driver to be used when accessing an embedded eXist database<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&gt;A remote connection driver to be used for remote standalone eXist databases<br>

	</div>
 </td>
 </tr>
</table>
<a name='fann' />
<h2> fann </h2>
<table>
 <tr>
 <th>Title</th>
 <td>VFANN ( Vector Fast Artificial Neural Netwoks)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Vincenzo Di Massa</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Seth J Price</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this project is to develop a vector version of FANN which can take advantage of modern CPUs like those implementing SSE or similar technologies.<br>
Another goal of the project will be to add utility apps/functions/scripts in order to make using FANN easier. A fann_trainer script or application will be in good shape at the end of the project and will be capable of training different kind of network with appropriate algorithms.<br>
If projects for a FANN GUI are accepted I'll collaborate with the other student in order to make the utilities well integrated.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Self-Organizing Maps and Growing Neural Gas</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Zsolt Kira</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Steffen Nissen</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Competitive artificial neural networks have increasingly become popular for visualization and clustering of the large amounts of data existing in many scientific fields.  They are also used for pattern recognition, image analysis, and many other applications.   This project will add Self-Organizing Maps and a similar dynamic algorithm called Growing Neural Gas into the FANN library.  The implementation will be coded so as to support extensions such as adding multiple learning rules<br>
and neighborhood functions, and include features such as calculation of quantization error and other metrics.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Native GUI</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Yusef Maali</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Seth J Price</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My background on the subject:<br>
At my university, I've started to collaborate (as co-developer) to an open-source project: HuMoR. It is an intelligent video surveillance application, with a (working-in-progress) GUI to manage the HuMoR core.<br>
It is written using the QT libraries and, thanks to HuMoR, I have acquired a good knowledge of QT and its philosophy.<br>
Right now I have good skills in C++, QT coding and UI design.<br>
<br>
Using QT became possible to have also a real cross-platform native GUI, especially with QT4 (windows, linux, macOs).<br>
&nbsp;<br>
Goal:<br>
My objective is to create a user-friendly cross-platform native GUI using Qt4 libraries.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Neural Networks on the GPU</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Lars Johan Samuelsson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Seth J Price</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will implement both representation of a neural network and the execution of it on the GPU as well as a training algorithm. This will hopefully speed up the FANN-library that already is a fast lib. To accomplish this i will use GLSL to maintain the platform independence.<br>

	</div>
 </td>
 </tr>
</table>
<a name='fedora' />
<h2> fedora </h2>
<table>
 <tr>
 <th>Title</th>
 <td>An upstream-friendly l10n Web UI for Fedora</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Dimitris Glezos</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Karsten Wade</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The most important process of the Fedora Localization Project is the translation of Fedora resources (applications, documentation, websites, etc.) in various languages. Contributors identify a resource that needs translation, receive the respective `PO`-file, translate it, and commit the changes to our Source Code Management (SCM) system.<br>
<br>
The system currently used allows translations of resources hosted on the same system but not on other systems, such as the main SCM of Fedora or remote SCMs.<br>
<br>
Our goal is to build a platform that will facilitate localization processes of the Fedora L10N Project and other l10n communities. I will pursue this by deploying a Web User Interface for translation statistics which will also give translators seamless access to upstream-hosted translation files. This automation will benefit both the Fedora L10N Project in terms of usability and the upstream projects in terms of translation completeness.<br>
<br>
The full application can be found at: http://fedoraproject.org/wiki/SummerOfCode/2007/DimitrisGlezos<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>An offline package update/installation facility for Pirut.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Debarshi Ray</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sankarshan Mukhopadhyay</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I would like to develop an enhancement to Pirut that will enable users, who do not have the necessary bandwidth to download packages from the Internet, to install and update from packages downloaded on a different machine having better connectivity. This is inspired from one of last year's accepted proposals mentored by Ubuntu [1].<br>
<br>
[1] https://wiki.ubuntu.com/OfflineUpdateSpec<br>

	</div>
 </td>
 </tr>
</table>
<a name='ffmpeg' />
<h2> ffmpeg </h2>
<table>
 <tr>
 <th>Title</th>
 <td>RV40 decoder</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Kostyantin Sergiyovich Shishkov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Melanson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Real Video 4 is one of Real Video family codecs. It is believed to be based on some standard (H264?) or standard draft.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Matroska Muxer for libavformat</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>David Robert Conrad</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Aurélien Jacobs</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Matroska is a container format that's capable of holding almost any combination of audio and video codecs. It has recently been gaining popularity. FFmpeg is perhaps the world's largest open-source multimedia solution, found at the heart of many media players. This project aims to write a simple Matroska muxer in C for FFmpeg's libavformat. This will better enable the creation of Matroska files from the many applications that utilize FFmpeg.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Video Filter API</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Robert Bingham</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Benjamin Larsson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 FFmpeg's libavcodec library has become the de facto standard library for video decoding and encoding in free software projects.  Unfortunately, no similar standard library has surfaced for filtering and otherwise working with video once it has been decoded.  Various projects (MPlayer [1], Xine [2], GStreamer [3], VirtualDub [4], etc) have implemented their own systems to various degrees of success.  What is needed is a high quality video filter API - efficient, flexible enough to meet all the requirements which have led various projects to invent their own system, and yet easy to use or develop new filters with.  FFmpeg is already well-known for its libavcodec.  This proposal is to implement a high quality video filter library for FFmpeg, where it can be easily used by other video-related software projects.<br>
<br>
1. http://svn.mplayerhq.hu/mplayer/trunk/DOCS/tech/libmpcodecs.txt?revision=15625&amp;view=markup<br>
2. http://xinehq.de/index.php/hackersguide#AEN864<br>
3. http://gstreamer.freedesktop.org/data/doc/gstreamer/head/pwg/html/index.html<br>
3. http://www.virtualdub.org/filtersdk<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>E-AC3 Decoder</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bartlomiej Wolowiec</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Justin Ben Ruggles</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 AC-3 was created to support multi-channel high quality sound. It mostly contains five channels (Right front, Center, Left Front, Right Rear and Left Rear) and one special channel for low frequency effects, but the number of channels may be various. Since early 90s it have been used in many cinemas, it also used on DVD-Video and HD-DVD. Because of the popularity of this codec, it is very important to make good implementation of it in projects such as ffmpeg. And that's why I decided to work on ac3 decoder.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>The JPEG2000 deocder and encoder</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Kamil Nowosad</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Loren Merritt</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 JPEG2000 is an image compression standard. It was created to supersede the discrete cosine transform used in standard JPEG. The new algorithm is based on the wavelet transform. The lossless - by the use of reversible wavelet transform, and lossy - by the use of the CDF 9/7 wavelet transform. The main advantages of the standard are:<br>
- superior compression performance (much higher than in JPEG, especially at high bit rates)<br>
- support progressive transmission by pixel and resolution accuracy, which is very useful when publishing images in the Web<br>
- flexible file format<br>
<br>
FFmpeg is an open source tool that can convert multimedia formats. It is highly portable. Most codecs it supports are coded from scratch to provide the best performance.  It is widely used in other open source projects, such as mplayer, xine or videolan.<br>
<br>
The goal of my project is to implelement JPEG2000 encoder and decoder in FFmpeg, so that it can be used by the open source community. Although its advantages, the format has not yet become very popular. My project will surely help to change it.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Dirac encoder and decoder</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Marco Gerards</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Luca Ugo Maria Barbato</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 During this project I will implement a decoder and encoder for Dirac<br>
for ffmpeg.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Applying for the soc programme of ffmpeg</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Xiaohui Sun</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Baptiste Coudurier</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Implementing a MPEG TS/DVB Muxer, which comforming to the specification ISO 13818-1.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>QCELP decoder</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Reynaldo H. Verdejo Pinochet</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Benjamin Larsson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 To write a libavcodec decoder for Qualcomm's 'Code excited linear predictive coding' speech/voice codec as is commonly found in 3g2 and mov files, using the reference source, shared by the company while developing it and the published standard. Efforts will be made for optimizing the resulting decoder to make it usable on constrained or low end hardware.<br>

	</div>
 </td>
 </tr>
</table>
<a name='fityk' />
<h2> fityk </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Improving Fityk GUI</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Diaa Mahmoud Sami Abdel-Ghani</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Marcin Wojdyr</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 There's a lot of room for GUI improvements in Fityk, this project aims to fix existing issues, and add some improvements to make the GUI more usable and intuitive.<br>

	</div>
 </td>
 </tr>
</table>
<a name='freebsd' />
<h2> freebsd </h2>
<table>
 <tr>
 <th>Title</th>
 <td>GNOME front-end to freebsd-update(8)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andrew Turner</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Joe Marcus Clarke</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will build a front-end to freebsd-update using GTK+. It will be designed in<br>
two parts: a daemon that waits for freebsd-update to find new updates and the<br>
front-end proper.<br>
<br>
The back-end daemon will find when there are updates available. It will then<br>
tell the front-end about the updates that will display them and allow the<br>
administrator to install them.<br>
<br>
The back and front ends will communicate over either a local IPC or a network<br>
connection.<br>
<br>
The design will allow for multiple back-ends on different computers to allow<br>
one front-end to update headless servers.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Revise ports / package system database backend and implement unified interface</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Garrett Cooper</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kirill Ponomarew</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 What is FreeBSD?<br>
From the front page &lt;http://freebsd.org&gt;:<br>
FreeBSD® is an advanced operating system for x86 compatible (including Pentium® and Athlon™), amd64 compatible (including Opteron™, Athlon™64, and EM64T), UltraSPARC®, IA-64, PC-98 and ARM architectures. It is derived from BSD, the version of UNIX® developed at the University of California, Berkeley. It is developed and maintained by a large team of individuals. Additional platforms are in various stages of development.<br>
<br>
How does it run?<br>
Using a unified and integrated kernel / userland, providing a large amount of functionality to a large userbase. For any applications not included in the base system (kernel / userland), the applications must be installed via an infrastructure called &quot;ports&quot;, which are maintained by a group of volunteers. The ports system is constructed of multiple makefiles, predefined variables, and other items.<br>
<br>
A similar analog are packages, which are versioned tar files containing precompiled ports binaries, as well as system / userland precompiled binaries.<br>
<br>
Issues:<br>
<br>
Speed:<br>
There has been a great deal of discussion on the hackers at freebsd dot org list about the speed of the package / ports database being too slow (uses standard Binary Tree with BDB). One request (the primary one) is to take the Binary Tree based storage algorithm and convert it to a Hash Table format with BDB, which would greatly increase the search / insert time, to O(c) instead of O(log(n)) or O(n) in the worst case scenario.<br>
<br>
No unified frontend:<br>
There currently isn't a unified frontend in ports, requiring admins / users to install either management applications that require ruby (which depend upon perl, not in the base system) and tend to be slow, or a unix shell script version which provides ports management, but tends to break periodically.<br>
<br>
Base / ports dependencies break other ports:<br>
There are a number of different packages included in the base system as well as in ports, and there's some confusion in the underlying ports system when it comes to which installed system to use. Some examples are OpenSSL, OpenSSH, Kerberos 5, etc. There should be some simple virtuals / entries created to the underlying ports system to allow base and ports versions of libraries / applications from not conflicting with one another.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Super Tunnel Daemon</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Matus Harvan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Max Laier</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 IP can easily be tunneled over a plethora of network protocols at<br>
various layers, such as IP, ICMP, UDP, TCP, DNS, HTTP, SSH and<br>
many others. While a direct connection may not always be possible due<br>
to a firewall, the IP packets could be encapsulated as payload in<br>
other protocols, which would get through. However, each such<br>
encapsulation requires the setup of a different program and the user<br>
has to manually probe different encapsulations to find out which of<br>
them works in a given environment.<br>
<br>
The aim of this project is to implement the Super Tunnel Daemon, a<br>
tunelling daemon using plugins for different encapsulations and<br>
automagically selecting the best encapsulation in each<br>
environment. Should the environment change, the user would not notice<br>
the transition to a different encapsulation except for a small<br>
delay. Connections estabilished within the tunnel would seamlessly be<br>
migrated to a different encapsulation. In this way, mobility would be<br>
supported as well, even to the extent of changing between different<br>
physical network interfaces. New encapsulations could easily be added<br>
in the future using the plugin interface.<br>
<br>
The implemnation would be in C, use the tun(4) interface, multiplex<br>
between the tun device and the encapsulations with a select(2) and<br>
load plugins via dlopen(3).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Rewriting lockmgr(9)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Attilio Rao</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jeffrey Roberson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Rewriting lockmgr support for the FreeBSD kernel<br>
<br>
Recent analisys on FreeBSD scalability, evicted a number of kernel bottlenecks that should be solved someway. One of the hottest cames from the heavy lockmgr(9) syncronization primitive implementation*.<br>
<br>
The project will be focused on rewriting lockmgr on a lighter basis, using memory barriers (atomic(9)) and a direct usage of the sleepqueue(9) low level interface.<br>
This is alredy an ongoing effort, but some foundraising would speed up the development.<br>
<br>
* the lockmgr code demonstred very fragile at relatively simple changes too<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Apple&#39;s MacBook on FreeBSD</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Rui Paulo</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Andre Oppermann</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Apple's MacBook computers are nicely designed and have neat<br>
features that other laptops don't. While Mac OS X is a nice operating<br>
system, UNIX folks (like me) would prefer to run other operating<br>
systems like FreeBSD.<br>
This project aims to bring bug fixes and new drivers to FreeBSD that<br>
would help running this OS on this platform.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Getting gvinum up to standards</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ulf Lilleengen</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lukas Ertl</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Ulf Lilleengen<br>
lulf at stud.ntnu dot no<br>
Getting gvinum up to standards<br>
<br>
One year ago I sent a proposal to improve gvinum in FreeBSD. Although<br>
I did not get any sponsoring, I did a lot of work on it.<br>
Unfortunately, none of these changes has been imported into the code<br>
base due to lack of developers. One year later gvinum is even more<br>
important to get up to standards, because I have experienced even<br>
more users who have troubles with it. This is because it's not<br>
reliable enough and not correct enough for an old FreeBSD<br>
installation to be upgraded to the 6.x series yet. I want to change<br>
this.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>TCP/IP regression test suite</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nanjun</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>George Neville-Neil</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project is about to produce a program to test some devices' network performability by emulating remote TCP endpoint.  Based on prior work, the task may focus on designing test schemes and displaying the report on packet level in a comprehensive way.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>bus_alloc_resources() Code Update for FreeBSD</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christopher Davis</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Warner Losh</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Project Description<br>
<br>
Currently, many devices in FreeBSD's source tree use excessively verbose methods of resource allocation and deallocation. Numerous calls to bus_alloc_resource() or bus_alloc_resource_any() are used to allocate resources, and subsequently, multiple calls to bus_release_resource() are used to free the resources after an error in allocation or when the device is detached.<br>
<br>
Recently, however, the bus_alloc_resources() and bus_release_resources() functions have been added. These simple wrappers around bus_alloc_resource_any() and bus_release_resource() both operate on the same resource description, so that much of the repetition once needed to allocate and free resources can be mitigated.<br>
<br>
My project is to update driver source code where necessary using the new functions to make the code related to allocation and deallocation simpler and clearer, while making other refinements as needed.<br>
<br>
I will patch and test as many drivers as I can during the Summer.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>FreeBSD &quot;safety net&quot; IO logging utility</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Sonja Milicic</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lukas Ertl</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A kernel module that allows copy-on-write style logging of I/O requests and can be used as a &quot;safety net&quot; during critical file system operations.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improve the FreeBSD Ports Collection Infrastructure</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gábor Kövesdán</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Andrew Pantyukhin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 FreeBSD is a UNIX®-like operating system with lot of interesting and exclusive features. One of those is the FreeBSD Ports Collection, which provides easy installation, customization and management for third-party softwares. Official packages are also built from the Ports Collection. This proposal is about some new updates, immprovements and features for the Ports Collection infrastructure.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>http support for PXE</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alexey Tarasov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ed Maste</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Main purpose  of this project - to write extendable (as much  as possible - C) code wrappers to provided by PXE and UNDI APIs to support downloading of files via TCP-based protocols in preboot environment. Goal - to introduce  code, able to download and prepare booting of FreeBSD kernel from remote server via direct connection or http proxy.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Graphical installer for FreeBSD (finstall)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ivan Voras</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Murray Stokely</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The current FreeBSD's installer, &quot;sysinstall&quot; is more than 6 years<br>
old and way overdue for a replacement. This project will create a graphical install &amp; setup application for FreeBSD which aims to make use of a live on-CD system and specifics of the FreeBSD system.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Porting Linux KVM to FreeBSD</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Fabio Checconi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Luigi Rizzo</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Linux KVM is a Virtual Machine Monitor, part of the Linux<br>
kernel, that uses Intel VT-x or AMD-V extensions for x86<br>
processors to create a full virtualization environment.<br>
This project will consist in porting Linux KVM to the FreeBSD kernel.<br>
<br>
Since Linux KVM has a structure similar to that of a device driver<br>
(actually, it is a device driver, from many points of view,) core kernel<br>
changes will not be required, and the final product of this project will<br>
be an external loadable kernel module, exporting an interface based on<br>
ioctl() calls to a device descriptor.<br>
<br>
Part of the project will be also the porting of the userspace client<br>
for that interface, a modified qemu that uses KVM for host<br>
execution.<br>

	</div>
 </td>
 </tr>
</table>
<a name='freenet' />
<h2> freenet </h2>
<table>
 <tr>
 <th>Title</th>
 <td>A Blogging plugin for Freenet</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Frédéric Rechtenstein</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jerome Flesch</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Freenet is a tremendous project, but one of the biggest problem (IMHO) is the lack of useful and interesting content.<br>
But after a reflection, this situation seems to be logical : If it's easy to insert or download a movie, currently it's hard for a common user to publish a site or a blog.<br>
On the web everyone can easily express himself in a CMS, Wiki, Blog, Podcast, ..<br>
On Freenet, the only solution is to create a Freesite, but a lambda user can't do because it requires to know HTML, CSS, etc.<br>
This situation may change with Freekiwiki, but a wiki is made for collaborative content, so it's not adapted for many usages like a personal site.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Different growth models for routing/congestion control</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Vilhelm Verendel</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ian John Cecil Clarke</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Many social systems (such as links on the Internet) have the small-world property, but also a power-law degree distribution. This means that some nodes have many more peers than others. This can be a risk for a network with respect to targeted attacks, but also something I think one has to partly accept in case that the Freenet system should allow for adding trusted connections just as in the real<br>
world. It's hard to put constraints on this.<br>
<br>
I would like to take the existing work/simulations that have been done and see if it could be extended to a network that either has finer details or are in some sense more alike to the structure of either wider models or to the current generation process (setting up connections via an irc channel should for example give quite clustered networks with few long links, perhaps also with very varying amount of degrees of the nodes). Having a large number of connections may be relevant to study for avoiding bottlenecks in the network.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>DOS resistant link level encryption using JFKi key management protocol</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Srivatsan Ravi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Florent Daignière</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The creators of Freenet tried to enhance the security of the system by envisioning all forms of DOS attacks. There still however exist some ways in which an attacker may affect the system through some variant of DOS. For my project, I will try to provide a DOS resistant link level encryption using the Just fast Keying(JFK) key management protocol.<br>
<br>
Denial of service attack can be directed at Freenet by the attacker in several ways.<br>
1.Insert a large number of bogus files into the network to attempt to fill the network’s storage capacity.<br>
2. Distributed DOS attacks can be launched by the attacker by using several zombie systems to simultaneously launch smurf attacks( spoofed broadcast ping messages to flood the system) because there is nothing to prevent the attacker from using any number of ports on a single host pretending to be an extremely large number of nodes.<br>
3. The attacker could also modify all messages that pass through him by generating false RequestFailed or TimedOut messages to DataRequests or sending messages with extremely large amounts of data.<br>
<br>
JFKi provides active identity protection for the initiator and no identity protection for the responder, whereas JFKr provides active identity protection for the responder and passive identity protection for the initiator. By superencrypting the authentication packets with the symmetric key in each node’s reference, we make JFKi resistant to the attacker.<br>
Link level encryption by means of the Just Fast Keying (JFKi) protocol significantly reduces the chances of analyzing network traffic when the communication link operates continually and carries a significant level of network traffic. JFKi will be DOS resistant because it will resist CPU/memory exhaustion attacks on the network, unaffected by Man in the Middle( MITM) attacks because nodes will authenticate other nodes and most importantly, protect the anonymity of the user which is the unique feature of the Freenet that sets it apart from other P2P architectures.<br>
<br>
The JFKi protocol will be implemented in Java (Freenet is written in Java) so that it can be incorporated into the Freenet source tree. Having studied the Freenet architecture and the several cryptographic algorithms in the past, I am confident of completing the task within the stipulated time.<br>
<br>
The original Freenet documentation is present here<br>
http://freenetproject.org/papers/freenet.pdf<br>

	</div>
 </td>
 </tr>
</table>
<a name='freevo' />
<h2> freevo </h2>
<table>
 <tr>
 <th>Title</th>
 <td>DVB CAM support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alessandro Decina</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Zaheer Abbas Merali</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The scope of this project is to add DVB CAM support to Freevo.<br>
Kaa.record, the recording component used by Freevo, is based on the<br>
GStreamer framework so this will require adding the support to<br>
GStreamer and then integrating the work back in Kaa.record.<br>
When this project will be completed, Freevo will have a rocking DVB<br>
CAM support. Also all the other GStreamer based media players will<br>
be able to integrate this new feature with little effort.<br>

	</div>
 </td>
 </tr>
</table>
<a name='fsijp' />
<h2> fsijp </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Improve Eclipse plugin of OCaml</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Soutaro Matsumoto</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Yoriyuki Yamagata</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 There is an Eclipse plug-in for OCaml programming. The plug-in is a part of EclipseFP project(http://eclipsefp.sourceforge.net/index.html). However, the plug-in provides only a few features and looks being not maintained for two years.<br>
<br>
I propose better plug-in, which provides following features.<br>
<br>
1. Integrated build system, which recognize the dependencies between modules<br>
2. Code editor, which provides simple code formatting and refactoring browser<br>
3. Integrated unit-testing support<br>

	</div>
 </td>
 </tr>
</table>
<a name='gaim' />
<h2> gaim </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Gaim/Pidgin MySpaceIM Protocol Plugin</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jeffrey Connelly</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sean Egan</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 MySpace is a popular social networking site used all over the world. In May of 2006, MySpace released their own proprietary instant messaging program, MySpaceIM. The goal of this project is to reverse-engineer the MySpaceIM protocol and implement support for it in Pidgin's libpurple (formerly Gaim's libgaim) library, allowing Pidgin users to have full access to the MySpaceIM network.<br>
<br>
A preliminary proof-of-concept Gaim plugin implementation is available at http://xyzzy.freeshell.org/gsoc/myspace-gaim-prpl-01.tar.gz, implementing the following:<br>
<br>
- Parsing most of the protocol<br>
- Logging in using RC4/SHA1-based authentication<br>
- Sending messages, by numeric userid or username<br>
- Receiving messages, currently only by numeric userid<br>
- Some buddy list support (show all users on buddy list as online, by uid)<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Certificate Manager and Improved SSL Support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>William Ehlhardt</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ethan Blanton</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Gaim's SSL (Secure Sockets Layer) support is currently incomplete. Several protocols, notably the MSN and Jabber instant messaging protocols, use SSL to communicate securely with the chat server to prevent harvesting of password data, hijacking, and eavesdropping. However, Gaim's current solution to SSL support is something of a hack; in order to sidestep the problem of key management, Gaim simply &quot;takes the server at its word&quot; and does no certificate verification.<br>
<br>
I propose to add a certificate management system to Gaim. This will provide increased security by allowing the user's Gaim client to keep track of the certificates of the services she uses, alerting her to unrecognized certificates, and allowing her to verify and add them to the trusted list.<br>
<br>
SILC (Secure Internet Live Conferencing), another secure chat protocol that Gaim supports, would also benefit from the addition of a key manager. If time allows, I intend to extend the certificate manager to be useful for SILC keys.<br>
<br>
PROJECT DELIVERABLES:<br>
(SILC-related parts somewhat optional)<br>
- A unified &quot;Certificate Manager&quot; interface within libgaim through which the various public-key-using systems can export key/cert management.<br>
- A corresponding &quot;Certificate Manager&quot; dialog for the GUI.<br>
- Appropriate extensions to the SSL and SILC interfaces to provide a protocol-specific &quot;key management API&quot; for each, through which the trusted keys/certs databases can be modified.<br>
- Management interfaces, implemented through the Certificate Manager interface, that allow the user to control the key/certificate stores of SSL and SILC.<br>
- (Possibly) A set SSL certs to ship with Gaim and initialize the cert store.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Telepathy support for Gaim</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Will Thompson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robert McQueen</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Gaim is a popular instant messaging client with support for more IM protocols than most people have fingers. In recent times, it has been suggested that Gaim development has stagnated; for example, the MSN protocol implementation lags behind that of a number of other clients, and there is no voice or video support.<br>
<br>
Telepathy is a communications framework built around DBus. Connections to IM servers, text conversations, and voice calls (for instance) can be implemented with a number of separate processes, interacting via the session bus. This approach allows each component to do one thing well, rather than requiring a single monolithic application to provide every piece of functionality. It also allows any new UI to reuse the existing connection managers rather than having to reimplement every protocol itself.<br>
<br>
Currently, there are only five released Telepathy connection managers. Some of these are said to be superior to Gaim's implementation of the same protocol, while others are more rudimentary. On top of this, Gaim supports a range of protocols which are totally unavailable within the Telepathy universe. I propose to implement:<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;* a Gaim-based Telepathy connection manager, to provide Telepathy clients with access to the full range of protocols supported by Gaim.<br>
&nbsp;&nbsp;&nbsp;&nbsp;* a Telepathy protocol plug-in for Gaim, to give Gaim access to Telepathy implementations of protocols in addition to Gaim's own implementations. This would also allow other desktop applications to interact with Gaim's connections without needing Gaim-specific code in each application or application-specific plug-ins in Gaim.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Gaim-Text Improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Eric Polino</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sadrul Habib Chowdhury</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 =======<br>
Overview<br>
<br>
A prioritized list of deliverables is as follows:<br>
<br>
1. Shortcut Keys Overhaul<br>
2. Sound<br>
3. Logging Improvements<br>
4. Buddy List Options<br>
5. Documentation of my changes<br>
6. Crashing bug fixes (if time permits)<br>
<br>
========<br>
Shortcut Keys Overhaul<br>
<br>
The shortcut keys need some serious work.  I will build an independent interface made available with a command line option to catch basic keystrokes.  To provide running customizations I add an interface within Finch to bind keystrokes to predefined actions.  Finch will be able to detect both 8-bit meta and ESC sequences.  If time allows I will also add the ability for Finch to detect that the user is unable to send commands due to key binding issues and then provide a way for it to grab a group of basic keystrokes to allow the user to navigate.<br>
<br>
====<br>
Sound<br>
<br>
I frequently run Finch inside a screen session in the background, and it is very frustrating when I miss someone who tried to talk to me. Since it's not a GUI and doesn't have the ability to pop up a notification, the best way to resolve this problem is with the use of sound. I will add the ability to customize sounds for different events, similar to many existing IM programs. I will also make sounds customizable on a per-buddy basis similar to how you can program custom ring tones for different people in your cellphone.<br>
<br>
=====<br>
Logging<br>
<br>
The logging features are another feature I will improve. I will build on the same basic ideas found in Pidgin's logging tools. Though there are a few ideas I want to add.<br>
<br>
I will add the option to search through all conversations instead of just searching them one by one, or even searching them over a range of dates. There will also be the option to search from a list of logs from different users. From there we can add an array of search capabilities to better search the logs.<br>
<br>
===============<br>
Basic Buddy List Options<br>
<br>
There are a few options to the buddy list that I think are missing. I will add the ability to hide/show empty groups and to hide/show buddy details.<br>
<br>
===========<br>
Documentation<br>
<br>
I will document my work for users and developers in LaTeX and thus provide a way to output the docs in a variety of formats.<br>
<br>
==============<br>
Crashing Bug Fixes<br>
<br>
If time allows I will work on some bugs that cause Finch to crash.  Some of these are related to chatting over GoogleTalk and causing a segmentation fault when the program attempts to exit.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Mono Loader (Part Duex)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Eoin Coffey</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Gary Kramlich</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My name is Eoin Coffey and I'm applying to continue working on the mono-loader plugin for Gaim.<br>
<br>
After the 2005 SoC I submitted my patches for a basic mono-loader to gaim and they were accepted and committed shortly thereafter.<br>
<br>
Currently the mono-loader is sitting neglected in the Sourceforge's shiny new SVN repository.<br>
<br>
I aim to fix that.<br>
<br>
The plan breaks down into improving the stability of the plugin, possibly improving mono to make the first task easier, and planning, generating, and packaging .NET bindings for Gaim.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Stabilize and improve MSN support in Gaim</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Carlos António Vieira Silva</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mark Doliner</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The main goal is to update MSN protocol and its features support in gaim, and producing quality code ready to be included in mainline gaim. The areas of improvement will be the MSNP13 branch completion and stabilization, SOAP handling simplification, direct P2P file transfers, and extra features supported by the MSNP protocol such as storing the display picture and personal message on the server, so it is the same everywhere the user connects.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Virtual Classroom over Pidgin</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Prekshu Ajmera</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Richard Laager</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of the project is to design a virtual classroom plugin for gaim. The instructor can add the students as buddies in his own classroom group on gaim. Whenever the instructor runs the classroom, the students can connect to it to get benefits from his lecture .. The main features will be a white board where the professor can draw &amp; write and chat facility(through gaim). He can also show them some videos if required.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Remote logging</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Shkutkov Michael</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Richard Laager</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Everyone know what does “IM” stand for? And almost all of us use messengers in everyday life. We can chat with out friends, parents, colleagues or even boss, we can just simply chat or have an important conversation – it doesn't matter actually. In the end, the only thing that matters is the information - only what we or our interlocutor typed. So it's rather useful and comfortable to have access to chat log anytime.<br>
<br>
May be you think that it’s not a big problem. Let’s imagine you have one home computer and another home computer or your personal working place at university, work or anywhere. So you need to synchronize your logs (which can be very important). It's a very common problem of many IM users (I am not the exclusion).<br>
<br>
The goal of this project is to extend existing logging subsystem of Gaim, popular multi-platform instant messaging client. This extension allows to safely store your logs on different type of repositories and synchronize your logs with remote ones. With this extension you don't need to copy valuable information form messenger to external device no more. You can forget about mailing your own logs to your own mailbox to have access to them from some other place. With this extensions you can stop worrying about the hardware failures -  because what ever happen with you computer, your logs will be safe. Another minor goal is to allow user to convert their IM message history to Gaim log.<br>

	</div>
 </td>
 </tr>
</table>
<a name='gallery' />
<h2> gallery </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Full Text Indexes for Gallery2 Search</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Adam Pflug</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Felix Rabinovich</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The current implementation of Gallery2's search functionality suffers from poor performance, a problem particularly pronounced for large datasets because indexes cannot be used to improve efficiency. The solution to this performance and scalability problem is to use DBMS agnostic full text indexing for searches. Furthermore, the current search implementation does not support complex queries (such as queries containing boolean operators) or effectively support even basic relevance-based ranking algorithms. The use of a full text index and an enhanced query parser could offer improvements in both these areas.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Gallery 2 SQLite backend</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Brian Kirchoff</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tim Almdal</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Gallery 2 currently supports a number of databases for storage backend including MySQL, PostgreSQL and Oracle. SQLite is a new flatfile database system that is fast, simple and easy to use and is now included by default in new PHP installations. By adding support for SQLite to Gallery 2 as a storage backend it increases the number of people who will be able to easily install and use Gallery.<br>
<br>
Deliverables for this project:<br>
&nbsp;&nbsp;SqLiteStorage class that extends GalleryStorage<br>
<br>
&nbsp;&nbsp;Implements SQLite Version 2 using ADODB and SQLite Version 3 with PDO driver added to ADODB<br>
<br>
&nbsp;&nbsp;SqLiteStorage will have to handle ALTER TABLE which is missing from SQLite by making a new version of the table and copying all the data.<br>
<br>
&nbsp;&nbsp;Add SQLite to DatabaseSetupStep class in Installer<br>
<br>
&nbsp;&nbsp;Test and Pass all 2200+ Unit Tests<br>
<br>
Visit http://codex.gallery2.org/Gallery2:SoC-SQLite_Gallery_2_SQLite_Backend for more information about the project.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Web Based Image Manipulation .</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>UdayaKiran  Ghattamaneni</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jack Bates</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The idea of this project is to develop a 'Web based<br>
Image Manipulation' module for Gallery. Gallery is a<br>
very good package for managing images.There are a lot<br>
of things which we can do with gallery.But<br>
surprisingly gallery does not come with many Image<br>
manipulation options.There are some basic operations<br>
like flip, rotate and resize.But it would be great if<br>
we could have a bigger set of image operations built<br>
into gallery so that even users without any image<br>
editing software on their computers can manipulate<br>
their images before they take prints.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Media Metadata Extraction and Manipulation</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Camilo José Díaz Repka</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Russell Lee</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Improve the Current Exif Extraction G2 Plugin, adding database storage support(and searching) along with property editing for a subset of suitable items.<br>
<br>
Currently G2 has an Exif plugin, which enables read-only access to embedded metadata in image files, this plugin also provides an admin interface to select which fields should G2 display on Basic/advanced view mode. Every time a user request to view an GalleryPhotoItem via the core.ShowItem view/controller, the underlying Exifer lib parses the original file Exif/IPTC Attributes, and the Exif block is embedded on the view, displaying the user-selected subset of the picture metadata.<br>
<br>
There are several drawbacks of this approach. One of them, is the amount of load that impacts the server when the underlying Exifer/JPEG libs parse metadata entries, something really noticeable on big files. Other drawback is the unability to search such parsed properties just from the database.<br>
<br>
I want to solve those current G2 issues, and provide additional functionality by implementing a base Metadata Interface, and two backend support modules for it, in a way that the backend can be chosen by the user, as already happens with the Graphical Toolkit. I also want to implement a MetadataEditor for Gallery, capable of setting metadata fields on a per-item and per-album basis, something similar to what the customfield module provides. Beside this, I want to extend the current Exif module capabilities to copy a selected field gathered from medatada to a GalleryItem field after adding new media to the Gallery. This will allow a G2 user the possibility to mirror any gathered metadata property to a user-selected property of a GalleryItem, replicating previous exif module functionality in a flexible, user-customizable way.<br>
<br>
There has been previous attemps to do this, however, no further advance has occurred since then, and the issue is still active on the tracker, being also one of G2’s most requested features.<br>

	</div>
 </td>
 </tr>
</table>
<a name='gcc' />
<h2> gcc </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Propagating array data dependence information from Tree-SSA to RTL</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alexander Monakov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Berlin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The RTL array data dependence analyzer was written specifically for swing modulo scheduling (SMS) implementation in GCC.  It is overly conservative, because it uses RTL alias analysis to find intra- and inter-loop memory dependencies.  It also assumes that the distance of an inter-loop memory dependence equals to one.<br>
&nbsp;<br>
I propose to improve the quality of data dependence analysis on RTL via propagating the information from Tree-SSA dependence analyzer.  The saved information will be used in construction of data dependence graph for SMS.  It can also be used for other optimizations, e.g. scheduler.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Fortran 2003 features for GCC</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Janus Weil</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Steven Bosscher</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I would like to contribute to the Fortran front end of GCC by implementing some missing features from the Fortran 2003 standard, primarily concentrating on the ones concerning object orientation. In particular I would like to focus my efforts on the implementation of:<br>
- procedure pointers<br>
- type-bound procedures<br>
- (and possibly even more ...)<br>
Depending on the time it takes to reach the first two aims, I would try to implement some more Fortran 2003 features, where the object-oriented features would be on top of my list (e.g. type extension, inheritance, polymorphism, type-bound operators), since I think that the lack of object orientation is the most serious deficiency of Fortran 95.<br>
I chose the two primary aims because type-bound procedures are at the heart of object orientation, and procedure pointers are a good first step towards type-bound procedures.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Open Mutliprogramming Interprocedural Analasis and Optimalizations</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jakub Staszak</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Berlin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My idea is Open Mutliprogramming Interprocedural Analasis and Optimalizations (OMP-IPA). Multithreaded programming has become very important and I think that GCC should focus more on this subject. OpenMP implementation in GCC is on very basic stage, and there is still a lot of things to do. In my opinion my project (OMP-IPA) may improve GCC's posibilities and fix some bugs.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Integrating OpenJDK&#39;s javac bytecode compiler into gcj</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Dalibor Topic</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mark J. Wielaard</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The GNU Compiler for the Java programming language includes a front end for the compilation of source code to JVM bytecode. The original front end has evolved over time, to be eventually replaced in early 2007 by a front end based on integrating the Eclipse Compiler for the Java programming language in order to allow gcj users to utilize features from the Java 1.5 language specification in their code.<br>
<br>
I would like to integrate the OpenJDK javac compiler, into gcj in the same way. That would allow gcj to easily track the next batch of Java programming language changes planned for Java 7 as they are introduced in the javac code base, as javac serves as the reference implementation for Java programming language (bytecode) compilers.<br>
<br>
The project would entail :<br>
<br>
1. Making javac build and run on gcj &amp; GNU Classpath, building upon the work done by Andrew Haley and Andrew Hughes.<br>
<br>
2. Porting the GCCMain wrapper for gcj-specific behavior (compiler options, error output style, etc.) to wrap javac's functionality and integrating it into the gcc bootstrapping process.<br>
<br>
3. Integrating gcj+javac into the gcj and javac regression test suites, in order to shake out and fix potential regressions in the jc1 bytecode-to-native-code translator in gcj, as well as the integration code.<br>
<br>
4. Adding support for the stack map attribute in gcj, which was introduced in JSR 202 and implemented in javac for Java 1.6.<br>
<br>
5. Rebuilding Fedora's, Debian's or Gentoo's Free Software Java programming language based packages using the gcj+javac combination in order to detect and fix potential regressions in real-world code.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>New static scheduling heuristic for GCC.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Dmitry Zhurikhin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Vladimir Makarov</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Most scheduling approaches consist of two steps: computation of sets<br>
of available instructions at the current scheduling point, and<br>
choosing one of them to become the next instruction.  This approach is<br>
used in GCC compiler in current implementation of list scheduler<br>
(known as Haifa scheduler) and new approach under developing –<br>
selective scheduling.  While most activities aimed at improving<br>
scheduling quality are trying to increase number of gathered available<br>
instructions (such as above-mentioned selective scheduling, treegion<br>
scheduling, improvements of region formation), choosing step plays an<br>
important role too. Current implementation of scheduler uses static<br>
priorities, based on critical path heuristic, which is known to behave<br>
well while scheduling single basic blocks and become worse when<br>
expanding scheduling boundaries to extended basic blocks or regions.<br>
This project aims at developing a new priorities system, which would<br>
consider not only the critical path, but other possible exits from<br>
scheduling region and their probabilities.<br>

	</div>
 </td>
 </tr>
</table>
<a name='geda' />
<h2> geda </h2>
<table>
 <tr>
 <th>Title</th>
 <td>SDF Parser/Annotor for Icarus Verilog VPI Plugin</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>yang ju</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stephen Williams</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The SDF parser will parse SDF files, that are described in Standard Delat File format ( a generic SDF file, no FPGA or ASIC preference). It can be invoked by the '$sdf_annotate' system task and match paths with the specify paths actually available (via vpi) in the design.<br>
<br>
This task is made in C and can be loaded as a VPI module, that is inoked by the VVP engine during the simulation time. The property EDA tool, Modelsim, from Mentor Graphics, is used to validating the implementation and a comparative report is attached by the end of project.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Usability enhancement in Gtkwave</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Kermin Fleming</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Anthony J Bybell</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Debugging HDL circuit descriptions is a challenging task as many events in hardware systems occur concurrently.  One of the best ways to debug such systems is by viewing the simulataneous changes in logical waveforms within the system using a waveform viewer.  Gtkwave is an open digital waveform viewer commonly used in academic and industrial settings.  I propose to fix some usability issues in gtkwave, such as reloading waveform dumps while gtkwave is running and improving inter-run compatibility of stored waveform configuration files.<br>

	</div>
 </td>
 </tr>
</table>
<a name='geeklog' />
<h2> geeklog </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Installation Wizard for Geeklog</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Matthew West</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Dirk Haun</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 These days there are several different CMS and Weblog packages freely available for website owners to download and install. Because of this it is imperative that a software package create a warm and fuzzy experience for those who are installing and administering it. The current Geeklog installation procedure may be seen as daunting by novice website owners. The several steps that are involved in the setup process makes it likely that a user will become discouraged during the process, abandon the installation and move onto try other weblog software. Additionally, it is a hotspot for errors if a user makes a syntax mistake in the config file during the setup. My suggestion for a more automated process should solve most of those problems and present a more elegant installation experience.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Article plugin</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Damien Hodgkin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tony Bibbs</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Geeklog 2 is getting to a stable and usable state. The new Geeklog 2 core allows for most major  functionality to be added in via a plugin structure.<br>
<br>
Geeklog 2 needs a working plugin implemented to ensure all the various<br>
API's built into the kernel (SOAP, Event Management, etc) are working as designed.<br>
<br>
The core to most CMS engines is article management and as such Geeklog 2 needs an Article plugin.<br>
<br>
The Article plugin will allow users to post articles to be displayed on the front page of the site. It will be written in PHP, Xhtml and Xml.<br>
<br>
To accomplish the task of creating this plugin a core class will be written to house all the needed &quot;main&quot; functionality, such as submission functions along with any hooks to make it compatible with future plugins (ie. a media plugin).<br>
<br>
The finished plugin will deliver a very flexible article submission system, complete with richtext editor, SOAP inteface, AJAX (which will allow the plugin to be usable without javascript, but if the clients browser supports it will allow more advance enhancements), media hooks, options to configure how the article is displayed, and automatic article aging.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Web services API for Geeklog</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ramnath R Iyer</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Dirk Haun</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My proposal for SoC is to develop a comprehensive Web Services API for the Geeklog content management system. The purpose of this API would be to publish and update stories and comments using a desktop application, import data into the Geeklog system or export data into a standard or well-established format such as RSS or Atom. This would also entail a re-organization of Geeklog's code internally, and the development of an API layer to handle the flow of information between the web service, the website, plugins and the database.<br>

	</div>
 </td>
 </tr>
</table>
<a name='genmapp' />
<h2> genmapp </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Enhanced search strategy in Cytoscape</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Maital Ashkenazi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David States</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Cytoscape is an open-source network visualization and analysis software.<br>
<br>
A network is composed of nodes and edges. Those elements can have different values associated with them, known as attributes. The user can search and retrieve a list of nodes or edges according to a specific attribute’s value. Currently, The search is carried out one attribute at a time. To perform complex queries, involving multiple attributes, the search should be repeated for each attribute; then the result sets can be merged into a final result set. Wildcards can be used only for terminating a value.<br>
<br>
I will introduce an improvement to Cytoscape that will enhance the search capabilities to allow searching on multiple attribute fields with the use of logical operators and wild cards.<br>
<br>
The search interface includes a text line, into which the user types the query. The intuitive query syntax uses the form attribute:value. Logical operators (AND, OR, NOT) can be used between the query parts, resulting in a search on multiple attributes. The use of wildcards anywhere within the value will provide additional flexibility to the search strategy.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Visual history of pathway modifications</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Martijn van Iersel</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Alexander Pico</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 An important usability feature in wikis is the ability to examine changes made by others. The same principle goes for wikipathways.org. Simply showing an old and new version of a pathway side by side may work, but usability could be improved by giving better visual indicators of what has changed.<br>
<br>
I intend to develop a standalone utility that takes two pathways in GPML format, calculates the minimal difference, and turns this into an SVG image that clearly visualizes the differences between the two pathways. I'd like to create at least two possible visualizations: transparent overlays and a two-pane color-coded layout.<br>
<br>
I've created mockup images of what I think this could look like here:  http://ftp2.bigcat.unimaas.nl/~martijn.vaniersel/gsoc/ . I want to implement two different visualization styles simultaneously to get a better idea for what ideas are good and bad. User-testing should determine the best of the two and I want to make that part of my project. Subsequently I intend to integrate this application both into wikipathways.org and PathVisio.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Pathway Editor for WikiPathways.org</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Thomas Kelder</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kristina Hanspers</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 ++++ Pathway Editor for WikiPathways.org ++++<br>
To facilitate easy and user friendly pathway editing, I propose to rebuild PathVisio to create an embedded pathway editor, that can be included in the WikiPathways.org web pages. A user should be able to activate this editor with a single mouse click making the editor start within seconds. The editor should be light-weight, user friendly and have no other dependencies than the user's browser.<br>
For more info see: http://conklinwolf.ucsf.edu/genmappwiki/Google_Summer_of_Code_2007/Thomas<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Graph layout library for GenMapp</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nikolic Aleksandar</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Smoot</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Graphs (networks) are one of the main utilities for visualization of biological data. Standard algorithms for graph layout are good enough for some applications, but knowledge of domain is sometimes a necessity for proper analysis of the represented data. Main purpose of this project is to combine advanced graph layout algorithms with semantics of represented biology data in order to get the best representation.<br>

	</div>
 </td>
 </tr>
</table>
<a name='gentoo' />
<h2> gentoo </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Collective Maintenance</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andrey Falko</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stephen Bennett</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Most work in Gentoo revolves around the maintenance of the ebuilds in the portage tree. This work is divided up amongst either individual maintainers or herds. An individual maintainer or a herd is responsible for committing bug fixes and version bumps for the packages that they officially maintain. A single maintainer or herd cannot take on more packages than they have time to work on. As a result, the number of packages that can be well maintained in portage becomes limited by the number of developers. Second, should a maintainer become absent, his packages will not be maintained. Sometimes users will submit ebuilds with version bumps for bug fixes, but not have them committed to the tree until the maintainer returns.<br>
<br>
I propose a system that helps overcome these disadvantages. My project will not require a banishment of official maintainers and herds, as there are advantages to such a scheme. My project's goal is to allow Gentoo to expand its capabilities to better support a large number of packages. I propose to create a web interface where users and developers can collaborate on a list of packages maintenance tasks. The tasks in higher demand will be at the top of the list. Users can register, mark that they are working on a task, submit their work, and wait for a developer to review and commit their work. Developers can do the same, with the exception that they will not have to wait for another developer to commit their work.<br>
<br>
This interface will effectively allow users and developers to flexibly to take on tasks without needing to search for a maintainer or herd to do the task. This interface can allow for the ability to have packages in portage that are not maintained by a single herd or maintainer, but instead are maintained by the whole community. If an issue arises with such a package, the issue will be put on the task list, and solved by the large number of people who might care about the package.<br>
<br>
Another thing that the interface will allow is the ability for herds and maintainers to list tasks that they cannot do. For example, the kde herd is in need of more maintainers to fix a number of outstanding bugs. With the interface, the herd can submit the bugs and see a response from capable people who do not have time to be an official maintainer, but have the time to fix a bug or two. In sum, the interface will allow Gentoo to communicate specific work that needs to get accomplished to the community.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GNAP cross compile support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Philipp Riegger</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jose Alberto Suarez Lopez</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 GNAP (Gentoo Network Appliance) is a toolkit to build small<br>
Gentoo-based distributions for embedded devices or old PCs.<br>
<br>
It consists of 3 packages: gnap, gnap-dev and gnap-ext (all in<br>
dev-embedded). Gnap provides the gnap_overlay script, which is used<br>
to build customized images (disk image or cd image). Therefore it<br>
takes a prebuilt GNAP core and &quot;overlays&quot; it with customized<br>
configuration files. Gnap-dev provides gnap_make which can be used<br>
to build customized GNAP cores and extensions for existing GNAP<br>
cores. Gnap-ext provides gnap_remaster, which is used to extend GNAP<br>
cores with extensions. It is easy to get a simple system running<br>
using only the gnap and gnap-ext package and GNAP is also flexible<br>
enough to allow the user to build complex images with all kinds of<br>
special software using gnap-dev.<br>
<br>
Unfortunately, all of them are only available for x86 and/or amd64.<br>
It is only possible to build images for x86 compatible systems. This<br>
is a big limitation, since lots of embedded systems are not x86<br>
based, but ppc, arm, mips or mips64. And since GNAP can run off a 16<br>
MB flash drive and is very customizable (a smaller gnap is possible,<br>
a totally different purpose is possible) it is interesting for all<br>
kind of devices. Or it could/would be, at least.<br>
<br>
The goal of my project  is to integrate cross compilation support in<br>
GNAP, include support to build images on platforms different than<br>
x86/amd64 and to include support and create documentation for at<br>
least one specific embedded board. This probably also includes<br>
cleaning up the codebase, fixing bugs to get gnap working out of the<br>
box (the current gnap in portage needs some love) and maybe<br>
expanding/clarifying existing documentation.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Robust Cisco-like configuration interface for GNAP-powered embedded distros</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>ALEXANDROS STERGIAKIS</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Alexander Færøy</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Improve the usability of GNAP/Catalyst-based distributions by developing a Cisco-like CLI framework, as well as basic configuration-plugins for it. The goal is for this layer to be flexible enough as to empower other more high-level layers to sit on top of it.<br>
<br>
Specifications:<br>
*Separation of the CLI as a system, from the code that enforces user configuration commands.<br>
*Modular architecture: New configuration commands and modules can be inserted/removed/updated at anytime on a running system.<br>
*Supports local (console) connections and remote (network) connections with optional authentication.<br>
*In-line scripting language embedded in the CLI interface, with ability to activate/deactivate.<br>
*System configuration for each configuration plugin is reflected internally in XML files.<br>
*Command output is natively XML, with later being XSLT (or otherwise) translated to human readable format to be displayed on the console. XML allows for easy layering with other Configuration Interfaces (such as Web-based or Remote GUI).<br>
*Integration with “GNU Screen” to support multiple parallel local CLI sessions.<br>
*Arbitrary configurable privilege modes, with arbitrary configurable commands associated to each of them (USER, EXEC, ...). A command can be registered in many privilege modes.<br>
*Optional authentication for each of the privilege modes. Hash-based authentication.<br>
*Arbitrary configurable configuration modes (configure terminal, router rip, interface eth0, ...) this resembles a tree directory structure with different command visibility at each node. A command can be registered in many configuration modes.<br>
*Superset of the functionality provided by a Cisco-router in terms of CLI versatility.<br>
*Real-time informational messages on the console in a push manner, for evens such as interface link state UP/DOWN.<br>
*Escape mechanism that allows the user to enter shell mode and conduct debugging, information gathering or manual tweaking of the configuration.<br>
*Optional component. The user must be able to deactivate it and be able to configure the system manually or by other means. While active, other means should be avoided, except if they can interact with the CLI API.<br>
*Bounded command length, or unbounded with the last element repeating arbitrary times (or limited by the handling function).<br>
*Finally some basic configuration plugins should be provided mostly as a proof-of-concept, and to encourage user community to contribute, and also as a guidance on how plugins should be implemented.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>equizApp - system that helps Gentoo Recruiters and mentors create and manage quizzes for new recruits</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Grzegorz Kulewski</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Christel Dahlskjaer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Gentoo is a huge project with many developers and big and complicated infrastructure. All new developers must know how to inter operate with others without problems and collisions and how to fully use all tools and services before they are accepted and granted access into CVS repository and other parts of infrastructure. To make this even more complicated there are several kinds of developers (...) having access to different infrastructure and needing different knowledge (...) and skills.<br>
<br>
Historically all this was checked by quizzes (sets of questions ensuring that recruits read and understood documentation). (...) Everything was coordinated by emails.<br>
<br>
This process of course does not scale too well. The biggest problem is that quizzes were too static (...). Also questions need to be adjusted as the infrastructure changes. Maybe even the whole process should be centrally managed by this system (...).<br>
<br>
The equizApp is designed to fix these problems and make everyone's life easier. The most important part of it will be the question and answers database. (...) The second part will be individual quiz generator (...) with some export options for ready quizzes (with answers or without). The third part (optional: if Gentoo Recruiters want it) will allow Recruiters and mentors to fully manage whole quiz process for the given recruit (...).<br>
<br>
I propose to do equizApp as an application driven by web browser (and possibly some scripts if needed), installed on some Gentoo server, written in PHP (...) or Python (...), using MySQL or PostgreSQL and integrated with Gentoo's LDAP for user authentication. Also I think it is good idea to use some framework to avoid mixing presentation with logic and bloating everything with heaps of (X)HTML code. Of course the requirements and design and especially feedback from Gentoo developers can change these plans.<br>
<br>
My goal is to keep it as simple as possible (KISS) so everyone will be able to change and adapt it as process it models changes (something that probably slowly happens anyway, as with all real life &quot;business&quot; processes). The most important part is the model of the whole process and workflow and right design that fits it. Then features can be easily added when needed. This way the application can serve well for many years with only minor improvements.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>SCIRE&#39;s job subsystem implementation for both the frontend and backend.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Rodrigo Eduardo Lazo Paz</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Matt Disney</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Working with a large network of machines involves, among other tasks,<br>
dealing with jobs in a comprehensive and as-simple-as-possible way.<br>
<br>
The job subsystem is one of the most complex parts of SCIRE, given<br>
that it has to deal with several scenarios that may turn a simple job<br>
into very frustrating experience. This SoC project aims at working on<br>
this subsystem so it can handle from simple tasks as jobs for a single<br>
machine to more complex duties as per-profile recurring jobs with<br>
error handling. This will be achieved trying to make client and<br>
client-server communication as simple as possible delegating most of<br>
the work to the server application.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Python bindings for Paludis</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Piotr Jaroszyński</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Saleem Abdulrasool</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Create Python bindings, associated documentation and test cases for the Paludis public API, and allow subclassing of Paludis classes using Python.<br>
<br>
Most current version of my application:<br>
http://dev.gentoo.org/~peper/soc/application.txt<br>

	</div>
 </td>
 </tr>
</table>
<a name='ggi' />
<h2> ggi </h2>
<table>
 <tr>
 <th>Title</th>
 <td>OpenGL support for GGI</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Raghavendra Narasimhan V</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Christoph Egger</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The basic operations on visuals, as defined by GGI, are intentionally limited. It's impossible to define an API for all possible graphic features because of the variety of hardware, and the fact that graphic needs are constantly evolving. Such an API would be bloated and quickly obsolete. The GGI answer is to implement only a simple set of universal features, and leave the rest for extensions.<br>
<br>
In this project I start with an existing extension framework called libggigl.And extend it with OpenGL API, allowing GGI applications to easily use OpenGL for drawing.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improve XGGI by implementing some X extensions.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Vikram Kumar</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Christoph Egger</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 We can improve XGGI (the fork of X server which uses GGI at backend)<br>
by implementing various latest developments in X.<br>
&nbsp;1. Available X extensions should use libggi functions for h/w<br>
&nbsp;&nbsp;&nbsp;&nbsp;acceleration.<br>
&nbsp;2. Update RandR support.<br>
&nbsp;3. Implement Composite extension.<br>

	</div>
 </td>
 </tr>
</table>
<a name='git' />
<h2> git </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Replace most core scripts with C versions.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Carlos Rica Espinosa</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Johannes Schindelin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The project goal is to replace most git scripts written in shell or perl languages, with a more portable and faster builtin C versions.<br>
<br>
Many git commands are currently implemented as scripts, since they are easy to program. In order to run the program in other systems, a Bourne shell and a Perl interpreter need to be properly installed, resulting in a harder development and use on other platforms or systems.<br>
<br>
Many projects has been converted to builtin code already, and the structure of the code simplifies that task. At present, there are about 10 perl scripts and 32 shell scripts in the Git code implementing essential Git commands, like &quot;git commit&quot;, &quot;git merge&quot;, &quot;git clone&quot;, etc. It has been estimated three days for converting the smaller cases, and a couple of weeks for the larger ones, so most of the scripts would be replaced with this project, allowing easier port of the program to other platforms.<br>

	</div>
 </td>
 </tr>
</table>
<a name='gnome' />
<h2> gnome </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Evolution Data Server Backend for google calendar</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ebby Wiselyn</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Harish Krishnaswamy</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 With Google Calendar, you can create and add your schedules and your family and friend's , add events mentioned in Gmail conversations.You decide who can see your calendar and which details they can view. You can create invitations, send reminders and keep track of RSVPs right inside Google Calendar.<br>
<br>
Enabling connectivity to the google calendar from evolution . The Aim is to create a google calendar backend that allows to read and write through the GData Interface.Evolution will have a offline read-only support google calendar , and a online read/write support .<br>
<br>
The Gdata provides a protocol for reading and writing data on the web. GData uses standard XML-based syndication formats either of Atom or RSS. It also has a feed-publishing system that consists of the Atom publishing protocol plus some extensions (using Atom's standard extension model) for handling queries.Client applications can view and update calendar events in the form of Google data API ('GData') feeds.Evolution can use the Google Calendar data API to create new events, edit or delete existing events, and query for events that match particular criteria.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GStreamer plugins and extensions for multimedia content creation applications</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Sebastian Dröge</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stefan Kost</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently the Gnome desktop is missing some great multimedia content creation applications. Jokosher is already fairly good but apart from that everything else is just in the beginnings.<br>
This project will be mostly audio-oriented and would help Buzztard, Jokosher, Marlin and to some degree Pitivi to become better by providing a foundation in GStreamer. Some starting parts are already there but for example many audio effect plugins are missing and some GStreamer parts, although being there are half-implemented or suboptimal.<br>
<br>
The goal of this project would be to improve the current situation by providing some more audio effect plugins, finishing some unimplemented GStreamer parts and adding some missing elements.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Brave New X11 World</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Pascal Schoenhardt</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Christian Kellner</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Brave New X11 World<br>
<br>
With the changes to the X.org windowing system with version 7.3, a range of new possibilities is available for the Linux desktop platform in regards to input and display configuration. This Summer of Code project aims to take advantage of these changes to significantly enhance the GNOME Capplets for configuring input devices and displays. Upon the completion of this project, GNOME should be able to run entirely on hot-plugged input peripherals, with advanced options such as individual key mappings and settings on each device. GNOME users should also be able to easily detect all attached display devices, configure their resolutions, refresh rates, and relative positions, as well as store these settings in profiles, which can be changed at the press of a button.<br>
<br>
For a formatted, PDF version of this application, please visit the following URL:<br>
http://www.designerglasssigns.com/private/soc/application.pdf<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Extending the lockdown framework in GNOME and making it even more deployment friendly</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Sayamindu Dasgupta</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Federico Mena-Quintero</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 One of the major features required in any kind of desktop deployment is the support for lockdown, where users are barred from performing certain actions (like, for instance, printing files, or saving files to disk). GNOME already has lockdown support in a few areas (especially the panel and the epiphany web browser). However, the file manager (Nautilus) does not have any kind of lockdown support at all, and good quality documentation and specifications for the lockdown features is also missing.<br>
The proposed project will add lockdown features to Nautilus and to the GTK+ FileChooser (to ensure a consistent user experience, as well as complete implementation of relevant lockdown policies). The lockdown features would cover filesystem access and modification permissions. Moreover as a part of the project, I would implement a mechanism to define items which will be shown on users' desktops, such as links to common web sites, launchers for programs, or links to commonly-used files such as forms or reference material. I would also document how lockdown and preconfiguration work, which can be used as a reference for administrators and deployers. The last, but in no way the least item in the roadmap is a plan to create a spec for the proposed lockdown on Nautilus and the GTK+ filechooser (probably this should go to first :-)).<br>
The project will involve modifying various GNOME modules (Nautilus/GTK/GNOME-VFS/GNOME-Panel/GNOME-Desktop/etc), written mostly in C. The relevant GUI tools (Sabayon/Pessulus), which are written in Python will also be extended as and when required.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>PiTiVi, an Open Source Video Editor</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Brandon J Lewis</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Edward Hervey</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 PiTiVi is an open source, non-linear, non-destructive video editor that shows great promise. While it is currently barely usable, it has the potential to be transformed into a robust, powerful media authoring tool. I want to help 'kickstart' the project by implementing the minimum set of features needed to attract a community of users, and be considered a functional video editor.<br>
<br>
PiTiVi is designed to be flexible enough to offer at least two UI views, called 'Timelines'. Currently these are 'Simple', aimed at novice users, and 'Advanced', offering more professional features. Most of the features proposed here would be implemented in the Simple Timeline, and would include: editing and trimming support, project file load/save support, and transitions. Optional goals would include a media capture interface, jog/shuttle support, and contributions to the Advanced Timeline.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Integrating Epiphany Bookmarks and Browsing History For GNOME-wide Access</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Imran Patel</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Xan López Saborido</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Synopsis<br>
Most GNOME users access and discover new information using a web browser. The broad goal of this project is to develop a framework for Epiphany that will enable GNOME users to quickly, easily and accurately recall this information. To that end, this project will focus on three specific goals:<br>
1. Develop a high-level design for unifying the storage, visualization and management of user bookmarks and browsing history.<br>
2. Implement a robust and efficient backend store for bookmarks+history objects on top of an indexing framework like Tracker<br>
3. Integrate the currently separate bookmark and history managers to create an intuitive User Interface (UI) for viewing, searching and managing bookmarks+history.<br>
If time permits, an optional goal is to provide a simple high-level wrapper API over Tracker's DBUS API (libtracker) for accessing and querying bookmarks+history from Epiphany extensions and other GNOME applications.<br>
<br>
Benefits to Epiphany and GNOME<br>
Epiphany currently has an excellent topic-based bookmarking system which is the best in terms of ease-of-use among all browsers available for GNOME. By integrating the current system with browsing history, this project will bring several useful and novel features to Epiphany:<br>
1. Quick and easy interface for viewing, searching and bookmarking history items.<br>
2. Powerful free-text search over entire &quot;contents&quot; of bookmarks+history URLs as well as filtering based on metadata attributes such as page visit date.<br>
3. In the long-term, facilitate new Epiphany extensions and GNOME applications for visualizing and organizing bookmarks+history, e.g. Browseback [3]<br>
4. A private trusted system (unlike online systems such as Google search history) that the user can rely on for increasingly common problems (e.g. “Where did I see it before?”)<br>
&nbsp;<br>
In addition to Epiphany, the GNOME desktop will also benefit immensely from a central object store for boomarks+history. An object store maintained by the browser itself will have more fine-grained and accurate metadata. This could be leveraged by desktop search tools for providing more relevant results. In addition, applications such as Deskbar could easily integrate handlers for bookmark+history search using the Tracker API (or the optional high-level API).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Creating a new documentation editor for Project Mallard</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Buddhika Laknath Semage</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Donald Scorgie</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project will implement a new document editor for the Project Mallard using Python and XML.<br>
<br>
This new document editor is called Foie Gras and will be an asset for doc writers. Foie Gras will effectively hide the XML tags and will give the user the ability to focus more on the documentation task rather than having to divide their attention on both XML and documentation.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Simple user-to-user file transfer without configuration in a LAN</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Marco Barisione</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sjoerd Simons</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 There are many solutions to share one or more files, from setting up a Samba share, to a personal directory in a HTTP or FTP server, they have one big common flaw: they do not “just work”. As a consequence people often use services relying on an external server (such as email and chat), or removable devices. In some cases it is not even reasonable to do server-based communication, as is the case of meshed networks.<br>
<br>
Moreover systems like Samba or FTP are useful at home or work when you want to permanently share a folder but often people just want to quickly send a file to some specific person. For that you do not want to first put it in your shared files (making it available to everyone, which you might not want so you need a password on it etc.) and then tell your contact that he/she can find it there. Just right-clicking on a file and using &quot;Send to&quot; (through a nautilus-send-to back-end) to just send this file to that person is a lot nicer.<br>
<br>
An ideal system should automatically discover other users in the neighborhood, list them and let the user choose who to send files. The system should also work without any configuration, without the need to tell one’s IP address, and without requiring any operation from the administrator, such as setting up a server or configuring a service.<br>
<br>
I want to develop a program to satisfy those needs enabling users to easily send and share files over a LAN. My plan is to work on the telepathy-salut connection manager adding support for file transfers, on top of that I'm going to write an easy-to-use GTK-based GUI to show available contacts and to initiate and accept file transfers. The GUI should also manage authorizations in a user-friendly way, without bothering the user with technical details about the involved certificates.<br>
<br>
Recently Xavier Claessens, the author of gossip-telepathy, started to work on grapevine, a modular version of gossip using Nokia's mission control. A good idea would be to work on it adding file transfers capabilities instead of writing a separate GUI, this way other protocols could benefit of my work.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Changing metacity into a window-and-pointer-manager</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Paulo Ricardo Zanoni</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Elijah Newren</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 With the recent X Window System changes, a lot of features are being added, and<br>
the whole world will need to adapt to these changes.<br>
<br>
One of these changes is the addition of multiple-pointer support in X.org 7.4,<br>
that will allow a whole new set of applications that were never made<br>
before, and will also make multiseat easier. When X.org 7.4 gets released<br>
people won't be able to make full use of its new features if there is no window<br>
manager that also manages multiple pointers.<br>
<br>
And to be able to use all of these new features, the window managers will have<br>
to be adapted. What I am going to do is to fully integrate metacity with MPX,<br>
write a document describing the new features that window managers should<br>
implement, and how to do it. The aim of this document is to help developers to<br>
implement multiple-pointer support on their own window managers.<br>
<br>
Also, in the process of adding multiple-pointer support to metacity, problems<br>
might be found and there might be the need of new features/protocol calls, so I<br>
will be able to detect them and report/correct them before xserver 1.5 is<br>
released.<br>
<br>
By the end of summer we expect to have a window manager that brings the new MPX<br>
features and a document that helps everyone integrate their window managers to<br>
work with MPX.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Jokosher VoIP Integration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Michael Sheldon</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Benjamin Thorp</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Podcasters often interview guest via VoIP, some even have their regular presenters communicating via VoIP when physically being in the same room is impossible. In these circumstances it would be useful to have VoIP integrated in to an audio editor, such as Jokosher. This would allow each person participating in the conversation to be recorded as a separate track/instrument, allowing for much easier mixing and editing of the resulting audio.<br>
<br>
&nbsp;This would be achieved through use of the Telepathy communications framework, allowing Jokosher to make use of multiple VoIP protocols such as SIP and XMPP (as used by Jabber/Google Talk).<br>
<br>
&nbsp;I believe this feature would be unique amongst all Free and proprietary audio editors and would be useful to a large number of podcasters.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>gnome-bluetooth and bluez-gnome improvements and unification</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Tadas Dailyda</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Marcel Holtmann</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Synopsis<br>
<br>
Overall project goal is to improve GNOME Bluetooth stack so that it has more functionality and all the features are easily accessible to user. Current gnome-bluetooth functionality would be made available from Bluetooth applet (BlueZ GNOME applet). Support for OBEX FTP server would be introduced and existing gnome-bluetooth code would be refactored. Gnome-vfs OBEX FTP module would be further improved.<br>
<br>
Benefits<br>
<br>
Currently there are at least three separate attempts at making Bluetooth experience in GNOME better: BlueZ GNOME apps, gnome-bluetooth and gnome-vfs-obexftp. This project would unify all of these (both code base and UI) as well as improve overall functionality.<br>
<br>
Success criteria<br>
<br>
*  gnome-bluetooth code should be refactored to loose libbtctl dependency;<br>
*  A working OBEX FTP server should be implemented;<br>
*  All the Bluetooth functionality should be accessible from Bluetooth applet;<br>
*  All configuration options should be available in Bluetooth manager.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Enhance Mango to allow self-service of GNOME account data and streamline GNOME account setup</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Barış Çiçek</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Raphael Slinckx</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project aims to automate account management in GNOME infrastructure. Currently a lot of things are handled manually. With this project account team will only trace the work flow of account creation and only do final decision.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>art.gnome.org 3</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bruno Miguel Fachada dos Santos</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Thomas Wood</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The project is to develop version 3 of art.gnome.org(AGO).<br>
<br>
The main objective of the AGO project is to be an artwork community server at users disposal. As such, Users are the ones who should decide what they want to see. They should have an user-centered experience and feel they are part of the community. Naturally artwork developers should also be encouraged to participate actively with their work. Without them there is no artwork. Thus, users should be able to comment and review developers works and consequently developers must be able to receive such feedback.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Cross-Application Scripting</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ori Bernstein</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Hubert Figuiere</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently, in the Gnome desktop, it is generally impossible to glue together applications in a manner similar to what AppleScript does. There are good examples of scripting within apps (see: Gimp's Script-Fu), but it doesn't allow the easy gluing together of applications, automating workflows such as &quot;Insert data into Gnumeric, Create a chart in Gnumeric, save to file, and convert to EPS for use in LaTeX&quot;.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;This scripting will be the counterpart, to technologies like Apple's AppleScript and KDE's Dcop, and hopefully will eventually interoperate well with DCop.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;The idea was inspired by Hubert, in this blog post:<br>
&nbsp;&nbsp;http://www.figuiere.net/hub/blog/?2006/04/16/397-desktop-scripting<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>VoIP and video call client using Telepathy</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Elliot Fairweather</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robert McQueen</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I should like to put forward a proposal to write a VoIP and video call client for GNOME based upon the Telepathy framework. I am a first year Computer Science undergraduate and have been an enthusiastic user of GNOME since my introduction to Linux four years ago. I have always wanted to contribute to the open-source software community and I believe that I now have the necessary foundation of knowledge and programming ability to do so. I have followed with interest the development of Telepathy and should like to create an application which will allow the GNOME community to benefit from the new opportunities presented by this project.<br>
<br>
My application will provide a GTK front-end to Telepathy to allow audio and video calling via the XMPP protocol. I will create the client's UI by constructing new GTK widgets that will form part of the Grapevine project. Grapevine aims to gather together both Telepathy back-end functionality and UI components from which current and future GNOME applications may be developed. As well as being a showcase for the power of Telepathy, I hope that this client will be act as a proof of concept for these widgets by demonstrating how Telepathy may be fully integrated into the GNOME desktop through Grapevine. A simple interface for the setup and troubleshooting of both webcams and microphones will also be included.<br>
<br>
To get involved with two such great projects as GNOME and Telepathy would be most exciting for me. I think that such a project would be invaluable to me in my education as a programmer and that GNOME would be even greater by the inclusion of an application such that I have proposed.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Gnome Scan NG</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Étienne Bersac</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Vincent Untz</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Gnome Scan aim to make scan as simple as print for both users and developers. Gnome Scan was started during the Google Summer of Code 2006. The project continued his development, including moving to Gnome SVN, distributing in Ubuntu/universe, translating in several languages.<br>
<br>
However, Gnome Scan shows its structural limits :<br>
<br>
&nbsp;* Hard coded very limited processing (only rotation was implemented)<br>
&nbsp;* Hard coded scan option set (resolution, area, …)<br>
&nbsp;* Hard coded UI. The dialog wasn't build depending on device<br>
&nbsp;* No scan from file (useful for importing PDF with one image per page).<br>
&nbsp;* Some duplicated code<br>
&nbsp;* Quite buggy SANE handling.<br>
<br>
Also, since the beginning of Gnome Scan development, some other technologies have evolved :<br>
<br>
&nbsp;* HAL is receiving SANE support. SANE provide HAL fdi (in CVS) and HAL addon for monitoring buttons.<br>
&nbsp;* Gegl implement very nice and efficient processing pipline.<br>
<br>
Waiting for Gnome SVN account, i redesigned Gnome Scan in order to fil the lakes and take advantage over new technologies. This summer, i will implement Gnome Scan ng specification.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>WYSIWYG Documentation Editor for GNOME (Foie Gras)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Szilveszter Farkas</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Shaun McCance</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 SUMMARY<br>
-------<br>
<br>
The GNOME documentation system is under reconstruction (Project Mallard). As part of this, there is need for a WYSIWYG editor that lets anyone (both authors and contributors) to create and modify documentations easily (codename: Foie Gras).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Face detection and tagging feature for F-Spot</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andrzej Wytyczak-Partyka</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lawrence Ewing</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Within this project I would create a module for F-Spot that would make face detection on the pictures, and tagging of the detected faces possible. It would also give grounds to a future, automated system (developed after the SoC), which would give a new level of photo organization. Faces could be automatically recognized and sophisticated queries could be performed (i.e. integration with Beagle).<br>
<br>
The following link contains the full proposal :<br>
http://facedetect-f-spot.googlecode.com/files/fspot-proposal.pdf<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Voice recognition applet to control desktop</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Raphael  Nunes da Motta</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Nickolay Shmyrev</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The idea is to develop some features that will improve the usability in the Gnome Desktop. The goal is to implement a Desktop Voice Control System. The system consists in an application that will be monitoring the audio input( microphone ) and when a significant audio signal has been detected, the software catches, processes and recognizes the signal and then executes the desired action over the Gnome Desktop. In a set of actions could include maximize, minimize, close the active window; open a specific program; switching from one desktop to another; among others. The software will be implemented in C language in conjunction with CMU Sphinx, which is an open source tool, created to recognize and decode audio files in word list files. The software will be developed as a Gnome applet.<br>
<br>
The original proposal is available here:<br>
http://live.gnome.org/SummerOfCode2007/Ideas<br>

	</div>
 </td>
 </tr>
</table>
<a name='gnucash' />
<h2> gnucash </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Delimited File Importer</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Benjamin Leonard Sperisen</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Joshua Sled</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Some people already track the status of their finances with spreadsheets. They might, for example, keep a record of all withdrawals and deposits from a bank account in a spreadsheet and use the sum feature of their spreadsheet application to keep track of the balance. Such users may wish to migrate their data to GnuCash but would find the task of manually copying all of these entries into GnuCash daunting.<br>
<br>
Virtually all spreadsheet applications can export to CSV format. Therefore, I propose the development of a dialog for GnuCash to import spreadsheets in the form of delimited files. The dialog will accommodate various forms of delimited files by allowing the user to specify the meaning and order of the columns in the file, the column delimiter, and the character encoding. It will attempt to be as transparent as possible by showing the user the consequences of each configuration change instantly. To minimize the work the user has to do, a guess at the file's format will be made in the hope of providing reasonable default settings. When the user is satisfied with the configuration, the user will click a button and the transaction data will appear in the user's account.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Dogtail UI Test Harness</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ahmed Sayed Hassan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Joshua Sled</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Aim of this project is to build automated Gui test suite for GnuCash, using dogtail, my proposal is not only building this test suite but also to make it  an environment that make it easy  to create, maintain, understand GnuCash test cases, and considering all precaution that should be considered for this type of projects, consider the best practice in those systems, The Test suite will also monitor the quality of the application, by monitoring e.g.the response time of the dialogs.<br>

	</div>
 </td>
 </tr>
</table>
<a name='gnu' />
<h2> gnu </h2>
<table>
 <tr>
 <th>Title</th>
 <td>GRUB2 CD-ROM Boot Support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alexandru Roman</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jeroen Dekkers</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The aim of this project is to implement CD-ROM booting support in GRUB2. First, an INT13 calls driver will be implemented to provide access to the boot image. This has the drawback that it relies on a relatively new compliant BIOS (some BIOSes are buggy). Second, a full ATAPI driver will be implemented to do the same function, hopefully on any setup (including older and buggy BIOSes).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>User defined out of date decission for GNU make and persistent variables.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ramon Garcia Fernandez</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Paul Smith</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The purpose of this project is to extend GNU Make with user defined method for deciding when a target is out of date. Persistent will be also added because it is necessary to make this useful, for example, for using MD5 sums for checking if a source was modified since last compilation.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Mailutils: Add TLS capability to IMAP and POP client code.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Wojciech Polak</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sergey Poznyakoff</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to develop GNU Mailutils[1] TLS encryption (Transport Layer Security) to all client-side code, particularly to 'mail' utility (IMAP and POP client) and Sieve filter. Client-side encryption will secure fetching/sending of e-mails from/to remote connections and will allow to use mail services which don't work without encryption (like Gmail for instance). I have already implemented TLS to the server-side code (pop3d and imap4d), which is now part of the Mailutils framework, as well as I did some other miscellaneous contributions. My work will be based on using GnuTLS library[2] as the encryption backend. GnuTLS is part of the GNU project.<br>
<br>
References:<br>
[1] http://www.gnu.org/software/mailutils/<br>
[2] http://www.gnu.org/software/gnutls/<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Gnome/GStreamer Desktop sound integration for Java</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mario Torre</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mark J. Wielaard</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In the last years, Java has seen various efforts in the direction of Desktop integration, but the various implementations still lack important functionalities, and this is especially true on GNU/Linux and the other FLOSS systems, though luckily GNU Classpath is pioneering in this area, paying already a particular attention to the Desktop integration.<br>
<br>
One of the area still uncovered by this integration is that of the sound editing/streaming.<br>
<br>
Many solution exist for native applications, but they are not accessible to java programs and in a standard way, and this lead to poor performance, duplication of code and an overall bad user experience, GStreamer is a versatile framework for creating streaming media applications, and is the default framework used by the Gnome Desktop Environment and by most distributions; javax.sound, aka Java(TM) Sound API, is a low-level API for controlling Input and Output of sound media and is the standard API for use by all the Java applications.<br>
&nbsp;<br>
GStreamer is so widespread as default and provide most of the functionality that the Java Sound API requires, that makes sense to implement javax.sound peer classes that natively use GStreamer as a backend for data transport and audio format handling, enabling so<br>
Java desktop application the access to Formatted Audio data and<br>
sound pipeline creation directly via Gstreamer.<br>
&nbsp;<br>
Part of the Goal is also to develop simple applications and Mauve<br>
Test classes, to show the validity of the project and the final results.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GNU Hurd libchannel</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Fredrik Hammar</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Richard Braun</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The GNU Hurd needs a library that abstracts the idea of a character<br>
device to ease the clean and efficient implementation of their<br>
corresponding translators.  It has been recognized as needed for a<br>
long time and some tasks have been stalled because of it's lack.<br>
<br>
Not only could such a library enable quicker and cleaner<br>
implementation of many translators that directly corresponds to kernel<br>
implemented devices, such as keyboards and mice.  It would also allow<br>
this for character devices that are layered on top of other devices.<br>
<br>
The goal of this project is to design, implement and document<br>
this library, which will be called `libchannel'.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Generics support in Portable.NET</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ivan de Jesus Deras Tabora</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Klaus Treichel</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The basic idea of this project is to extend Portable.NET to support generics in the C# compiler and the Portable.NET Virtual Machine based on the ECMA standard 334 and 335.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Graphical navigation/representation of knowledge base; and interfacing with other knowledge systems.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Rakesh Pandit</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Nagarjuna Gadiraju</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My proposal is aimed at providing two functionalities to GNOWSYS. First<br>
is to provide a model which can be used by a Web browser, Gnowser or an application to make concept maps of the knowledge base stored by GNOWSYS. Second is to provide a single unified framework for importing<br>
and exporting the knowledge base and its organization in RDF, OWL, XTM,<br>
CL, KIF, LISP, Prolog, CNL and other such languages for seamless interoperability.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>SyncML interface for phpGroupWare</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Johan Gunnarsson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Dave Hall</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My idea is to design and implement a synchronization interface for the phpGroupWare project. External devices such as cell phones and PDAs will be able to keep a synchronized copy of parts of their phpGroupWare data, for example your calendar.<br>

	</div>
 </td>
 </tr>
</table>
<a name='gnustep' />
<h2> gnustep </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Key Value Observing and Bindings implementation</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christopher Farber</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Nicola Pero</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I would like to finish GNUstep's Key Value Observing implementation and implement bindings. I am interested in this because KVO and bindings would lead to faster, easier application development, cleaner code, and bring GNUstep closer to compiling the majority of Cocoa code without modification.<br>
<br>
Key Value Observing is necessary to implement bindings, and would increase the flexibility of GNUstep's KeyValueCoding implementation. Bindings support would eliminate the need for most outlets and controller code that deals with updating the status and value of UI controls while reinforcing the separation between Controller and View in the Model-View-Controller design pattern. As most modern Mac OS X applications take full advantage of KVO and Bindings, a GNUstep implementation would be a huge step toward source-level compatibility with Mac OS X.<br>
<br>
My work would include creating the NSController, NSArrayController, NSObjectController, and NSValueTransformer classes and adding bindings support for existing classes, for example NSTextField, NSPopUpButton, and NSProgressIndicator.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improving GNUstep AppKit components and the Text System</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christopher Elsmore</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David Chisnall</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Improving the GNUStep AppKit components will help to develop GNUstep and increase compatibilty with Cocoa.<br>
I shall be Implementing a modified NSBitmapImageRep class to write GIF, JPEG, PNG &amp; PNM files. I shall also be producing implementations of NSDatePicker, NSLevelIndicator and NSCell classes.<br>
<br>
However the main body of the project shall be focused on examining, finishing, rewriting and generally cleaning up the whole Text System, and profiling it.<br>
<br>
This will benifit GNUstep by having more features in the framework, as well as a clean Text System, suitable for testing.<br>

	</div>
 </td>
 </tr>
</table>
<a name='google' />
<h2> google </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Sockets for Google Web Toolkit</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Aleksey Lagoshin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Dan Morrill</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 During application development, fairly often appears a nessesity in sockets use. Applications written using<br>
Google Web Toolkit aren’t the exception. Unfortunately, most of browsers are devoid of possibility to connect<br>
with other computers by means of sockets. So when such necessity appears, developers have to write a server-side<br>
implementation (Java Servlets, PHP, ASP.NET or something else), which could realize connection with other computers<br>
by sockets and transfer received data to a browser, using, for example, AJAX. Unfortunately, such solution has it’s own<br>
disadvantages because of the server-side can’t notify the browser of data receiving. Standard and somewhat slow<br>
decision: a browser is querying new data every n seconds. Also more interesting solutions exist, such as Comet and<br>
Continuation, but they also have some disadvantages. But the main shortcoming in such realization of socket support<br>
for browsers is the necessity to write a server-side, which will essentially load a server while numerous users use it.<br>
<br>
I suggest to realize socket support in Google Web Toolkit on a browser level using GWT Socket module.<br>
<br>
There are some means to realize it:<br>
<br>
1. Java Applets<br>
2. Macromedia Flash<br>
3. XPCOM (Only for Firefox)<br>
4. ActiveX (Only for Internet Explorer)<br>
<br>
Solution based on Java Applets.<br>
- Needs Java virtual machine and Java Plugin.<br>
- Could run on any platform in any browser supporting Google Web Toolkit.<br>
- It is possible to use wide Java capability.<br>
- Includes writing small Java Applet, which will fulfil connection by means of sockets.<br>
- Applet is easy enough to realize.<br>
<br>
Solution based on Macromedia Flash.<br>
- Needs installed Macromedia Flash plug-in in client's browser.<br>
- Could run on any platform in any browser supporting Google Web Toolkit.<br>
- It is necessary to write LiveScript code, which will fulfil connection by means of sockets.<br>
<br>
Solution based on XPCOM.<br>
- Doesn't need any additional plug-ins.<br>
- Could run in FireFox browser only.<br>
- Demands knowledge of XPCOM.<br>
<br>
Solution based on ActiveX.<br>
- Needs an ActiveX component, which will fulfil connection by means of sockets.<br>
- Could run in Internet Explorer only.<br>
- Demands knowledges in ActiveX component writing.<br>
<br>
Taking to account that Java and/or Flash are installed by almost every user, Socket module will include both these solutions.<br>
The module will be flexible enough in order to the developers’ possibility of adding solutions based on XPCOM and ActiveX,<br>
in case of need if necessary.<br>
<br>
The module will consist of Flash and Java applets, corresponding communication between applet and GWT, and clean enough<br>
interface for developers.<br>
<br>
Sockets module will essentially facilitate GWT based application development, which need a possibility to work with sockets.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>phpAspect eclipse plugin</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>WIlliam Candillon</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Vanwormhoudt</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 phpAspect is a PHP language extension to implement Aspect-Oriented Programming (phpaspect.org).<br>
<br>
The goal of this project is to write a phpAspect plugin for eclipse in order to make people able to use phpAspect easily in their projects.<br>
This plugin will have the following features:<br>
* Support of phpAspect syntax<br>
* Embedding phpAspect<br>
* The vizualisation of cross references.<br>
* The vizualisation of advices into the business logic.<br>
* The vizualisation of code refactoring effects in the functioning of aspects.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GWT for Gadgets/Widgets</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Tomasz N. Kolodziejczyk</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kelly Norton</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Google's web toolkit is a great tool for writing large web applications that depend heavily on javascript, and since the primary functionality for gadgets is written in javascript it seems reasonable to use GWT to write gadgets. For my summer of code project I would like to extend GWT to make the process of writing gadgets in it less of a challenge. I would like to add functionality to ease the process of writing gadgets for multiple frameworks by allowing writers to focus on functionality rather then implementation.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Java API Compatibility Validator</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Aleksandar Pantaleev</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Miguel Mendez</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 It is my understanding that the Google Web Toolkit would be much benefited by having a tool that &quot;could examine two versions of a set of Java classes and report on interface changes that affect user code,&quot; as per http://code.google.com/p/google-web-toolkit/wiki/GWT_GSoC . I propose to complete such a tool within the timeframe of Google's Summer of Code 2007.<br>
<br>
As a Ph.D. student in Software Engineering / Software Analysis and Understanding, I have ample experience with various algorithms and data structures relevant to analyzing object-oriented source code and runtime behavior. What is more, Java has been my first language of choice for implementing analysis tools, which is directly pertinent to the needs of the Google Web Toolkit.<br>
<br>
I am slightly puzzled by the suggestion to use Java reflection to solve the problem, as that is sub-optimal in my opinion, and in fact is a step that can be skipped. A better solution would be to employ direct comparison of the Abstract Syntax Trees (AST) of the two versions of Java classes, and report the corresponding differences. I propose to develop a tool that will:<br>
<br>
- Build the Abstract Syntax Trees of the Java classes in question.<br>
- Compare pairs of Abstract Syntax Trees to encounter any changes between two versions of a set of Java classes.<br>
- Report the identified differences in a concise structure that can be either examined by a human, or passed on to automated tools.<br>
<br>
Further capabilities can be included in the tool as suggested by mentors and as time permits.<br>

	</div>
 </td>
 </tr>
</table>
<a name='haiku' />
<h2> haiku </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Network stack revamp: IPv6, ICMP, multicast, etc.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hugo Santos</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Axel Dörfler</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In today's world, where almost every bit of information is available online, where people communicate via the Internet and develop open-source projects in Internet communities, a stable and feature rich network stack is absolutely required. One, that besides supporting current technology, is able to adapt to future trends, including security and mobility. We want to provide the best experience to users, and within the open-source spirit by being connected allow them to be an integral part of new developments as well.<br>
<br>
&nbsp;&nbsp;&nbsp;Haiku's current network stack, which is implemented in C++, is presently giving it's first steps. Some initial IPv4 support has been implemented, as well as some UDP and TCP. Although this initial code has been enough to complete some basic operations, some standard support is still missing. A few additional features could also be added to allow a richer experience, specially considering a future of mobile IP hosts communicating securely. Some of the crucial points to be dealt with presently, identified by both the development community and the author, include:<br>
<br>
&nbsp;&nbsp;&nbsp;* IPv6 support -- Although IPv4 is still the de facto Internet protocol, both enterprises and education networks are starting to migrate to this new Internet Protocol which introduces a larger address space, mandatory multicast and security (IPSec) and end-to-end mobility.<br>
&nbsp;&nbsp;&nbsp;* ICMPv4 and ICMPv6 support -- a host should both have a proper behavior in IP networks, generating errors whenever required, and be able to optimize it's communication by discovering the MTU between hosts, etc.<br>
&nbsp;&nbsp;&nbsp;* Multicast support -- IP multicast has a wide range of uses, from      allowing applications to deliver their content to a large set of receivers with minimal effort and excellent scalability; to allowing new kinds of auto-configuration and discoverable services to be implemented, such as ZeroConf.<br>
&nbsp;&nbsp;&nbsp;* Stacked destinations / end-points -- to allow the usage of transparent security (IPSec) and mobility (Mobile IP).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Create a thread scheduler with CPU affinity</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>André Braga</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Axel Dörfler</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 For this GSoC application, I intend to finish the design and implementation of an O(1) scheduler originally written as an Operating Systems class assignment. The approach used to select threads is pretty different from existing O(1) algoritms, and it has shown very promising results compared to existing O(n) algorithms and scheduling policies (as expected). Comparison with existing O(1) implementations is on the TODO list.<br>
<br>
The design and implementation must be finished to take into account thread blocking, real time constraints and CPU affinity, and of course it must be benchmarked against the current O(n) Haiku scheduler and, preferably, also against other existing O(1) implementations, for example the one found in the 2.6 Linux kernel series and also the ULE and CORE series of FreeBSD schedulers.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>USB isochronous streams</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Salvatore Benedetto</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Oliver Ruiz Dorantes</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Isochronous stream is one of the 4 USB transfer type that is missing from Haiku. Devices like webcams or usb audio cards are based on this transfer type, and therefore it is not possible at the present time to use those type of devices.<br>
<br>
Implementing it would increase the number of devices supported on Haiku.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>FireWire stack for Haiku</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>JiSheng Zhang</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jerome Duval</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 IEEE1394(FireWire) is high speed, low cost Serial Bus suitable for use as a peripheral bus. Current Haiku operating system lack of support to FireWire. My work is porting FreeBSD FireWire stack with mass storage and DV support to Haiku. My work will focus on the following tasks:<br>
<br>
1.Transaction layer driver. Asynchronous and isochoronous transmission support. Protocol standard: IEEE1394-1995 and IEEE1394a-2000<br>
<br>
2.Link layer especially OHCI driver. Protocol standard:Open Host Controller Interface v1.1<br>
<br>
3.Add support for DV cameras. Protocol standard:IEC61883 and SBP2<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Package (.pkg) installer for the Haiku Operating System</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Łukasz Zemczak</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ryan Leavengood</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Haiku Operating System finally reached the point where binary compatibility with BeOS is no more much of a problem. The only obstacle left for the user to enjoy the goodness of this very important feature is the .pkg package format. Many applications made for the BeOS platform use and prefer this type of data storage. At this stage of development, the existence of a .pkg compatible package installer would be a powerful addition to the system.<br>
<br>
PackageInstall will be a simple .pkg package installer. It will be mostly based on the BeOS default pkg installer, offering a user friendly, lightweight interface. It will be written in C++, using the Haiku API.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implement a precache algorithm along with aging policy for the file system caches</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Krishna Kishore Annapureddy</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>François Revol</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Precaching is an important feature for filesystem caches. The performance of the applications at the user-end can significantly increase with proper precaching module in place. Haiku file cache has an API for precaching. But the current launch_speedup module is very basic and simple. No precaching is implemented. I propose to implement the precaching algorithm for launch_speedup module.<br>
<br>
In Haiku the dirty blocks remain in VM until there is an explicit call to 'sync' system call. This might result in data loss because of power outages or sudden system crashes. In the light of the above issue I also propose to implement aging policy of the file system caches.<br>

	</div>
 </td>
 </tr>
</table>
<a name='handhelds' />
<h2> handhelds </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Finishing linux 2.6 for h5000 devices</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Milan Plžík</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Anton Vorontsov Vladimirovich</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 HP iPAQ h5000 series are older, but not rare devices, which are, except for their native operating system, capable of running linux. They are working very well when it comes to linux 2.4 kernels. But these kernels are already slightly older and more recent software doesn't seem to run without required modifications with them, e.g Hardware Abstraction Layer requiring sysfs will not run correctly without some sort of emulation layer.<br>
<br>
&nbsp;&nbsp;There is also linux 2.6 kernel running on these devices, but there are still some things missing to make these devices ready for production use. Aim of this project is to complete 2.6 kernel support, ideally to A+ support according to handhelds.org evaluation. This includes support for virtually any device available on h5550 device, which is almost superset of hardware found in these devices.<br>
<br>
&nbsp;&nbsp;If there will be enough time, sleeve support could also be on plan, eventually even accelerated driver for mq1132 graphics chip.<br>

	</div>
 </td>
 </tr>
</table>
<a name='haskell' />
<h2> haskell </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Darcs Conflict Handling</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jason Dagit</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David Roundy</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this proposal is to redesign the way Darcs handles conflicts and automatic merging to solve the current practical and theoretical problems with conflicts.  Informally a  conflict happens when two patches cannot be automatically merged into one repository.<br>
<br>
Darcs suffers from several flaws in the way it handles conflicts between patches.  Improper conflict handling in Darcs results in problems such as exponential time required to merge changes or failure with an error message.  When this happens the user is left to manually merge and patch their repository which frustrates users and defeats the purpose of version control tools.<br>
<br>
The problems with conflict handling were believed to be rare but large projects such as GHC have shown that conflicts are more common in practice than originally believed.  It is commonly believed that improper conflict handling is the biggest flaw of Darcs and must be fixed as soon as possible so that Darcs may reach its potential.<br>
<br>
By using a graph structure to store the relationships between conflicting patches, less  re-computation will be involved in each merge and the decisions the user has made in the past about previous conflicts may also be stored.   Storing this data will allow Darcs to handle future conflicts efficiently and correctly.<br>
<br>
An important goal of this work is to maintain the current level of abstraction for the user.  The user should be able to continue working with repositories as sets of changes.  The modifications to the user interface should be minimal while the changes to the user experience should be great.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Rewrite the typechecker for YHC and nhc98</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mathieu Boespflug</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Malcolm Wallace</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to reimplement the type checker used in both the nhc98 and<br>
YHC compilers, using Constraint Handling Rules (CHR) and based on work in the Chameleon project.<br>
<br>
* Motivation<br>
<br>
The current typechecker used in both compilers seems to be largely<br>
unmaintained, is difficult to understand and extend, and is<br>
occasionally wrong. Many common type system extensions to Haskell 98<br>
remain unsupported.<br>
<br>
In light of the upcoming Haskell' report that is likely to extend the<br>
type system in a number of ways (eg MPTC+FD, rank N types [1]), it is<br>
becoming increasingly important to the maintainers that the<br>
capabilities of the type system remain up to date, and to provide a<br>
simple and easily extendable platform for further research and<br>
experimentation with type systems. From a larger perspective, it is<br>
important for the good health of Haskell as a language that we<br>
maintain a certain amount of variety in implementations and offer<br>
viable alternatives to GHC.<br>
<br>
The goals for the type checker are:<br>
<br>
1. To be simple and easy to understand<br>
2. Easy to extend<br>
3. Provide good error messages.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Generalizing Parsec to ParsecT and arbitrary input (ByteStrings)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Paolo Martini</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Philippa Jane Cowderoy</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Generalizing the Parsec interface with a monad transformer for ease of use<br>
for the programmer, and get the best out of the new fast ByteString IO layer.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Shared Libraries for GHC</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Clemens Fruhwirth</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Simon Marlow</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Glasgow Haskell Compiler (GHC) links the executables it produces statically to Haskell packages. This not only wastes disk space but also leads to an increased loading time for the program itself and GHC Interactive.<br>
<br>
This application is about making GHC able to link to shared libraries of Haskell packages, reducing disk usage and loading time. Shared libraries are also shared in memory by Linux, hence the effective memory usage of a set of concurrently running Haskell programs is reduced.<br>
<br>
Requirements for shared libraries in GHC:<br>
1. Build object code as relocatable PIC code.<br>
2. Link PIC object into shared libraries.<br>
3. Patch GHC to make use of this shared libraries when producing exectuables.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Extending GuiHaskell: An IDE for Haskell Hackers</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Asumu Takikawa</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Neil David Mitchell</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 --Introduction--<br>
<br>
&nbsp;The success and penetration of a programming language or platform often hinges on the tools that are available for use with that language. For example, a widely cited reason for the popularity of Microsoft's .NET platform is because of the ease of use offered by the VisualStudio IDE. Even more obscure languages have benefited from a robust tool-set. Scheme, a language noted for its use in education, has Dr. Scheme[1], an IDE developed and used with the How to Design Programs textbook. Haskell itself has likely observed a boost in popularity with Darcs, a flagship product of the community that is used throughout Haskell development now. Given this, I propose to further develop GuiHaskell[2], an existing effort to develop a useful Haskell IDE.<br>
&nbsp;<br>
--Status--<br>
<br>
&nbsp;At the moment, GuiHaskell is capable of running a Hugs and GHCI environment inside of it. However, one cannot switch between the two without editing the source and re-compiling. Most of the toolbar buttons are also non-functional.<br>
<br>
I propose to add the following capabilities within the three month allocation:<br>
<br>
* Capability of running main Haskell implementations, e.g. Hugs, GHCI, Yhc, nhc, Jhc, etc.<br>
* Functioning toolbars and menus.<br>
* Create a framework for linking the application with existing Haskell tools, e.g. debuggers, profilers, etc.<br>
<br>
The following features will be looked into and worked on if there is additional time (I estimate that there will be):<br>
<br>
* Profiling.<br>
* Cabal integration for building and installing packages.<br>
* Hoogle support.<br>
* Support for a debugger.<br>
* Syntax highlighting.<br>
* Simple editor integration: open up an editor separately and jump to the appropriate line on an error in the REPL. Hyperlink to the editor instead of embedding it.<br>
* Editor embedding: external editors can be integrated into the application using GTK's Plug and Socket widgets (see PIDA[3] for example). This would allow the use of vim and possibly emacs within the IDE (a desirable feature because it would decrease the learning curve for users of those editors).<br>
* Editor-pane and REPL-pane: DrScheme uses an interface where the main pane contains a standard editor that can save and open files and a secondary pane contains the REPL. When the evaluator is run, the file opened in the main pane is run and any functions or variables defined can be used from the REPL. This design would fit the Haskell development cycle as well.<br>
<br>
Here I will list some additional niceties that could be added to the project after the summer of code:<br>
<br>
* User's manual and in-depth documentation of features.<br>
* Expand IDE to include advanced features such as class/type browser panes and project management like other full-featured IDEs (e.g. Eclipse, VisualStudio, etc.)<br>
<br>
--Preliminary timeline--<br>
<br>
Planning: Decide whether to extend PropLang, re-write using Gtk2Hs, or extend using Gtk2Hs. (I have taken the third approach in initial patches because it is easiest for now)<br>
Week 1-2: Support for adding multiple Haskell environment and the capability of switching between them.<br>
Week 3-4: Get menus and toolbars functioning to the level of WinHugs at least.<br>
Week 5: Investigate how to integrate external tools into the IDE. It may be helpful to look at the approaches of other IDEs (e.g. PIDA, Eclipse, etc.) as well.<br>
Week 6: Work on integrating cabal tools.<br>
Week 7: Work on integrating profiling tools.<br>
Week 8: Additional time for integrating cabal/profiling. Start on hoogle integration or syntax highlighting.<br>
Weeks 9 and beyond: Add additional features (e.g. editors, debugger, etc.) and streamline the existing ones (e.g. one-click operation).<br>

	</div>
 </td>
 </tr>
</table>
<a name='iem' />
<h2> iem </h2>
<table>
 <tr>
 <th>Title</th>
 <td>VideoIO</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Thomas Holzmann</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>IOhannes m zmölnig</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 VideoIO Framework for GEM<br>
<br>
This framework should be implemented via a plugin architecture (the various i/o modules are to be loaded at runtime).<br>
It will be made available on all major platforms that are supported by pure-data: linux, os-x and windows.<br>
<br>
The following points should be realized:<br>
* read/write video from/to firewire<br>
* read/write from/to files with various de/coding libraries<br>
* evaluation of libraries and desicion which one will be used (quicktime, directshow, libxine, mplayer, aalib,...)<br>
* implementing Video4Linux Loopback Device<br>

	</div>
 </td>
 </tr>
</table>
<a name='ikiwiki' />
<h2> ikiwiki </h2>
<table>
 <tr>
 <th>Title</th>
 <td>latex plugin input/output for ikiwiki</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Patrick Winnertz</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Joey Hess</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I would like to write the latex plugin for ikiwiki, since I have to use latex very often for university (I use it to wrote my summaries).<br>
<br>
Nice features would be:<br>
&nbsp;- add support for exporting the page to pdf via latex (or to native tex files)<br>
&nbsp;- add support to upload latex code which is then displayed on the side (good for chemistry &amp; mathematics) (as img or html, I have to look what is better)<br>
<br>
Problems I see:<br>
&nbsp;- if people use packages which are not on the server (some chemistry packages are not yet available in debian/other distris)<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Wiki WYSIWYG Editor</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Taylor Killian</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Joey Hess</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Wikiwyg editor will be integrated into ikiwiki allowing users to edit pages with the click of a button. It will allow them to edit wiki pages just like they were using a word processor.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Creating a gallery of a bunch of images</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Arpit Jain</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Alexander Wirt</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In wiki pages you are allowed to edit text and save it but nowhere it is allowed to add images and also display some of their information automatically. Ikiwiki has done some work in this area but it has huge scope for improvements. It will be very useful for users to be able to add or edit their images, comments etc:- with the same ease and efficiency as is done for text in a wiki.<br>
<br>
I plan to implement automatic extraction and displaying of information like resolution, exif metadata in ikiwiki. I will also add functionality to create thumbnails, allow commenting using AJAX, rating and embeding watermark. Some Javascripts will be used to enhance the image browsing features in ikiwiki.<br>
<br>
There would no longer be need of a completely different site for uploading images like flickr. You can have your text documents and images at the same place in ikiwiki.<br>
<br>
Contact: http://www.arpitjain.com<br>

	</div>
 </td>
 </tr>
</table>
<a name='inkscape' />
<h2> inkscape </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Text Improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gail Carmichael</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Richard Hughes</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My proposal contains various tasks that would enhance the user's experience of Inkscape's text tool, including addressing issues with font family variants, implementing advanced character insertion, legalizing flowed text, improving character and paragraph styles, and redesigning text user interface elements.  A subset of these tasks will be completed at the discretion of the mentor, on a priority-per-item basis.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Live path effects in Inkscape</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Johan Engelen</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Aaron Spike</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 At the moment, effects on paths are possible through the use of external extensions. These extensions are not 'live' in the sense that they are not interactive: if a modification to the effect is required, one has to recreate the situation before the effect was applied and run the extension again. Live path effects will make many of these extensions interactive and live on-canvas. For example the path along path effect will hugely benefit.<br>
Within this project, the underlying infrastructure will be created as well as a common framework and a couple of effects, including a basic UI to apply these new live effects.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>3D box tool for Inkscape</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Maximilian Albert</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>bulia byak</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Even in the framework of 2-dimensional vector graphics and illustrating, it is often desirable to edit objects 'in a 3D fashion', for example when drawing perspective representations of 3-dimensional scenes (as technical illustrators would want to do), but also in a lot of situations when creating 'pure' artwork.<br>
<br>
The proposed 3D tool will render this possible in Inkscape in a very intuitive and flexible way, by allowing the user to draw 3D boxes with arbitrary perspectives, freely move the vanishing points/perspective lines, move the boxes 'towards a vanishing point' (preserving the perspective), possibly rotate them 'in 3D', and many more things.<br>
<br>
Once this basic tool is available, its functionality can be used to implement a wide range of further enhancements with regard to 3D aspects (like extruding objects, drawing on inclined planes, etc.).<br>
<br>
See the accompanying web page http://www.rzuser.uni-heidelberg.de/~malbert for details.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>UI for SVG Filter Effects</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nicholas Bishop</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>MenTaLguY</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This goal for this project is to design and implement a complete user interface for SVG filter effects.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Raster Functionality in Inkscape</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christopher Brown</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Theodore J. Gould</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Inkscape was built purely as a vector editor – a GUI, you might say, for SVG. But the need has arisen for raster capabilities within the Inkscape application. Previous to this capability, the user would have to perform such raster post-production in a different application, such as the GIMP or Photoshop. Often this may not be anything more complicated than a punch/explosion effect or a windswept filter. This can be accomplished by integrating these effects, especially those provided by ImageMagick, directly into the Inkscape interface. The results will not be SVG, unfortunately, but they will be bitmaps, as the user desires.<br>
<br>
Mentor: Ted Gould<br>

	</div>
 </td>
 </tr>
</table>
<a name='internet2' />
<h2> internet2 </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Network Diagnostic Tool Enhancements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jakub Sławiński</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Richard Carlson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I want to enhance the Network Diagnostic Tool (NDT) in several<br>
directions.<br>
<br>
First of all, I want to design, test and implement the new detection<br>
algorithms awaited by the community. This include new duplex-mismatch<br>
detection algorithm and new congestion detection algorithms. I am<br>
going to create the semi-automated testing system to check new<br>
proposals. I will prepare the detailed reports from the testing phase<br>
and choose the best set of new algorithms for the integration with the<br>
NDT sources.<br>
<br>
The second area of development will be connected with improvement of<br>
the logging system. I will further modularize the logging system and<br>
create the possibility to use different logging front-ends. This<br>
include the databases and network-based protocols. Moreover, I will<br>
create the enhanced post-processing tool to allow administrators<br>
easily review the historical test results. I think this new tool<br>
should be written in Java using SWING to create the GUI. However, I'm<br>
opened for the possibility to write only text-mode post-processing<br>
tool.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
The third thing I would like to be done during the summer is the<br>
Microsoft Windows port of the web100clt. I know, that some<br>
administrators use this console tool for the scripting purposes.<br>
However, The I2util library used by the NDT cannot be compiled under<br>
the cygwin development environment. So the only options is to use<br>
different cross-compilation method, or modify the I2util problematic<br>
parts (IPv6 support).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Chrolog Application(second try)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Horia Vlad Balan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Aaron Brown</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I would like to apply for the Chrolog project with Internet2. I intend to use my previous experience with TSC timers and clock synchronization in LANs in order to develop a user-space solution for obtaining fast, accurate timestamps within a known error budget. I would also like to improve the methods used in maintaining an accurate system time.<br>
<br>
Note: This is my second version of the application, modified after receiving feedback.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Defining network metrics on a qualitive perspective</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Fausto Vetter</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jason Zurawski</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Network performance measurement in high speed networks is highly important once problems to users are alike to occur. It happens mainly because the expectations of the users are defined based on quality factors and network is measured based on quantifiable variables. This fact tends to difficult the way that the network performance is showed to the user of interest. Normally user is worried if he or she can download a file in a good quality or can understand a voice conference he or she is having with another user. The users expect to have the similar perceptions of the network when they are downloading a large size file or when they are using the Internet for multimedia communication, like voice, video or both together. They care about having similar quality they are used to consume on these kinds of services not served by data networks, like the quality of phone services served by the Public Service Telephony Networks (PSTNs) or the quality received on the television systems. The users are expecting to know if there is quality to run the application they want to run and not really if the network is having some specific delay or packet loss.<br>
The problem for Network Operation Center (NOCs) operators is to discover which factors for each kind of traffic affects the quality perceptions of the user. The question is how to represent these variables in an easy way and in quality perception so NOC operators may easily act upon a problem and present to the user if the quality of the network is good for defined kinds of applications.<br>
Measuring metrics in an ad hoc mode is worthless. Alone, the network metrics represent only a big amount of numbers with no sense and no qualitative information interesting to end user may be obtained from them. These metrics need to be contextualized to the pattern of traffic they are meant. Using some kind of baseline technique, it is needed to create a pattern behavior of the metric on normal condition to be able to NOC operator to observe ranges of quality in these quantifiable variables. After this, the traffic should be qualified in ranges that will permit a NOC operator to inform the quality of that kind of traffic. Then, metrics may be correlated to observe how one metric influence others.<br>

	</div>
 </td>
 </tr>
</table>
<a name='jikesrvm' />
<h2> jikesrvm </h2>
<table>
 <tr>
 <th>Title</th>
 <td>JMX Implementation</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andrew John Hughes</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Peter Donald</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Java Standard Edition class library[1] for Jikes RVM is provided by the GNU Classpath project, which focuses on the creation of a Free Software[2] clean room implementation.  As part of Summer of Code 2006, I provided Classpath with the necessary API interfaces and a VM layer for implementing java.lang.management, which allows the running virtual machine to be monitored and controlled either locally or remotely.  This year, I propose to provide an implementation of the VM layer for Jikes RVM, where such code will enhance the collation of research results and provide a uniform layer for comparisons.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Adding JDWP and JVMTI support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Eslam Ahmed Almorshdy</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ian Rogers</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Abstract<br>
========<br>
<br>
JDWP &amp; JVMTI  are standards introduced by sun to uniform the way JVM[s] are debugged/queried. They are not mandatory nor do they form requirements to comply with the JVM standard. Here I propose to enable those standards in the Jikes Research Virtual Machine. enabling those standards would greatly help the development/research process of the Jikes RVM itself as well as the applications that runs on it.<br>
<br>
Keywords:<br>
=========<br>
Debug protocol, Java, Virtual machine, JDWP, JVMTI.<br>
<br>
Motivation and Background:<br>
==========================<br>
Jikes is a Research Virtual machine developed by IBM. Jikes was released as an open source project and follows open source development model. It lacks conformance to the JDWP/JVMTI standards. They are not part of the JVM specifications.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Graph Coloring Register Allocator</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alexey Gorodilov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ian Rogers</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Jikes RVM optimizing compiler was originally designed for Power PC. Having 32 registers, register pressure on Power PC wasn't a big issue but the performance of the register allocator was. Given spills and fills were rare the trade-off suggested that linear scan was a good register allocator for the Jikes RVM. When the Jikes RVM was made open source a new Intel back-end was added. On x86 number of registers had decreased from 32 to 8. x86 is architecture where the problem of graph-coloring  register allocation is complicated by irregularities in the organization and use of the architecture’s register resources. I propose to implement Iterated-Coalescing Graph-Color Allocator with modifications for irregular architectures. This allocator uses interference graph to represent all program constraints.<br>
<br>
Original proposal:<br>
http://alexeigor.googlepages.com/gsoc2007.pdf<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Vectorization</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>jisheng zhao</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ian Rogers</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Vectorization is an important optimization to enable parallel code<br>
speedup within a single processor core. Currently, most mainstream<br>
general purpose processors provide support for vector/SIMD operations,<br>
such as MMX in Intel processors and AltiVec in PowerPC<br>
processors. Vector/SIMD operations are ones that perform a related<br>
function on multiple pieces of data in parallel. These operations can<br>
give important speedups for certain classes of application, such as<br>
multimedia programs.<br>

	</div>
 </td>
 </tr>
</table>
<a name='joomla' />
<h2> joomla </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Extending the Nested Sets Model with &quot;Hardlinked Nested Sets&quot;</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Enno Klasing</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Louis Benton Landry</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Some of the most often requested new features for Joomla! are the abilities to<br>
nest categories in an unlimited depth, and to place content into more than one<br>
category. The usage of the Nested Sets Model offers an elegant and efficient<br>
solution to this feature request.<br>
<br>
During this year's Google Summer of Code, I would like to extend the current<br>
Node Based Scheme libraries [1] – which implement a Nested Sets Model – with a<br>
feature which I call &quot;Hardlinked Nested Sets&quot;. Often it is needed to place the<br>
same item into different parent items at the same time. This is a simple task<br>
when dealing with just one single item each time. However, as soon as one wants<br>
to duplicate a complete branch of items (e.g. for categories with sub-items in<br>
it), this task becomes a whole lot more complicated.<br>
<br>
Data integrity, execution time and the forming of valid routes to such sub-items<br>
are three major issues which need to be taken into account.<br>
<br>
&nbsp;* Data integrity should be achieved at the library level, so that whenever a<br>
&nbsp;&nbsp;&nbsp;node which has hardlinked duplicates is being changed, all duplicated nodes<br>
&nbsp;&nbsp;&nbsp;will be changed as well. The Nested Sets Model (which is used by the NBS)<br>
&nbsp;&nbsp;&nbsp;already performs non-atomic actions, and therefore requires transactions.<br>
&nbsp;&nbsp;&nbsp;So if all extensions use the provided libraries, data integrity can be<br>
&nbsp;&nbsp;&nbsp;guaranteed.<br>
<br>
&nbsp;* When the main functionality becomes implemented in the data-changing<br>
&nbsp;&nbsp;&nbsp;routines, the &quot;Hardlinked Nested Sets&quot; feature will have a very small impact<br>
&nbsp;&nbsp;&nbsp;on execution time of data reading functions, but requires a little bit more<br>
&nbsp;&nbsp;&nbsp;time for storing data.<br>
<br>
&nbsp;* Routes to such hardlinked sets should still contain the IDs or names of the<br>
&nbsp;&nbsp;&nbsp;original items (except for the item where the linked branch starts), to<br>
&nbsp;&nbsp;&nbsp;present unique IDs or names to the outside (important e.g. for human readable<br>
&nbsp;&nbsp;&nbsp;URLs) and inside (important for future ACL implementations).<br>
<br>
[1] http://code.google.com/soc/2006/joomla/appinfo.html?csaid=23A1F7A6CF74EC01<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Email Interface for Publishing</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nur Aini Rakhmawati</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mateusz Krzeszowiec</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My idea for JOOMLA development is making of email interface for<br>
JOOMLA publishing. Why is email interface needed ? Quickening and make it getting easier communications and news publication. This email Interface provides function as media a author to write article in JOOMLA site without requiring to visit the the website. When article the sent to website hence publisher will get the notification  by his email whether there is new article that needs immediately reviewed and published. A publisher will visit to read the the article in website or can directly agree by email.<br>
<br>
Perhaps that idea is not really needed on country that provides high bandwidth and cheap internet payment. But it is important thing for countries that has limited bandwidth and expensive internet cost such as my country (Indonesia).  For Indonesian people, it is prefer to check his email first than his website. Because it needs small bandwidth.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Semantic Web Integration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Charl van Niekerk</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robert Schley</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently, the web can be a real challenge to those living with disabilities. Screen readers, Braille displays and other accessibility tools convey data but yet often fail to help the user understand that data. Visual cues such as colours, text formatting, layout, graphics, etc. help to convey certain meanings to the typical user but can easily leave others behind.<br>
<br>
Also, many tasks that are currently being performed by hand can be automated. For example, when I view a web page with a person's contact details, I have to copy and paste the information into the relevant fields of my address book application in order to save it for easy reference. The computer should be able to know which information is where on the page and do this job for me with only one or two clicks.<br>
<br>
Web Standards and the Semantic Web are the W3C's solutions to these problems. The idea is to not only store data, but also some of the meaning that's associated with it. This will help the computer &quot;understand&quot; the data better and will enable it to not only convey this meaning to users in a customised fashion (in the case of disabled users) but also automatically do some tasks with the data not before possible.<br>
<br>
Correct user of technologies such as (X)HTML, Microformats and RDF that already exists today can create improved accessibility and automation for all kinds of users. And because these technologies are royalty-free open standards, they can be implemented and used by anybody in an inter-operable fashion.<br>
<br>
The project will focus on the improvement of the (X)HTML output from the Joomla core, going as far as possible to ensure that valid and semantic markup is used. Semantic Web technologies such as Microformats and RDF will also be utilised wherever possible in order to make an entrance into the semantic web.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Geo-component for Joomla!</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mickael Maison</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Andrew Eddie</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Google Summer of Code 2007 – Joomla! organization<br>
<br>
Application of Mickael MAISON<br>
<br>
<br>
What about a Geo-component for Joomla!?<br>
<br>
<br>
What do I mean with Geo-component?<br>
Geographical information is becoming a key data on the Internet. Now many applications support KML/GeoRSS or geospatial tagging (Flickr, Google Maps/Earth, Drupal …).<br>
<br>
Because of its modularity Joomla! can become a Geospatial Content Management System (http://en.wikipedia.org/wiki/Geospatial_Content_<br>
Management_System).<br>
<br>
With a Geo-component, I mean a component which enables the user to add geographical information everywhere in Joomla! it can be useful:<br>
&nbsp;- News/Posts<br>
&nbsp;- Comments<br>
&nbsp;- User profile<br>
<br>
Then all this data would be publish using GeoRSS and KML feeds<br>
<br>
<br>
<br>
How is the project composed?<br>
This project is composed of 4 main blocs:<br>
<br>
- The administration bloc:<br>
Where all the configuration will be accessible<br>
<br>
&nbsp;- The user bloc:<br>
Enabling an easy geo-tagging<br>
<br>
- The feeds management:<br>
KML, GeoRSS Simple and GeoRSS GML feeds<br>
<br>
- The creation of the adapted documentation.<br>
It will be provided as a FAQ or tutorial and will explain in details how it works.<br>
<br>
<br>
<br>
What are the benefits for Joomla!?<br>
Geographical data is becoming a key interest dataset. KML and GeoRSS are starting to be widely used (i.e.: the 22nd of March 2007: Google Maps support GeoRSS). Moreover these formats are being standardized by W3C and OGC and will form a significant part of the future web.<br>
Such integration will keep Joomla! one of the more up to date applications.<br>
<br>
Then holding geographical data of the users and of the content will enable the community to build new features like:<br>
&nbsp;- Search for users close to me<br>
&nbsp;- Groups of users based on locations<br>
&nbsp;- Languages options<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Use Joomla! geo-coded GeoRSS or KML feeds in other applications<br>
&nbsp;- All the things the people will invent!<br>
<br>
Building this functionality will make Joomla! content more easy to integrate into mash-ups. Providing geo-coded content feeds will be an on-ramp for developers wishing to integrate such content into their own applications.<br>
<br>
I spoke about this project with Mikel Maron (the founder of GeoRSS) and he encouraged me to take this project forward. This functionality exists in projects such as WordPress and I am keen to see it in Joomla!.<br>
<br>
<br>
<br>
What is the roadmap?<br>
1. Specification and introduction into the community<br>
My first goal will be to publish all the specification of the project in order to clarify each part and feature which I want to develop. In the same time I will start to introduce myself to the Joomla! community (until mid May)<br>
<br>
2. Implementation:<br>
Then starting at the end of May I will implement all the features. I will use a logical order by starting with the administration part, continuing with the user part and finishing with the generation of the feeds. All these features have to be fully supported on all the common browsers (until mid August)<br>
<br>
3. Testing and documentation<br>
I count on the Joomla! community to test and give feedback as soon as the modules will be developed. But I also plan to keep some time to perform tests in order to deliver the application working perfectly in all the case with all the common browsers. I also have in mind to provide documentation (I am thinking about a tutorial) of the module to enable people to extend it.<br>
<br>
<br>
<br>
What about me?<br>
I am Mickael MAISON a 21 years old student from the University of Teesside (Middlesbrough - UK). I am currently in the third year of a BSc Computer Programming which is a yearly internship. So I am working, as a technical consultant, until this summer in Ordnance Survey (surely the place where I get this passion about location and geospatial information).<br>
<br>
I have developed a Chat component for the IRC Network EuropNet.org last year and I have been following the Joomla! project for a little while now so I think the Summer of Code is a good opportunity to enter completely as an active member in the Joomla! community.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Eclipse Plugin for develop Joomla&#39;s Component/Module</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Muhammad Fuad Dwi Rizki</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Laurens Vandeput</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Component and module is extension to Joomla. Every one can customize his CMS with add component or module into it. Developing this (component/module) is not trivial task. IDE (Integrated Development Environment) can help developer to do this work.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>General content recommendation component for Joomla</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Faolan Cheslack-Postava</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Samuel Alexander Moffatt</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 While manual content management and moderation has its established place in the world and on the internet, &quot;web 2.0&quot; has shown that there is extreme potential in algorithmic recommendation engines on both macro and micro scales. On a macro scale, it is clear from sites such as digg.com that the &quot;wisdom of crowds&quot; can be effectively utilized to filter content using the choices of many people to inform the content that will be similarly pleasing to many others. On the micro scale, there are a few sites such as reddit.com that demonstrate the possibilities of more personalized filtering still based on the wisdom of crowds. While the first steps have been taken in these areas there is much progress to be made.<br>
<br>
The goal of this project would be both experimentation and implementation. While the basics of such a filter/recommendation engine are obvious, a general purpose solution requires more consideration in order to provide the desirable features in a way that works in many different environments and for different types of content. This project would aim first to implement the basic functionality of a recommendation system into a Joomla component. After the most basic functionality is implemented, more complex filtering and recommendation algorithms can be designed and tested. By the end of the project the goal would to have a Joomla component with basic digg like functionality as well as the option of more complex general filtering and personal recommendation based on content, context, and temporal considerations.<br>

	</div>
 </td>
 </tr>
</table>
<a name='k3d' />
<h2> k3d </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Quadrilateral Remeshing</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ian South-Dickinson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Timothy M. Shead</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this project is to improve the Quadrilateral Remeshing K-3D plug-in<br>
by using a different algorithm that requires less user input. The current<br>
implementation requires the user to specify extrema points on the mesh. The<br>
proposed alternative algorithm for the plug-in will create a quad-dominant mesh<br>
that is aligned with the principal curvature directions.<br>

	</div>
 </td>
 </tr>
</table>
<a name='kde' />
<h2> kde </h2>
<table>
 <tr>
 <th>Title</th>
 <td>CMake support for KDevelop</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Aleix Pol Gonzalez</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Matt Rogers</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The main idea of this project is to provide KDevelop 4 to deal with cmake projects so anyone can easily create their own cmake project. It would be great to have this feature because cmake is the official KDE 4 buildsystem and most of the KDE related projects will be using it. Being KDevelop the KDE default development environment CMake support would be an appreciated feature for the users.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Kalzium 3D Molecular Editor</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Marcus D. Hanwell</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Benoit Jacob</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Molecular visualisation is a very important area in both scientific research and education. Having good open source tools capable of producing high quality 3D images of molecules would be useful to students from high school, up to university and research level. There are very few open source tools capable of drawing and rendering 3D molecular structures. Ghemical[1] is one such application which when coupled with Jmol[2] is capable of producing publication quality images.<br>
<br>
OpenBabel[3] is already used by many projects and allows programs to support a large array of chemical formats. Avogadro[4] is a new application and library satisfying a need in Kalzium[5] for 3D rendering of molecules as well as a wider need in the community for 3D molecular visualisation tools. Avogadro can already render 3D molecules and has basic molecular drawing facilities. It draws upon<br>
several libraries such as OpenBabel2, Qt 4 and Eigen[6] to allow rapid<br>
development. All core functionality is in the Avagadro library to allow other applications to easily use features implemented in the project.<br>
<br>
Avogadro is at an early stage of development but many basic features are already present. Avogadro will be extended to add support for custom atom/bond labels, implement POVRay[7] rendering of molecules for high quality ray traced image output and add the facility to export the 3D rendered scenes at user specified resolutions. Protein ribbon views, electronic charge and interatomic distances/bond angles would also be added as well as extensive bug testing with integrated user testing and feedback during development.<br>
<br>
Another goal is to move all calculation intensive processes (such as<br>
geometry optimisation) into a separate thread. This would maintain GUI<br>
interactivity during calculations and allow the program to display the molecule as its geometry changes. It would make more intensive calculations using the Avogadro program easier to implement and interact with.<br>
<br>
[1] http://www.uku.fi/~mthassine/projects/ghemical/<br>
[2] http://jmol.sourceforge.net/<br>
[3] http://openbabel.sourceforge.net/<br>
[4] http://avogadro.sourceforge.net/<br>
[5] http://edu.kde.org/kalzium/<br>
[6] http://eigen.tuxfamily.org/<br>
[7] http://www.povray.org/<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Kontact Journal/Blog Support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mike Arthur</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Cornelius Schumacher</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently, KDE's Kontact provides basic Journal support. However, this cannot be currently posted remotely or any more than plain-text used in creating entries. This project would improve this Journal support, integration with the KBlog blog-posting library, adding a WYSIWYG editor and other desired functionality.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>KAider, computer-aided translation system</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mykola Shaforostov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Adriaan de Groot</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 KAider is a KDE4 KBabel (http://kbabel.kde.org/) replacement that I've started in January. (see http://websvn.kde.org/trunk/playground/devtools/kaider/).<br>
My intention is to extend it to the state close to 'computer-aided translation system', i.e. tool that allows us translate more text in less time, and with higher quality.<br>
This includes following my 'maxima': majority (if not all) of actions must be accessible from keyboard, w/o using mouse, because it takes less time to press shortcut then to do things w/ mouse.<br>
All existing CAT systems don't support gettext format nicely, and don't have suitable interface<br>
(eg two panel one, like in Open Language Tools, doesn't suit for translating big paragraphs we have in .po files generated form docbook; if user wants to see context, it could be displayed in a special QDockWidget, with smaller font, etc)<br>
<br>
And, of course, they don't intagrate with KDE well.<br>
<br>
Short list of features (over what we already have in kde svn):<br>
-project management<br>
-context glossary (+sipping on google translate)<br>
-translation DB (QtSql)<br>
-mode for merging translations for editors (QA)<br>
-scripting API (kross)<br>
<br>
See<br>
http://techbase.kde.org/Projects/Summer_of_Code/2007/Projects/KAider<br>
and<br>
http://techbase.kde.org/Projects/Summer_of_Code/2007/Projects/KAider/Introduction<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improve OpenDocument compatibility in KWord</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Pierre Ducroquet</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sebastian Sauer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The office application for a Linux desktop has been OpenOffice for more than 4 years. During this time, a lot of files were generated in the OpenOffice specific format. With OpenOffice 2, OpenDocument started being used. This standard is allowing an old dream to become real : be independent from your office application, use what you want to use, be free. Currently, OpenDocument support in KOffice is quite good, but far from perfect. There may be missing features in KWord / KSpread, or just errors in OpenDocumment support breaking a feature or adding differences, breaking compatibility...<br>
The aim of this project, for me, is to be able to switch to KOffice for most of my work. It means that all the OpenDocument files I can find on my hard drive must be compatible with KOffice...<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Strigi: chemistry and biology support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alexandr Goncearenco</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Egon Lennert Willighagen</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Strigi [1,16], the fastest and smallest [2,3] desktop search engine introduced by Jos van den Oever, is a promising alternative to other tools like Beagle/Kerry [10].<br>
<br>
Strigi combines stream-based content analysis with an abstract index interface [9]. The universal metadata extractor can hugely speed up the indexing phase of any desktop search engine. On top of that, it lets the Strigi daemon be ignorant about its storage backend. Currently clucene backend performs best.<br>
<br>
Jstreams classes used in Strigi allow reading arbitrarily deeply nested files (e.g. files in a zipped email attachment) with very low CPU and memory consumption.  Strigi uses parallel analyzers that can extracts different types of data from a file in parallel. Strigi and jstreams are written in C++ with very few dependencies.<br>
<br>
KDE or any other, e.g. Gnome, applications can easily address Strigi through the DBus interface.<br>
<br>
Strigi could be integrated into core KDE4 components [7] in the near future. Its stream trough the analyzers metadata extraction system [14] has already been merged into the KDE metadata facilities. Porting of KFilePlugins is in progress [18].<br>
<br>
This project aims on making KDE a productive environment for Chemistry and Biology. Strigi can help chemical information to be semantically marked up, and easily retrieved.<br>
<br>
Kfile-chemical, like all KFile plugins, are moving to jstreams directly now [15]. Kat chemical file data analyzers can also be ported. Format detection is done by chemical-mime.<br>
<br>
OpenBabel [12] complies with Chemical MIME [4,5] and will be used to convert chemical structures to InChI strings [17] for exact molecule search [19].<br>
<br>
To extract chemical information from text documents, like PDF or HTML, chemical text mining tool OSCAR3 [20] can be used.<br>
<br>
You might want to look at Nepomuk [10], a group doing researching  into the Semantic Desktop, which (among other things) aims to develop ontologies for metadata fields. Such will have to be developed for chemical metadata. Current status of KDE integration is presented in the report [8].<br>
<br>
BENEFITS FOR KDE:<br>
- KDE4 will be the first chemistry aware desktop environment<br>
- example Strigi plugins for complex data mining<br>
- powertesting the Strigi framework<br>
- crossdesktop code reuse (benefits for other, e.g. Gnome, communities)<br>
- speedup expected after porting analyzers to jstreams<br>
- step towards the Semantic Desktop<br>
<br>
For references and up-to-date proposal visit   http://neksa.net/dokuwiki/doku.php?id=strigi_chem_bio_support<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GPS support for Marble virtual globe widget</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andrew Manson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Inge Wallin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I intend to give support for GPS devices within the Marble application, implementing a method of recording GPS data and loading saved information into the user interface keeping the interface as simple and user friendly as possible. I will also implement tracking of a GPS object that is in the meta layer. A secondary goal will be a basic implementation of support for open street map.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Amarok: Model/View implementation and usability improvements for playlist</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ian Monroe</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Seb Ruiz</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 At the heart of Amarok, the music player for KDE, is the playlist. Currently the Playlist class performs many functions. My proposal is give the playlist the tender love it truly deserves, by first making the playlist more modular and then redesigning its layout to improve its usability. The playlist is the central feature of Amarok, it needs to look good.<br>
<br>
More details at:<br>
http://amarok.kde.org/wiki/Playlist_Redesign<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Kopete messenger plugin update</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Zhang Panyong</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Matt Rogers</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Windows Live Messenger 8.1 is widely used around the world, The protocol is MSNP15.<br>
In last year's Soc MaYuan has supported the MSNP13 protocol for Gaim. The Kopete has done some work on implementing the MSNP13 in KDE4 trunks, but It's not functional,<br>
Based on messenger plugin, this project will implement a functional and stable messenger plugin for Kopete and update its protocol to MSNP15, introduce some new features such as Offline Message,Communicate with Yahoo Messenger, Roaming Contents...<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Step: interactive physical simulator for education</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Vladimir Kuznetsov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Carsten Niehaus</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of the Step is to make studying physics easier, more interesting and productive. It helps users to gain intuitive understanding of how physics works by allowing them to easily construct various experiments, interactively simulate them to see how they will evolve, adjust various physical properties to see what will change.<br>
<br>
The underlying simulation engine of Step is available as separate library called StepCore and can be used for other projects which requires simulation functionality.<br>
<br>
Step is a KDE4 application, KDE libs have already made development of Step quite faster and more enjoyable. When Step will be ready it can perfectly complement the kdeedu module and extend the realm of kdeedu to the whole new subject.<br>
<br>
I've been already developing Step for two months. With help of kdeedu people, Step has its own section on edu.kde.org: http://edu.kde.org/step/ . You can look at it to learn more about Step, its current state and future plans.<br>
<br>
Currently Step still needs more features, polishing and (especially) GUI improvements to become actually useful for education and to be included in kdeedu module. As part of the Summer of Code I propose adding some of this features and improvements to Step in order to make it more useful and ready to become a part of the kdeedu.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>KWin -- Improved Xinerama Support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Frederick Emmott</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lubos Lunak</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Xinerama (and various implementations known also as e.g. MergedFB or TwinView) is an X server extension that merges two or more physical monitors into one large display. KDE already provides a decent support for Xinerama, but there is still room for improvement, in particular, different monitors are linked together even in cases when it might be more beneficial to have them independent, for example with virtual desktops.<br>
<br>
I plan on improving support in this case, and general Xinerama issues under KDE, especially regarding multi-monitor full-screen mode in media players.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Text-tool plugins for KOffice apps</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Fredy Yanardi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tomas Mecir</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project aims to provide new plugins for the text engine of KOffice. The text plugins will mainly benefit KWord, but it is not limited only for KWord since the design of flake library allows component (shape) embedding in every KOffice application.Some of the text tools that are going to be implemented are:<br>
* Bookmarks plugin<br>
* Uppercase Text (change text to all lowercase, title cased, or capitalized)<br>
* Text replacement: Use thesaurus to do text replacement for similar words, another example is text replacement by texting language.<br>
* Colorization plugin<br>
* An optional plugin that shows a word count in a docker<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Marble KML support and creating KPart.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Murad Tagirov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Torsten Rahn</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Marble is generic map widget to display geographical data. Currently is supports basic KML objects and acts as a basic Qt application. To become more useful and part of KDE EDU in my view it should has enhanced KML support and act as KDE component (kpart). My aim is implement redesigned support of KML objects and introduce more flexible architecture with realization of basic objects meet to KML 2.1 specification and to convert Marble widget to KDE component (kpart).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Enhance KPilot record based syncing</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bertjan Broeksema</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jason Kasper</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 For a long time now kpilot is *the* application of the K Desktop Environment to sync your palm with the kontac framework. Syncing is done by so called conduits which sync handheld program data with the data of a desktop application. Most of the conduits are record-based, as in they check if records on the handheld are added/deleted/changed and update the application data and vice versa.<br>
For now each conduit did the handling of records on its own way which makes bug-solving and maintenance in general a time consuming job. Because of this, and because whe decided to port kpilot to kde4 i'll implement a more generic way of record handling which can be used by each which is record based.<br>
<br>
I'll deliver the following products at the end of the project:<br>
<br>
* Sequencediagrams/classdiagrams<br>
* Implementation of the abstract record framework<br>
* (Re)implementation of a (new) conduit as proof of concept.<br>
<br>
With this project the conduits of kpilot which make use of this will become more maintainable. It will become easier to create new record-based conduits and i'll be able to help a hand on the porting to KDE4.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Bluetooth Presence Manager (BtPM) and KDEBluetooth KDE4 port</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Juan González Aguilera</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Gollub</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Today, most people (at developed countries) carries some Bluetooth capable cell phone or, looking at the current supply at shops,  they will very soon.  Bluetooth is a wonderful technology that joins power efficiency with easiness, making things like file sharing, wireless hands free and so a  child's game. Of course, Bluetooth is not an exclusive property of the handheld world, and it's easy to find USB Bluetooth devices in the 15€/10$ range, and many new computers include it by default.<br>
<br>
In addition, Bluetooth management has been developed in the Linux world for some years, now we have the BlueZ stack integrated in 2.4 and 2.6 kernels providing a library to manipulate Bluetooth devices and a D-Bus interface with the same purpose. Also, KDE has gone it's way and has the KDEBluetooth project, which provides a DCOP interface to the underlying BlueZ DBus interfaces, but has one little issue, is not KDE4 ready. The first part of this proposal is to solve that problem.<br>
<br>
All this plots an scenario where a user arrival/leaving can be easily identified from Linux using few different ways. What if your computer pauses the music you are listening on Amarok,  locks the screen and mutes the audio when you leave, and also unlock the screen, restart playing your music and opens your favorite mail program and a browser with your favorite tabs when you get back to range. This is a feature that has already been included in OSX through the Proximity application, or even on Linux with the command line tool bluemon, so this proposal includes creating a similar application called Bluetooth Presence Manager, BtPM, using KDE4, on top of the previous Bluetooth support works.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Python Support for KDevelop4</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Piyush Verma</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Andreas Pakulat</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 KDevelop is an IDE that supports a wide range of Languages. Considering the fact Python is gaining widespread popularity as a programming language, the idea of my project is to bring decent Python support to KDevelop4.<br>
<br>
At present time, the python support for KDevelop4 is in its infancy. The Language parser does exist for python but is not complete, it is quite basic and does not comply with python indentation rules. So developing a lexer that supports indentation (or porting existing lexer from ANTLR python parser) would be the first task.<br>
The next one would be to make python parser understand a subset of the language.<br>
Apart from that I plan implementing a Definition Use chain for Classes and methods and &quot;Smart Highlighting&quot;.<br>
<br>
The Entire Project will have three milestones:<br>
- The Parser that is capable of reading predefined subset of python<br>
- Definition Use chain for classes/scopes/methods<br>
- &quot;Smart Highlighting&quot;<br>
<br>
The Language parser that exist for Python is just in its early stages and does support much of the functionality, so Considerable amount of work needs be done to add complete Python support to it.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Making KOrganizer look more like a paper-based calendar: theming improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Loïc Corbasson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Cornelius Schumacher</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Today KOrganizer's theming interface, CalendarDecoration, is not widely used. Plugins using the interface have to be written in C++, and the functionality remains simple.<br>
My goals during Summer of Code would be:<br>
- to allow for more features (background images, image/quote of the week/month, etc),<br>
- to write some example plugins (national calendars, &quot;This day in history&quot; links, ...),<br>
- to make it easier to write simple decorations for KOrganizer using a portable and easy-to-use format, which may be extended in the future (like the KDE themes).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Music Notation support for KOffice</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Marijn Kruisselbrink</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Boudewijn Rempt</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In this project I will add music notation support to KOffice. This will be accomplished by writing a new flake shape, which will make it possible to use this new feature in all KOffice applications. The goals of my project will consist roughly of 3 parts:<br>
* a way to show and print music in all koffice apps.<br>
* a way to edit this music notation<br>
* a way to load/save this in ODF files, either using a KOffice-specific file-format, or the 'standard' MusicXML format.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>KDEPrint -- add support for LinuxPrinting&#39;s on-line drivers query</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gavin Beatty</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Cristian Tibirna</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Personal:<br>
My name is Gavin Beatty. I'm 21 years old. I'm nearly finished 3rd year of my degree in Mathematics in Trinity College Dublin and I have been using Linux since Windows Millennium Edition ;) I have been a KDE user in all those years.<br>
<br>
My studies have included C++, computer networks, isometrized 3D graphing  applications in C++ and game development (last two using SDL).<br>
<br>
My personal experience in this realm include coding QT 4.x applications for library management (search,status,reminders) and personal itches such as for easy ssh port forwarding (became quicker than monthly `man ssh`ing).<br>
<br>
I have professional experience working with one of the largest (and Scandinavian ;)) telecoms companies in the world. There, I wrote testing frameworks in Python, debugged in Java and used many devel tools such as Subversion, ClearCase and all the major IDEs.<br>
<br>
I teach C and UNIX to Junior Freshmans in the School of Maths in Trinity.<br>
<br>
My passions are for Python, C++, QT and open source.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Java backend for Kross</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Vincent Verhoeven</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sebastian Sauer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Kross is a scripting framework that allows a program to easily integrate support for multiple scripting languages. Currently Python, Ruby and KJS are supported.<br>
<br>
This project aims to integrate Java as another supported scripting language. Java is among the most used programming languages according to various sources[1], so supporting Java in Kross opens a lot of potential for programs using Kross as a scripting backend. This affects among others popular applications as KOffice, KWord, Krita and SuperKaramba.<br>
<br>
[1] for example &quot;Programming Language Usage Graph&quot; by François Labelle, http://www.cs.berkeley.edu/~flab/languages.html<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improving the X RandrR extension support in KDE</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gustavo Pichorim Boiko</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lubos Lunak</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The X Resize, Rotate and Reflect (called RandR) is an extension that provides a way for applications to resize and rotate the root window of the display. In addition to that, the latest release of the extension (1.2.1) provides some additional features that are not yet supported by toolkits and desktop environments. One of the new features is the ability to deal with monitor hotplugging and zero or more outputs displaying arbitrary regions of the root window.<br>
From the desktop environment point of view, it is necessary to have an application monitoring for screen change events and managing all the available outputs and CRT controllers.<br>
<br>
KDE already has an application that can handle RandR events and that can do requests when necessary. This application is called krandr. But currently it only handles RandR 1.1 requests, which is not bad at all, but being able to interact using RandR 1.2.1 brings many new possibilities for the KDE environment.<br>
<br>
The idea of this project is to add necessary infrastructure for RandR 1.2.x support in KDE and make the desktop environment react and interact well with RandR requests.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Icon cache for KDE</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Rivo Laks</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Aaron Seigo</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 To improve startup times of KDE applications, I plan to create an icon cache which would store all icons in a common location. This would eliminate the need to scan tens of directories for icon locations, thus reducing disk seeking. And as the cache would consist of only two files, it would often be wholly cached in the memory by the operating system, eliminating disk access completely.<br>
Furthermore, the cache enables loading icons directly from SVGs, using any scale, as the SVGs need to be converted into pixmaps only on the first use.<br>
Finally, the cache would make it possible to support simple icon compositing, making it much easier for third-party applications to provide icons which always fit into user's current icon theme.<br>

	</div>
 </td>
 </tr>
</table>
<a name='lanka' />
<h2> lanka </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Sahana Disaster data import through arbitrary spreadsheets, relational databases</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hevafonsekage Joseph Priyanga Fonseka</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Chamindra de Silva</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project is to develop a data import module for Sahana Disaster Management System. This module will enable the Sahana users to import data stored in different formats like CSV , XLS, ODS and XML in to the Sahana system. Also it would enable the Sahana system to produce reports in those formats. This module will be relay help full for new Sahana users to adopt Sahana in to there disaster management activities, and also enable Sahana to work with other data management applications.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Optical Character Recognition for Sahana Data Entry</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Omega Silva</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>S.M Ravindra De Silva</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Abstract<br>
--------<br>
<br>
In disaster situations, the most common method of collecting information from the victims is by filling paper based forms. To use that information in a disaster management system like Sahana, they have to be typed in to the system, which is highly inefficient and delays the response time in a disastrous situation.<br>
<br>
<br>
The intension of this project is to provide an optical character recognizing tool which can recognize hand written English characters and save the data to Sahana database. The scope of the project will be limited to identifying English letters, numerical characters and other commonly used characters.<br>
<br>
<br>
Implementing the OCR tool in the server side is not a good option as optical character recognition is a highly processor centric task, and will overload the servers and waste the network bandwidth while uploading the images to the server. So it should be implemented as a stand-alone application that runs on the client side.<br>
<br>
<br>
The input to the tool is an image of the paper form, scanned from a normal desktop scanner.<br>
<br>
<br>
Since the OCR is to recognize hand written characters, AI techniques in the form of Neural Networks should be used. Neural networks are vastly used in OCR applications, since once trained well, they give results with high accuracy even in cases where high noise is present in the image.<br>
<br>
<br>
The characters in the input image have to be segmented and re-sampled before feeding it as the input to the neural network. The image processing part should also be efficiently handled.<br>
<br>
<br>
To minimize the errors in the final output, the paper form has to be designed to make it easier to segment the characters and thus minimize the errors in the input.<br>
<br>
<br>
The project is intended to be developed using C and C++, on Linux platform. Porting to MS Windows is also considered.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Extending KBFX the next generation Desktop resource launcher for K Desktop environment (KDE).</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Lahiru Lakmal Priyadarshana</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Siraj Razick</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Extend and Improve the latest KBFX 0.4.9.x branch of the menu. I hope to make KBFX even more user friendly, by flat indexed menu which can be ported to run on the upcoming major release of  KDE, KDE 4.0.<br>
<br>
&nbsp;&nbsp;&nbsp;“A Desktop resource launcher” hearing that may draw an image of a regular menu in your mind, which will load all the entries it has; such as all applications installed, administrative tasks, accessories, utilities etc... It is true that you may not interest in this image, because regular menu is sort of a mess and it is time consuming, since it has all the items and we have to find out what we need. So it takes time according to the loading speed and the time taken for searching relevant items.<br>
<br>
&nbsp;&nbsp;&nbsp;Think about a menu or in other words a Desktop resource launcher which shows only things or tasks that we should do, as its' entries.. And a menu which can be customized without editing the core part..!<br>
The extended KBFX menu will be full filling this need using Task Oriented Menu (TOM) concept.<br>
<br>
&nbsp;&nbsp;&nbsp;TOM can load only some selected entries as 'things to-do'. These entries will be defined in an XML file and the XML can be loaded to the menu via a tom-plug-in. There can be a baseXML for Office and Internet tasks, mulitimeadiaXML for Graphics and Multimedia, an XML for Games and also another XML for Administrative tasks. Users can modify their TOM by loading these XMLs via a tom-plug-in or even loading their own XMLs. This will allow multiple users to have different menus with their specific 'things to-do' list, in a single computer.<br>
<br>
&nbsp;&nbsp;&nbsp;My main goal is to give life to this TOM in this summer, with lot of additional features like better keyboard support. And it will be eye candy.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Sahana GPS Interface</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Selvamanickam Sriganeshan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mifan Careem</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Introduction<br>
Global Positioning System (GPS) is a satellite system that provides highly accurate location with the use of special GPS receivers and their augmentations. This accurate GPS data is of limited use by itself, unless it is coupled with a powerful visualization tool like the Geographic Information Systems (GIS). The GIS is a widely accepted visualization tool that presents data in a graphic form, which is a convenient and effective means of communicating complex information. These systems also have loads of relevant spatial and non-spatial data existing as different layers of information that can be expressed as a map. Thus, the integration of GPS and GIS brings into existence a powerful tool that has location and visualization aspects that can be put to effective use in the context of a disaster . The aim of this project is to develop a platform independent GPS interface to the Sahana disaster management system,which ultimately produces a strong integration of GPS and the existing GIS features of the Sahana system. This GPS/GIS integration would enable Sahana to communicate with GPS receivers very easily and efficiently allocate resources, model risks, and direct emergency response,relief,rescue,rehabilitation and recovery personnel.<br>
<br>
Deliverables of the Sahana platform independent GPS interface<br>
<br>
1&gt;Administrative interface to GPS devices -specifies the type and model of the GPS device,synchronizes the datums of maps and GPS device's,specifies ports,baud rate,etc<br>
2&gt;Format conversion interface -converting way points such as in Universal Transverse Mercator (UTM) to latitude and longitude and vice versa and many more format conversions.<br>
3&gt;The Import/Edit from GPS interface -imports waypoint/routes/tracks from the GPS device to the SAHANA system and provides the option to edit them.<br>
4&gt;The Export to GPS interface -exports waypoint/routes/tracks from the SAHANA system to the connected GPS device<br>
5&gt;The GPS map export interface -converts maps to GPS device compatible formats and exports those maps to GPS device.<br>
<br>
Tools<br>
Java is to be used to as the programming language for this project as it achieves platform independence and NMEA compatible GPS receivers are assumed to be used in connection with the SAHANA client as NMEA is the standard GPS device protocol. USB/Serial, bluetooth/Serial converters(software) are to be used to connect GPS devices through bluetooth and USB to the Sahana client. Java communications API 2.0/3.0 and jUSB are to be used to access ports.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Complete AJAX library for Sahana</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ishan Udyana Liyanage</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>S.M Ravindra De Silva</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project would be an attempt to provide AJAX (Asynchronous JavaScript and XML) support for Sahana. The current implementation of Sahana deals with AJAX little bit. AJAX can use to create better, faster, and more user-friendly web applications. There are lots of areas (modules) in Sahana that AJAX can be applied effectively. Therefore this project is important for Sahana to be able to perform efficiently and more user friendly way.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Sahana Meta data based dynamic report generation (tables, charts and
Sahana Meta data based dynamic report generation (tables, charts and
Sahana Meta data based dynamic report generation (tables, charts and maps)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Agnieszka Kulikowska</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mifan Careem</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I see this product as similar to pivot tables in Excel or as more advanced, like reports in one of Business Intelligence tools (Crystal Reports, Business Objects, Pentaho). Request is to allow use it via web interface. Hence my idea is to apply R statistical system (http://www.r-project.org) which can be integrated with virtually any other language (e.g. with Java via RServe). I would like to communicate with R from PHP level using R-php (http://dssm.unipa.it/R-php/). R will deal as computational engine. As platform for interface can deal Rpad (http://www.rpad.org/Rpad/) too. A simple example of dynamic report generator can be found at http://www.rpad.org/Rpad/DataExplorer.Rpad.<br>
<br>
Pivot tables supported with drag and drop technique will be applied (thanks to Rpad). Huge graphical data presentation possibilities of R statistical system will be applied. We can think of generation of pdf reports too.<br>
<br>
R can access almost any database. MySQL databases can be reached via RMySQL interface library.<br>
<br>
Of course, we do not have to use R and we can support pivot tables and dynamic reports with direct use of database queries from PHP level. We can apply mixed approach too: simple queries directly using SQL queries, more computationally complex (or statistically advanced) using R system.<br>
<br>
Sahana allows tight GIS integration (Google Maps), hence it could be applied to some very simple geographical visualizations. More advanced generation of maps could be needed, e.g. in case when we would like to visualize population density with colors. Such other approach to generation of maps could be supported by R too (it has several packages allowing this) but for greater flexibility GRASS GIS software (http://grass.itc.it/) could be used. It can be accessed via GRASS package for R. I am not sure if application of such advanced GIS system in Sahana is necessary / needed / possible. It should be investigated while beginning part of the project.<br>
<br>
The solution with use of R system will allow us to easily expand analytical possibilities when advanced needs will appear. I think that is really worth considering.<br>
<br>
I suggest to exclude geographical visualizations and pdf reports from scope of the project. Application of several tools may consume too much time and technical difficulties can cause project failure.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Effective Localization for Sahana</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Leevanage Pium Prabath Kumarasinghe</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Isuru Samaraweera</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Once a disaster occurs anybody should be able to download the opensource software and adapt it to their geographical location as quickly as possible.So adaption of the language to the geographical location definitely ease the disaster management process by enabling volunteers to use the sytem from their mother tongue and acclearate the data capturing process.<br>
<br>
When disaster happens lot of volunteers are speaking and understand there mother tongue. If we can make effective localization for Sahana which take to translate the site less than one day that would be very much helpful.<br>
<br>
Localization should be user friendly because translation are done by translators who are non technical person, to translate site if we required translator and technical volunteers that would be a problem.<br>
<br>
We can make localization module like this when user switch to Sahana localization mode they able to translate words while they are looking at the Sahana site. For instance if user want to translate 'Sahana Disaster Management System' into there language they can highlight that word phrase and press enter then they get text box saying please type translate word. After translation done when they say apply for  particular module then we are creating *.mo file internally.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Bassa, A Policy Based, User Driven, Content Caching/Sharing and Distribution System.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Wathawana Vithanage Wathsala</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Chamindra de Silva</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Bassa is a new project, that aims to build a policy based content caching, distribution and sharing<br>
system that is fully transparent from the web users' perspective.<br>
The ultimate goal of the project is to build a system that will efficiently utilize the available<br>
bandwidth in a timely manner using Quality of Service (QoS) and efficient bandwidth throttling.<br>
As an added benefit, the system will also be extended to provide a rich web 2.0 interface called<br>
GADisk,   that   enables   anyone   to   share   their   downloaded   content   such   as<br>
multimedia/documents/entertainment.<br>
Therefore Bassa can be considered  as a next generation proxy server extension that is capable of<br>
enhancing an existing proxy server to efficiently schedule and download content. It is primarily<br>
implemented using the C language for better portability and efficiency.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Fund Management Module for SAHANA</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>K H D KUMARASIRI</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Isuru Samaraweera</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In a disaster the whole community work together and try to mitigate the effect of the disaster situation.Huge amount of funds flows in and some times the amount may be more than required.If they are not properly managed it may lead to another disaster.Funds should be managed very carefully and requires high degree of professional skill.it is very costly and time consuming task.In a disaster, time and money will be the most scarese resource.<br>
<br>
&nbsp;&nbsp;As a solution to the above problem the Fund Management module will automate the fund management process.This will manage fund distribution process centrally and allocate correct and appropriate funds to correct places at the correct time.furthermore this will include an accounting statement generation submodule and several financial and non financial reports.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Google Summer of Code Application.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Dinishika Nuwangi Weerarathna</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Darmendra Pradeeper</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Package Manager Module:<br>
-----------------------------------------------<br>
<br>
There are number of modules available in SAHANA. If we take a user he will not need all the modules. There are so many functionalities are included in to the whole system and those functionalities are embedded in to the different modules. For example if any user wants to make a request, the request management module will be the expected one. In this case it will be convenient to user if he allow to manage the system by selecting only the appropriate modules they want.<br>
<br>
A good system would have to address the needs of usability, customizable and the accessibility since it improves the ability of make the task easy. Package Manager Module is the best selection to achieve those goals without affecting current usability of the existing system.<br>
<br>
By addressing the Package Manager module user will be able to select only the appropriate modules and select the themes according to their preference.<br>

	</div>
 </td>
 </tr>
</table>
<a name='lispnyc' />
<h2> lispnyc </h2>
<table>
 <tr>
 <th>Title</th>
 <td>IOLib</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Luís Manuel Borges de Oliveira</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robert Edward Brown</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 IOLib¹ is an effort to create a library for Common Lisp applications<br>
doing high-performance network I/O whose ultimate goal is to provide<br>
a framework for doing event-driven multi-protocol network<br>
programming not unlike the Twisted² and POE³ libraries for Python<br>
and Perl, respectively.<br>
<br>
&nbsp;&nbsp;With this goal in mind, this project proposal includes work on a C<br>
groveler targeting CFFI, a POSIX layer, a Win32 layer, a<br>
multi-platform sockets API, an event notification API and an I/O<br>
multiplexer.<br>
<br>
¹ &lt;http://common-lisp.net/project/iolib/&gt;<br>
² &lt;http://twistedmatrix.com/&gt;<br>
³ &lt;http://poe.perl.org&gt;<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>CL-ObjC. A bridge between Common Lisp and Objective-C</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Luigi Panzeri</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Edward Marco Baringer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 CL-ObjC is a portable Common Lisp / Objective C bridge, whose ultimate<br>
goal is to be able to build Cocoa applications on Mac Os X by using<br>
Interface Builder to design the GUI and then implement any required<br>
code entirely in Common Lisp.<br>
<br>
At this time the CL-ObjC project state is very experimental though the<br>
source code already written demonstrates his ambitious final goal can<br>
be easily achieved.<br>
<br>
Common Lisp is an high level programming language supporting a<br>
combination of imperative, functional and object oriented programming<br>
paradigms, compiled code, dynamical safe and strong typing, and<br>
extensible with macros.<br>
<br>
Several libraries and tools available for Common Lisp are often<br>
conceived to be used from the REPL (the command-line traditional<br>
interface). As a matter of fact this way of use, though powerful for<br>
an experienced lisp user, put little barriers up for newcomers.<br>
<br>
Having a tool to easily build modern, well-integrated with the OS and<br>
beautiful graphical user interfaces, will help lower the impedance to<br>
entry for new Common Lisp developers, and so will be helpful in<br>
advertising the whole Common Lisp community.<br>
<br>
CL-ObjC is a Common Lisp library that aims to help users writing GUI<br>
for their domain-specific applications, using all the features of the<br>
Cocoa framework, and all the power of an industrial strength lisp<br>
language, like interactive development through REPL.<br>
<br>
Actually CL-ObjC aims to provide the following features:<br>
<br>
* access to the Cocoa Objective-C based APIs using CFFI to guarantee<br>
&nbsp;&nbsp;portability among Common Lisp implementations;<br>
<br>
* Documentation, simple examples (Hello World, widgets demo), and a<br>
&nbsp;&nbsp;demo of a Common Lisp library (e.g. cl-skippy).<br>
<br>
* close integration with the Interface Builder;<br>
<br>
* multithreaded execution in order to recompile and eval lisp code typed<br>
&nbsp;&nbsp;at the repl;<br>
<br>
* CLOS (Common Lisp Object System) and macros interface for low level<br>
&nbsp;&nbsp;features of the Cocoa Framework, in order to provide a more<br>
&nbsp;&nbsp;functional and Object Oriented interface to them.<br>
<br>
At this time, a accurate TODO list is available for the project,<br>
including the steps to implement the former features in the order.<br>
<br>
My project proposal concerns in the initial stage the completion of<br>
the first two features, including the refactoring of the existing<br>
code. Then we will add examples and documentation to consolidate the<br>
work. In the last phase, depending on how much time is available we'd<br>
choose between the last two features.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Music interchange format support for Gsharp</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Brian Gruber</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Christophe Rhodes</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Functionality will be added to the Gsharp score editor allowing the importing and exporting of MusicXML files. With support for this interchange format, users of Gsharp will be able to integrate it into a work environment that includes a bevy of other music software.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>NXTLisp - a Common Lisp library for the NXT Mindstorms platform</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Milan Cermak</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Frank Klassner</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The aim of this project is to write a Common Lisp library for the Mindstorms NXT platform. It would provide a facility to write NXTLisp programs to run on NXTs, remotly and simultaneously control one or more NXT agents or set up a network of NXTs that communicate with each other.<br>
<br>
Mindstorms NXT is a programmable robotics kit produced by Lego. It is commonly used by universities and hobbyists around the world. The base kit is extensible by various sensors and components thus making it a perfect platform for learning and experimenting in various IT-related fields like AI, robotics or multiagent environments.<br>

	</div>
 </td>
 </tr>
</table>
<a name='llvm' />
<h2> llvm </h2>
<table>
 <tr>
 <th>Title</th>
 <td>LLVM Mips Backend</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bruno Cardoso Lopes</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Chris Lattner</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Mips is a RISC processor architecture known for it's simplicity.<br>
LLVM compiler infrastructure currently does not generate machine<br>
code for Mips architecture machines. The project goal is to<br>
implement the Mips backend support on LLVM and enable Mips machine<br>
code generation.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Using LLVM as a backend for QEMU&#39;s dynamic binary translator</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Tilmann Scheller</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Paul Brook</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this project is to modify the QEMU dynamic binary translator to use components of the LLVM compiler infrastructure to turn it into a highly optimizing dynamic binary translator in order to increase the performance of QEMU even further. Instead of directly emitting code for the host architecture QEMU is running on, the target code is first translated to LLVM IR, then a selection of LLVM's optimization functions are applied to the IR and the LLVM JIT is used to generate code from the optimized IR for the host architecture. Since the translation to LLVM IR, the optimization and the code generation comes at a cost of an increased execution time, it's not feasible to apply this process to any piece of code, else the execution time would be even lower. Especially since on average a program spends 90% of its time within 10% of the code it is critical to get these 10% to execute fast, for the other 90% of the code parts might only execute once or only a few times and the extra time spent to generate the optimized code would not pay off. Therefore the idea is to identify the &quot;hotspots&quot; of the program. The most simple way is to count how many times a piece of code has been executed and performing an optimizing translation once a certain threshold is hit or falling back to the current binary translation of QEMU if not. Another approach could be to instrument the target code at LLVM IR level to get an execution profile (LLVM already contains support for profiling) and use it to identify hotspots and to be able to perform profile-guided optimizations during runtime. Possibly a combination of both approaches will lead to the biggest overall performance gain. Detailed speed measurements will be performed in order to evaluate the efficiency of the different approaches, especially in comparison to the approach currently used by QEMU.<br>

	</div>
 </td>
 </tr>
</table>
<a name='lurie' />
<h2> lurie </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Proteomics and Metabolomics Data Processing System:</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jared Flatow</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Pan Du</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The MassSpecWavelet package in the Bioconductor provides a novel way of performing highly accurate peak detection on Mass Spectrometry data.  The package utilizes Continuous Wavelet Transforms to find peaks in the data at various resolutions.<br>
<br>
The CWT filtering used can be performed on any 2-dimensional dataset, however extensions need to be made to the package to allow it to read in a wider variety of data formats. In particular, the authors would like to be able to support LC-MS/MS data, mzData and NMR metabolomics data.<br>
<br>
Other modifications also need to be made to the existing data structures so that the provided functionality can more readily be shared with other packages in the Bioconductor.<br>
<br>
In addition to these extensions, the authors would like to see a suite of standard signal processing tools to give users the ability to filter and analyze the data in multiple ways. Another idea along these lines would be to provide a matched filtering algorithm to allow users to compare unknown datasets with known ones.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Adding GC-MS and LC-MS metabolomics support to MassSpecWavelet</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Michael Lawrence</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Pan Du</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A common source of metabolomics data is chromatography mass spectrometry. Adding support for this type of data to the MassSpecWavelet package will require adapting and expanding the package to consider the chromatographic time dimension.<br>
A separate peak detection algorithm may be required for chromatographic peaks, since their shape differs from that of mass spectral peaks. Chromatographic peaks often overlap, necessitating a deconvolution procedure. Also, the large degree of temporal shift between samples requires aligning them by retention time.<br>
The identification of metabolites is especially challenging in<br>
gas chromatography, where each metabolite is fragmented into multiple ions. The individual ions must be grouped together for identification. The new version of MassSpecWavelet must address all of these issues. To avoid reinventing the wheel, the package should be integrated with existing software for metabolomics, such as the xcms Bioconductor package, where appropriate.<br>
<br>
It would also be beneficial to make the MassSpecWavelet package generally more adaptable and more accessible to biologists. This would involve improvements along three axes. First, the design should be based on a modular, extensible data analysis pipeline. This would enable expert users to adapt MassSpecWavelet for specific needs. Second, MassSpecWavelet should visualize results and algorithm diagnostics with interactive graphics that promote open-ended<br>
exploration of the data. Every dataset is unique and requires a flexible means of visualization in order to detect problems and to discover the unexpected.  Finally, a graphical user interface (GUI) should be provided so that biologists are able to use MassSpecWavelet without spending valuable research time climbing steep technical learning curves.<br>
<br>
Adding metabolomics support to MassSpecWavelet is the priority for this project. General improvements will only receive attention when they directly support the metabolomics efforts.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Google Gateway to Genomics Literature</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Adrian Schönig</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Warren A Kibbe</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 SYNOPSIS<br>
<br>
G3L or Google Gateway to Genomics Literature is a website, which provides access to recent scientific data and research articles in a visual manner, that focuses on a clear representation of what is new and what is popular among the users - all without scrolling.<br>
<br>
BENEFIT &amp; PROJECT DETAILS<br>
<br>
Inspired by Newsmap (http://www.marumushi.com/apps/newsmap/newsmap.cfm), G3L immediately attracts attention by its visual appearance. Items on the website are arranged over the whole screen, taking advantage of current high-resolution or widescreen displays, while assuring readability and a clear design. Depending on the popularity among the readers and on its age, items are be highlighted, e.g. by increasing the font size of the heading or applying different colours.<br>
<br>
The data for the website is collected by spiders, that retrieve and parse web content from various relevant internet sources. The different sources are used to provide the grouping for the articles.<br>
<br>
The website is developed using the Ruby on Rails (RoR) framework and a MySQL database. This allows for an open and modular style of programming, while using AJAX techniques to provide an easy and attractive user experience. This is, in particular, used to load details for a particular item on the screen upon request by the user.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GeneQuad summary for GeneRIF using N-Gram Markov Model and other techniques</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Daniel Baggio</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Pan Du</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 - Goals and Project Interest for 2007 SoC<br>
&nbsp;<br>
&nbsp;I am primarily interested in the GenQuad project. The goal of this project is to summarize the function of each gene using four keywords. The source of information to find which words will be used is mainly &quot;geneRif&quot; (ftp://ftp.ncbi.nih.gov/gene/GeneRIF/generifs_basic.gz). Since this file records almost 500,000 descriptions, some approaches will need to be tested.<br>
&nbsp;A good approach is to use the Word Level method, so that word properties, stop-words, stemming, frequent N-Grams and Thesaurus techniques may be applied. The weight of each one of them will need to be measured, and a gold-standard will need to be defined. Since professionals from the field are the ones who can better evaluate what is a good summary for the genes, some feedback from them might be needed.<br>
&nbsp;One technique that will receive more focus is the &quot;Frequent N-Gram&quot; one. Since it has an easy dynamic programming algorithm, and yields to good results in other areas, this technique will be deeply explored. Another apprroach would be using &quot;Approximate N-Gram Markov Model&quot;<br>
(http://nlg3.csie.ntu.edu.tw/conference_papers/qualic1994b.pdf), which describes an O(n) algorithm for such implementation. The quality of both algorithms must be evaluated.<br>
&nbsp;In the word level field, we also want to determine whether CAP algorithms are suitable. Implementing such algorithms and comparing to the gold-standard may prove it.<br>
One paper used to get some previous experiences will be (http://www-nlpir.nist.gov/trec/pubs/trec12/papers/ntu.genomics.pdf)<br>
Another interesting field would be exploring the Document Level. Topics such as Summarization, Single Document Visualization and Text Segmentation algorithms will be used to evaluate if techniques in this field are suitable for the task.<br>
&nbsp;During my research, I will examine open source text mining tools so that previous work may be added in short period. Main Text Mining tools studied will be GATE(http://gate.ac.uk/), WEKA (http://www.cs.waikato.ac.nz/ml/weka/), MALLET (http://mallet.cs.umass.edu/index.php/Main_Page) and LingPipe (http://www.alias-i.com/lingpipe/).<br>
&nbsp;Besides all the research work, I intend to provide the results in a web-enabled database, for easy query retrieval, using AJAX technology. Since I’ve had a lot of experience in a software factory, these approaches will be quite straightforward.<br>

	</div>
 </td>
 </tr>
</table>
<a name='macports' />
<h2> macports </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Automate and beautify creation of universal binaries for ports that need to be built more than once and then run lipo on</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Elias Pipping</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Markus Weissmann</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In order to allow for complex, non-standard, or configure-lacking ports to built universal binaries, often configuring and compiling for a single architecture is required, once for every requested architecture (2 for 32bit u.b., 4 for 32bit+64bit u.b.). After every such run, the output needs to be backed up to a temporary location. Once that is done, lipo needs to be run on all those files.<br>
<br>
Openssl is the first port that allowed for building u.b. in such a way, everything from line 50 on deals with u.b..<br>
<br>
&nbsp;&nbsp;http://trac.macosforge.org/projects/macports/browser/trunk/dports/devel/openssl/Portfile<br>
<br>
I'd like to automate and beautify such universal variants through functions, as described here:<br>
<br>
&nbsp;&nbsp;http://trac.macosforge.org/projects/macports/wiki/SummerOfCode#Task8:Portfiles<br>
<br>
e.g. functions for lipo and backing up are needed.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Port isolation while building</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Eugene Pimenov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Paul Guyot</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I'm going to implement building port in isolated environment. I'll add to inject library ability to reject attempts to read file, so program will se only ports which was wrote in portfile.<br>
<br>
Now inject library communicate with tcl code and can log read attempts. We need to add backward communication. So inject library should ask read-abiltiy for every file.<br>
<br>
To reduce performance penalty we need to cache on library side.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>New Repository Backend</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Chris Pickel</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Paul Guyot</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A universal need of package managers such as MacPorts is the ability to track dependencies between packages and determine if one package needs to be installed to support another. There are, however, some important deficiencies in the MacPorts dependency resolver, and in fact, in package managers in general. I propose to address these issues in MacPorts by designing a new repository backend for tracking ports, and an appropriate suite of functions to query it.<br>
<br>
This backend will be capable of tracking a wider range of requirements: in particular, it will let packages request particular variants and versions of other packages. This is important to the MacPorts project because it will improve the reliability of the dependency system.<br>
<br>
Additionally, the dependency graph will be represented in such a way that it will be possible to identify stages of installation that can be performed simultaneously. This is important because, as processors tend towards parallelization, it will be necessary to split the process of installation into concurrent tasks.<br>

	</div>
 </td>
 </tr>
</table>
<a name='maemo' />
<h2> maemo </h2>
<table>
 <tr>
 <th>Title</th>
 <td>GeoClue for Maemo</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jussi Kukkonen</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Henri Bergius</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Location-awareness would open various new possibilities for Maemo-based<br>
devices. Examples of such possibilities include a camera application that<br>
automatically tags pictures with a 'taken at' address or an automatic timezone<br>
setting. At the moment adding location-awareness to applications is so<br>
difficult that only specialized applications, like gps-map software, do<br>
anything at all based on the users location.<br>
<br>
The goal of this project is to provide Maemo application developers with a<br>
easy to use API for basic location-services, like acquiring current coordinate<br>
position or street address. To reach this goal I plan to package the GeoClue<br>
library for Maemo and to develop the necessary user interface to make GeoClue<br>
functional from the end-user perspective.<br>
<br>
Links:<br>
http://geoclue.garage.maemo.org/ -- Project home<br>
http://vilunki.wordpress.com/ -- project blog<br>
http://maemo.org/ -- Maemo home<br>
http://geoclue.freedesktop.org/ -- Geoclue home<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Japanese/Chinese handwriting recognition on Maemo</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mathieu BLONDEL</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Makoto Sugano</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A project was recently added on &quot;garage&quot; [1] to add the CJK (Chinese, Japanese, Korean) support on the Maemo platform. With about 1.5 billion people using CJK in the world, this allows the Maemo platform to target a much broader population.<br>
<br>
However, a feature which is extremely common in the PDA with a touchscreen is still lacking: handwriting recognition. Handwriting recognition is useful when people want to input a character that they cannot read and thus cannot input with the standard input method. This of course often happens to foreigners learning CJK but also to native speakers when it comes to unusual characters. That is why handwriting recognition makes so much sense for Japanese/Chinese PDA. Other possible applications of handwriting recognition include dictionaries and character (kanji) learning games.<br>
<br>
This Google Summer of Code project aims to add support for Japanese/Chinese handwriting recognition using tomoe. [2] Focus will be on performances and smooth integration with the current input system and latin character recognition.<br>
<br>
[1] https://garage.maemo.org/<br>
[2] http://tomoe.sourceforge.jp<br>

	</div>
 </td>
 </tr>
</table>
<a name='metabrainz' />
<h2> metabrainz </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Working on implementing simplified NGS</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Erik Dalén</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lukáš Lalinský</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The purpose of this project is to implement the simplified NGS scheme specified at:<br>
<br>
http://wiki.musicbrainz.org/LukasLalinsky/NGS<br>
<br>
The goal is to reach at least step 5 on that roadmap.<br>

	</div>
 </td>
 </tr>
</table>
<a name='mixxx' />
<h2> mixxx </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Improved BPM detection</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Micah Lee</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Albert Santoni</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The purpose of this project is to analyze and improve upon the beat detection algorithm implemented in mixxx. The project will begin by analyzing Mixxx's implementation of the &quot;Real-time beat estimation using feature extraction&quot; method for areas where the current code could be improved. Then, research will be conducted to determine what other methods/libraries are available for real time beat estimation. Using the results, either the current implementation will be improved upon or at new method will be implemented.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>LADSPA Support in Mixxx</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Paweł Bartkiewicz</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Albert Santoni</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 LADSPA [1] is an acronym for Linux Audio Developers Simple Plugin API. It is a standard for audio processing plugins, mainly filters and effects. Currently, many free software projects benefit from using these plugins, which let the users apply both simple and advanced effects to their audio signals without forcing developers to spend time implementing filters which already exist. The spare time can then be assigned for implementing other features, perhaps more innovative. Despite the name beginning with &quot;Linux&quot;, so far LADSPA is the most cross-platform widely adopted solution for audio plugins.<br>
At present, Mixxx is offering only a built-in flanger effect. Therefore the goal of my project is to implement support for LADSPA plugins within Mixxx.<br>
<br>
[1] http://www.ladspa.org<br>

	</div>
 </td>
 </tr>
</table>
<a name='moin' />
<h2> moin </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Interactive Wiki Maintenance with Jabber/XMPP</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Karol Nowak</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Alexander Schremmer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Nowdays, wikis are widely used as tools for fast and efficient sharing<br>
of knowledge, that in contrary to other forms of Internet communication (like IRC or IM networks) offer persistence and encourage collaboration by providing full access to the information. Various means of control are used to keep the content from being corrupted either by malicious users or plain mistakes. These include full logging, tracking of changes and author/admin notification systems. A common use pattern also includes using 'talk pages' to discuss changes being made to the content.<br>
<br>
I find email notification systems slow and not interactive, and as a natural consequence of this, I believe that developing means of interactive, Jabber/XMPP-based content handling might greatly improve the usability of the MoinMoin project. This would include: Jabber/XMPP notification of subscribed users (useful to fight spam or keep track of changes made to heavy-traffic pages), simple editing options like adding a comment at the end of the pages (again, tremendously useful for talk pages as all the user has to do, is write a reply in the IM client) and efficient anti-spam fighting measures (an option to revert a particular change with one command). This functionality should be implemented in a separate daemon, to reduce latency and overhead of networking operations.<br>
<br>
Progress is being tracked here: http://jabba.pl/grzywacz<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Automatic classification of wiki pages and extending security system.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Marian Neagul</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Reimar Bauer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Project Description<br>
<br>
&nbsp;The Classification Feature will provide MoinMoin the ability to automatically group related wiki pages based on user feedback and to implement new actions (notification) when new content is added. The project should implement state-of-art algorithms like: Bayesian classification, Support Vector Machines or Artificial Neural Networks.<br>
&nbsp;The other features that I am interested would help to provide a more secure and usable MoinMoin.<br>
<br>
Project Motivation<br>
<br>
&nbsp;Currently, MoinMoin does not provide a way to classify wiki pages based on their content and these feature would allow big MoinMoin installations to provide supervised or unsupervised text classification.<br>

	</div>
 </td>
 </tr>
</table>
<a name='mono' />
<h2> mono </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Windows.Forms.Designer</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ivan Zlatev</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Miguel de Icaza</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 === Introduction ===<br>
<br>
Hi! Firstly a bit about myself. I am a second year BSc. Software Engineering student in the University of Hull, UK. I've been interested in .Net since I got my .Net 1.0 Beta 1 CD and I've been following the Mono project for almost 2 years now. Event though Mono has quite a decent Windows.Forms support, being actively worked on, as a Mono and also a GNU/Linux user and developer I am not able to design Windows.Forms interfaces, nor edit alreadyexisting ones in a visual and pleasant way. I've been researching on the topic since summer 2006.<br>
<br>
=== Summary ===<br>
<br>
This project is targeting at:<br>
<br>
1) Providing an implementation of the .Net 1.1 and .Net 2.0 Design-Time stack for the Mono Class Library, mostly hosted in the System.Design assembly and .Design/.Design.Serialization namespaces. The stack consists of:<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;* A DesignSurface (Host)<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Windows Forms Designers<br>
&nbsp;&nbsp;&nbsp;&nbsp;* ASP.NET Designers - not targeted by this project.<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Serializers<br>
<br>
It should be noted that SharpDevelop relies on this stack.<br>
<br>
2) Integration in MonoDevelop to enable:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Designing Windows.Forms interfaces<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Full forward and backward compitability with Visual Studio generated interfaces.<br>
<br>
=== Status and TODOs ===<br>
<br>
The project is hosted at http://monodt.i-nz.net and managed via Trac and Subversion. It currently provides an initial .Net 2.0 ready implementation of the DesignSurface and .Net 1.1 ready core Windows.Forms designer stack, which allow dragging and droping, selecting and resizing controls. Initially development was done on Windows and MS.Net, but after 2 bugfixing cycles, which introduced about 15 bugfixes and patches in the Mono Class Library related to Design-Time behaviour the code works fine on Mono and the development has moved to Linux/Mono.<br>
<br>
TODOs are:<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Improve selection, drag and drop and resizing behaviour and design<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Implement the Serializers<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Merge with Mono's class library<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Implement the specific Windows.Forms designers per Control basis.<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Update core designer stack to .Net 2.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;* MonoDevelop integration<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Extensive testing<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>FastCGI ASP.NET Server</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Brian Nickel</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Marek Habersack</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Very few web servers are supported by mod-mono-server, namely, XSP and Apache. More servers support FastCGI, either internally or through a module, including Apache, Microsoft IIS, Netscape, SunOne, and others. As such, a FastCGI mono server could improve mod-mono-server's market share.<br>
<br>
The primary target is:<br>
1. A FastCGI bridge to XSP, similar to mod-mono-server.<br>
2. A configuration page (aspx) and a web service to adjust or reset the server's configuration remotely.<br>
3. Create sample configurations for common server setups, prioritizing based on market shares.<br>
<br>
Secondary targets (as time permits) would be:<br>
1. Creating a test program which determines the optimal FastCGI settings for a given computer.<br>
2. Configuration software which uses the configuration web services, console, Gtk#, and/or Windows.Forms<br>
3. Implement a FastCGI 1.0 authorizor, so that HTTP Authorization could be handled through through mono.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>WYSIWYG Editor for Monodoc and MonoDevelop</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hector Enrique Gomez Morales</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mike Kestner</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Mono Project is one of the fastest moving open source projects, this a very good<br>
thing but the work done in the area of Documentation is lacking and the amount of documentation<br>
to be reviewed or created is huge. So to close this increasing gap an application that helps in  the<br>
creation and edition of documentation with a very low learning curve is not only good but a<br>
necessity for the project.<br>
<br>
So a WYSIWYG Editor will be integrated into the Monodoc application that will make it easy to edit the documentation, there will be an option in Monodoc to enter Edit Mode that will present to the user with 2 panels: one panel with a &quot;Documentation Palette&quot;  (in style of the Dia palette of the widgets palette in Monodevelop) and another panel where the document will be shown. The user will drag elements from the palette and drop them in the document and the editor will restrict the drop of certain elements depending in the visual context of the area where the user is trying to drop the element.<br>
<br>
This functionality will be abstracted so that it can be used for a plug-in for MonoDevelop, so that any ECMA documentation is associated to the editor.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Gendarme project development</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Lukasz Knop</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sebastien Pouliot</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The aim of this project is to make a substantial contribution to the Gendarme project, akin to Microsoft's FxCop or Java-based FindBugs, for performing static code analysis. Static code analysis means inspecting code without running it - in case of ECMA CIL resulting in inspection of the code after it has been compiled to intermediate language. Static code analysis is a powerful tool for developers who strive for high quality of their code. Although it can not replace human code reviews, it is invaluable in pinpointing bad practices, finding omissions or common mistakes.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>MonoDevelop Database Improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ben Motmans</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Miguel de Icaza</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 MonoDevelop currently has some tools to allow browsing of databases inside the IDE and an editor to write SQL queries. However, these features are currently very basic and could use some serious improvements.<br>
<br>
During the summer, I would like to add the following features to MonoDevelop:<br>
* SQL parsers to provide syntax checks and code completion<br>
* Graphical database overview<br>
* Graphical Database designer<br>
* Database unit tests<br>
* ...<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>On WCF, NetPeerTcpBinding and PeerResolvers</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Marcos Cobeña Morián</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Atsushi Enomoto</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 It's been now more than 5 years since I started playing with Mono. .NET platform has become in those last ones one of the most powerful tools for developers from a large variety of architectures, thanks to the existence of Mono Project, which has made possible a true fact as portability is.<br>
<br>
Today, we live in a connected world where communications play an important role on this exciting 'second life'. WCF is one the doors to the very close future so it's worth to work on a robust base for this technology, and even more exciting inside a community as the one Mono has.<br>
<br>
That's my application: to help on improving WCF, and work on WCF core to allow Mono keep on climbing as in some other areas currently does.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Ribbons Widget</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Laurent Debacker</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mike Kestner</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Build a Ribbons widget similar to the ribbons found in Office 2007. The widget would be written in C# targeting Gtk#. This includes the tabs, the ribbon below the tab, groups, and both large and small buttons. Both button format would support drop-down menu with more actions. If the ribbon is not large enough for all groups, some groups will be minimized to a single button which can be used to display a drop-down menu with the real content of the group.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>MonoTorrent Gtk# GUI</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jared Hendry</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Alan McGovern</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project aims to take advantage of previous SoC work on the MonoTorrent library and interface. Currently there is a very limited Gtk# client developed using MonoTorrent but severely lacks the regular options a user would expect from a BitTorrent client.<br>
<br>
I intend to further develop the existing MonoTorrent gtk-sharp interface and provide GNOME with a feature complete BitTorrent client to compliment the other quality applications available to GNOME users(Banshee, F-Spot, Tomboy). I am keen on seeing the MonoTorrent Gtk#  GUI standing beside KTorrent and uTorrent.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Gendarme Tasks</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nestor Salceda Alonso</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sebastien Pouliot</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The purpose of this tasks are the following:<br>
<br>
* Create 2 new runners, one for Gtk# and other for Managed Windows Forms, for help developers to create / edit / customize the rules.xml file. And help the running detection process.<br>
<br>
* Create a set of new rules for detect bad smells in the source code, for example the smells in the Fowler's book called 'Refactoring: Improving the design of existing code'.  These smells are, duplicated code, long method, large class, long parameter list ...<br>
<br>
* Set of new rules for check code guidelines, for example the mono ones.  We can check casing and other stuff, and document it.  Help contributors to add value and send patches and gendarme and the rules check some code guidelines, and warn from rule violations.<br>
<br>
* Rules for get synchronized the classes, and namespaces.  For example, if you only use a class and put the using directive; and then you give up use the class, the using directive could be written in top of the code and you don't need use this namespace.<br>
<br>
* Integrate Gtk# runner with Monodevelop.  This is the perfect complement for Monodevelop, you are developing an application; and then, you could check the rules with only check a button. I will take the Gtk# widget and embed into Monodevelop.<br>
<br>
* I'm an open minded people, and I could write some new useful tasks if I have more ideas or suggestions.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Adding C/C++ support in MonoDevelop</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Marcos David Marín Amador</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael James Hutchinson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My goal is to create a MonoDevelop Add-in that adds support for C/C++.<br>
<br>
* Create a new C/C++ project<br>
&nbsp;* Choose project template (Console Application, Dynamic Link Library or Static Library).<br>
* Load a previous C/C++ project<br>
* Add existing and new files into the project<br>
* Configure global C/C++ options (Compiler, include paths, bin paths, lib paths).<br>
* Configure project specific options (extra compiler arguments, project specific include paths, project specific bin paths, project specific lib paths, code generation, output, pkg-config extra arguments).<br>
* Pass project's references to pkg-config.<br>
* Code completion using ctags (similar to the vi implementation, but with a more modern feel to it).<br>
<br>
75% of the time will be dedicated to implement and improve as much as possible code completion, since the rest doesn't take that much time and I really want a powerful code completion implementation.<br>
<br>
If I finish this before GSoC finishes I will work on integrating with autotools.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Banshee - Porting Banshee to Windows</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Scott Peterson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Aaron Bockover</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Banshee is a music playback and management app for the GNOME desktop built on the Mono runtime. Capitalizing on Banshee's platform-independent design, this project will fully port the program to the Windows desktop. In addition to providing our Windows brethren with the best open source music player ever, this project will forward the effort to test Mono/Windows compatibility in an important direction: bringing a Linux application to Windows. Major work will include porting hardware support, CD-Burning, and media playback to Windows. At the conclusion of this port, Banshee should support Windows as a stable build target for many releases to come.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Gendarme: The problem finder</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nidhi Rawal</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sebastien Pouliot</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 As mentioned Gendarme contains a couple of rules but lacking simple rules that are very important for good performance and correctness of the program.  I am planning to implement some simple rules in Gendarme regarding naming conventions as well as rules that will help<br>
improve  performance, correctness, remove dodgy behaviour and also detect inefficiently written code in the program.<br>
<br>
I'll implement 13 simple rules regarding naming coventions that can be added to the category &quot;Gendarme.Rules.NamingConventions&quot; which can be created and 22 normal rules out of which some can be categorized into &quot;BadPractice&quot; or some other more general category. Some rules can be added to existing &quot;Gendarme.Rules.Correctness&quot; and &quot;Gendarme.Rules.Performance&quot; categories. And for some rules new category &quot;Gendarme.Rules.DodgyBehavior&quot; can be created.<br>
<br>
As required, I'll be using C# to implement the rules.  I have chosen C# among other .Net langauages because I have prior exposure to C#.<br>

	</div>
 </td>
 </tr>
</table>
<a name='moodle' />
<h2> moodle </h2>
<table>
 <tr>
 <th>Title</th>
 <td>User Management Improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andrei Băutu</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Yu Zhang</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I want to add some features to Moodle that will make user management easier and faster. Most of these features are inspired by the phpMyAdmin application which allows operations to be performed on a single entity (e.g. table) through a single click, but it also allows same operations to work on groups of entities (after selecting the group members and the required operation). Other features that will be added or improved in Moodle are related to user accounts import/export. I recently needed to copy some user accounts from one Moodle installation to another one (both using the same Moodle version) and it was quite a task. I will also implement the ability for professors to attach notes to user accounts, and to course creators to specify the time for manual enrollments.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Extending and Improving Quiz Questions</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Adriane Boyd</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tim Hunt</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to update Moodle to add several new types of quiz questions and to update the student and teacher interfaces for a number of existing question types to make them easier to use.  The new types of questions would include click on an area of an image, Likert/opinion scale, and file-upload response questions.  The Likert and file-upload questions can be adapted from other types of activities already available in Moodle.  A new ordering question type would be created separate from the existing matching question type to allow more flexibility in the student interface and grading options.  New drag and drop student interfaces would be created for both ordering and matching questions with a fallback similar to the current matching question type.  Matching questions and the multi-select option in multiple choice questions would be updated to include more grading options and a graphical user interface would be developed to improve the teacher interface for cloze questions.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Command line installer and upgrader for Moodle</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Dilan Anuruddha K</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Penny Leach</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project will make possible to install and upgrade Moodle using command line interface. Functionalities will be the same as that are given in the web based installation of Moodle. Scripts are to be done in PHP. All the scripts will support platform that will support PHP.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Epaile: Automated Grading for Computer Programming Assignments</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Arkaitz Garro Elgueta</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Nicolas Connault</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project has the objetive to develop a plugin for Moodle, making it able to grade computer programming assignments automatically. This plugin is based in actual Assignment module, that gives us an easy way to allow students to upload any digital content for grading.<br>
<br>
Epaile will make it easy to create new assignments and define the actions used to compile, execute, and evaluate student code. When students submit their solutions, Epaile will compile, execute and evaluate the code, acording with solutions defined by teacher. Initialy, Epaile will support Java and C++ programming languages, but it will be plugin based, so new languages can be added if needed.<br>
<br>
This application will provide to teachers the way to organize students grades and of course more free time, and to students the possibility to know their grade inmediatly, and also check their evolution in course.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Messaging improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Luis Filipe Romão Rodrigues</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Moodle</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I plan to do messaging improvements, this would include the creation of a messaging class that all modules should use and better configuration of how the user receives its messages.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Moodle – Social Networking Features</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Luiz Cruz</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Moodle</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Moodle is great tool for students and educators. It allows the creation of an effective online learning community, expanding the boundaries of education beyond regular classrooms. By adding social networking features to Moodle, the sense of belonging to a community in such an online environment would grow even stronger. Members would be able to describe and share their interests in a systematic way, increasing the potential for interactions among them. It would be possible for members to find, connect to, and share ideas with people having similar interests.<br>
<br>
One way to make these types of interactions possible is to let users describe their interests with tags. The vocabulary of these tags would be created by the members of the community. When a member wants to describe one of his interests, he would search for tags that others have been using for that purpose. The tags a member has would appear in his profile, so that others would know what his interests are. Each tag would be linked to a page where there could be a description of it, a searchable list of members that have this tag and possibly some kind of collaborative tool (wiki, a forum or a blog).<br>
<br>
One other feature that would also be very helpful for moodle users to connect and stay in touch with peers would be a “friends list”. Social networking tools such as Facebook and Myspace have shown that this is a concept of great value to users. This feature would increase the involvement of users in the community, making them feel connected to it and to their colleagues. Members would be able to add friends to their list, which would appear in their profile.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Moodle Voice</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mayank Jain</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David Jesús Horat Flotats</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The objective of this project is to provide a Multimodal interface to Moodle so as to navigate it with voice with a VoiceXML enabled browser, such as Opera. Multimodal interaction provides the user with multiple modes of interfacing with a system beyond the traditional keyboard and mouse input/output.<br>
<br>
Making Moodle voice enabled will help disabled people, specially blind and motor disabled, to interact with this great e-Learning tool. Not only that, but also this gives another input interface which can be used to interact faster with the application.<br>
<br>
I will be implementing voice navigation and form filling through voice. I will be using VoiceXML, an XML language for writing Web pages you interact with by listening to spoken prompts and control by means of spoken input, and customized scripts to implement the above functionality.<br>
<br>
Detailed Plan can be obtained from my website:<br>
http://mayankjain20.googlepages.com<br>
<br>
Contact @gmail:mayankjain20<br>

	</div>
 </td>
 </tr>
</table>
<a name='mozilla' />
<h2> mozilla </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Enable Roaming Support in Thunderbird</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nick Kreeger</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David Bienvenu</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In a situation where a Thunderbird user has an installation at work and at home, there is a very obtrusive way of synchronizing personal settings such as mail filters and address book contacts. If a user wants to keep his or her personal settings consistent on both installations, the process would be very intensive and involve manual copying of the contents of the files between the installations.<br>
<br>
My solution would give the user a synchronization feature that would transfer their personal settings between one or more profiles. The synchronization would store the desired information in an IMAP folder, and be passed back and forth between profiles to keep the data concurrent.<br>
<br>
Another option would be to implement the same type of synchronization in a server-less configuration. The type of synchronization would be carried out over an email message, and eliminate the need for IMAP server synchronization.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implementing cross-session download resume</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Srirang G Doddihal</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Dan Mosedale</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Abstract<br>
=========<br>
<br>
This project consists of implementing download resume across different sessions of Mozilla Firefox, i.e if at all the browser was closed or the system itself was shutdown when a download was going on, the download can be resumed when the browser is started the next time. Firefox currently supports pause and resume within the same session. Currently there is no support for appending new data to the partially downloaded files. The project encompasses solving this problem also.<br>
<br>
With this project Firefox will have a feature that is available with only a few top download managers. Firefox users can rely on its native download manager in case of bad internet connection or frequent power failures.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Link Fingerprints</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Edward Lee</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Gervase Markham</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Link fingerprints allow clients such as Firefox to check automatically the validity of a file and inform the user if the retrieved file is not as expected. The primary usage would be to ensure that files downloaded to users are exact copies of what the provider intends. But link fingerprints can also validate embedded page content (image sources, script files, object references) as well as other resources (html, xul, xpi).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>JPEG2000 Support for Firefox</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Benjamin Karel</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stuart Parmenter</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 JPEG2000 is a standard for compressing photographic images. It produces higher-quality images at smaller file sizes than the current web standard, JPEG, but the only browser to offer native support is Safari. Because of this, it is unfeasible for web sites to use JPEG2000, since they must assume their images would not be rendered.<br>
<br>
I propose to write a new extension that will add JPEG2000 support to Firefox. Hopefully this will be the first step towards seeing ubiquitous support for JPEG2000 on the web.<br>
<br>
The benefits of ubiquitous JPEG2000 support would be direct.<br>
If Google, for example, saves 150 GB/day in bandwidth by serving smaller JPEG2000 files from Images, it alone could save twenty seven thousand dollars a year in bandwidth fees. End-users benefit too, by downloading smaller images that look better than what the current standard offers.<br>
<br>
This project will be implemented as an extension for Firefox. This will allow any interested user to view JPEG2000 images inline, while at the same time avoiding unnecessarily large changes to Firefox's trunk source code. It may also spur advocates of other image formats to write similar extensions, thus further strengthening Firefox's ecosystem.<br>
<br>
The full proposal may be viewed here:<br>
http://eschew.org/projects/soc/2007/application.html<br>
<br>
I may be contacted at {my first name}@{the above domain}<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Microsummary Generator Web Service and Application Improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ryan Flint</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael D. Melez</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this project is to enhance the usability and discoverability of microsummary generators for users and provide features that enhance the abilities of generator and content authors to convey their information easily and in a format beneficial to their users. Through this project I intend to provide incremental improvements to the microsummary service itself as well as an open web service integrated into Remora to allow generators to be as easily distributed as extensions and themes. I also intend to upgrade my Microsummary Manager extension to make use of the new web service in order to provide users with visible notification within the UI of available generators for the page they're currently visiting.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Camino : Tabosé</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jeff Dlouhy</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stuart Morgan</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will add functionality and eye candy to Camino by implementing Tabosé. Tabosé will make it easier to switch between tabs and see all the sites you currently have open. At WWDC ’06 Bertrand Serlet, Vice President of Software Engineering at Apple stated that at first, software needed function, then ease of use, and now needs a “wow factor.” Tabosé will be the feature that adds the “wow factor” to Camino.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Integration of Mozilla Thunderbird with Windows Vista Desktop Search</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Damitha Pahan Fernando</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Scott MacGregor</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The integration of Mozilla's popular Thunderbird mail client with Windows Vista's new index based search tool is a feature that the TB community has been requesting for sometime. The main goal of this GSoC project is to develop of a protocol handler for Windows Vista desktop search tool that will enable it to crawl through TBs messages and index them and eventually TB users will able to search within their messages through windows vista desktop search.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Firefox automation &amp; Tinderbox integration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>HARISHANKARAN K</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Nagappan</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 *Synopsis*<br>
&nbsp;&nbsp;Firefox 3 automated smoke-testing using Linux Desktop Testing Project.<br>
&nbsp;Tinderbox integration of LDTP results.<br>
<br>
*Benefits to Community*<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;Automated testing will result in finding the bugs in the new releases of firefox sooner and easier which in turn will help in fixing the bugs sooner.<br>
<br>
*Deliverables*<br>
<br>
&nbsp;&nbsp;I will be integrating tinderbox with ldtp.<br>
&nbsp;&nbsp;Test scripts for Mozilla Firefox.<br>

	</div>
 </td>
 </tr>
</table>
<a name='mysql' />
<h2> mysql </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Title: MySQLXplorer: Enabling Keyword Search in MySQL Applications</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mayssam Sayyadian</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>James A. Starkey</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Internet search engines such as Google have popularized keyword based search. Applications in which plain text coexists with structured data are pervasive, examples of which are CRM and Knowledge Management applications among many MySQL customers. The simplicity of keyword search as a querying paradigm offers compelling values for data exploration. Specifically, keyword search does not require a priori knowledge of the database schema and its catalogs. The above is significant as much information in a corporation is increasingly being available at its intranet.<br>
<br>
Currently, MySQL provides indexing and querying capabilities for textual attributes that incorporate information retrieval (IR) relevance ranking strategies, but this search functionality requires that queries specify the exact column or columns against which a given list of keywords is to be matched. This requirement can be cumbersome and inflexible from a user perspective: good answers to a keyword query might need to be 'assembled' 'in perhaps unforeseen ways' by joining tuples from multiple relations. Moreover, casual users, usually have little knowledge of formulating keyword queries using SQL extensions, not to mention they are - in many scenarios - more interested to discover unexpected answers that are often difficult to obtain via rigid-format SQL queries.<br>
<br>
MySQLXplorer operates on relational databases and facilitates information discovery on them by allowing its user to issue keyword queries without any knowledge of the database schema or of SQL. The system administrator will use a Web interface to specify the database and its desired tables to publish for keyword search. Then the typical user will connect to a Web application, with an interface similar to other Web search engines, to query the database. MySQLXplorer returns qualified joining networks of tuples, that is, sets of tuples that are associated because they join on their primary and foreign keys and collectively contain the keywords of the query. The answers to a keyword query are ranked based on their similariy to the keywords, how strong the keywords are correlated in every answer, and other properties that can be specified through the scoring API of the MySQLXplorer.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>MySQL Auditing Software</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Umair Mehmood Imam</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sheeri Kritzer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Project:<br>
&nbsp;&nbsp;Development of a MYSQL Auditing Software.<br>
<br>
Modules:<br>
&nbsp;The separate aspects of the software are:<br>
<br>
&nbsp;1). Netowrk Process : Monitoring of packets through a network of nodes<br>
&nbsp;2). Graphs and Reports : Reports showing the statistics accompanied with the graphs<br>
&nbsp;3). Administrative interface<br>
<br>
Building on the concept of the &quot;poor man's query profiler&quot; at http://forge.mysql.com/snippets/view.php?id=15 , this project entails developing a process to listen to network packets to find MySQL packets destined for a server, and keeping a copy of the packet to use in the auditing of what commands are sent to that MySQL server. This project can accommodate a light or heavy workload, and one or more students.<br>
<br>
The separate aspects of the software are: Network process: process to intercept network packets on a separate machine (in the same network range) for full access to information being sent to the database without causing any load on the MySQL server or interference with the queries. This process should also parse the queries and be able to store them in its own database.<br>
<br>
Graphs and reports: This module will show statistics and graphs.<br>
<br>
Administrative interface: This will take user input and write to the configuration file that the &quot;network process&quot;, described above, will read to determine which queries to keep and which to not worry about. It will also configure the &quot;graphs and reports&quot; desired by the user<br>
<br>
All deliverables will be released under the GNU General Public License<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>IPv6 network support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Miloš Prodanović</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brian Aker</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 IPv6 network support<br>

	</div>
 </td>
 </tr>
</table>
<a name='nescent' />
<h2> nescent </h2>
<table>
 <tr>
 <th>Title</th>
 <td>A PERL based Command Line Interface to a Topological Query Application for BioSQL in Support of High Throughput Classification and Analysis of LTR Retrotransposons in Plant Genomes</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>James Estill</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Hilmar Lapp</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A biologically relevant classification scheme is at the heart of any study of the distribution and abundance of biodiversity. This statement holds across biological scales ranging from the taxonomies of complex vascular plants to the ontologies of the genes and transposable elements that the genomes of these plants contain. A robust and biologically meaningful classification scheme is thus the cornerstone of any analysis of transposable elements. As a biologist interested in the influence of infrastructural genomic features on the distribution and abundance of LTR Retrotransposons in plant genomes I am therefore developing the “RepMiner” application which takes a graph theory based approach to the classification and assembly of the repetitive fraction of plant genomes. The current results of this research have identified putative LTR retrotransposon families that have been previously been named as separate families under existing nomenclatural systems. Future application of this approach will allow for the assembly and classification of LTR retrotransposons from partial genomic data sets, and will provide the framework required to study the evolution of LTR retrotransposons across plant lineages and within genomes.<br>
<br>
A current development need of the RepMiner approach is to convert these putative classifications into phylogenies representing the history of the individual LTR retrotransposons within these families. This research will generate a large number of phylogenies produced by multiple compute nodes and would require that these phylogenies be flexible to permutations in tree topology. This phylogenetic evaluation would therefore benefit from the use of a flexible SQL based phylogenetic database. My participation in the NESCent proposed topological query application would therefore fit into my individual research needs as well as produce informatics resources that are useful to the larger community.<br>
<br>
I believe that I am the best applicant to complete this project because: (1) I have experience as an open source developer in both PERL and SQL, (2) I have informatics experience as a researcher studying aspects of comparative biology at the genome scale that has contributed to peer reviewed publications, (3) the goals and timeline for this specific project are in line with my research goals over the next six months, and (4) I have an interest in maintaining future collaborations with the NESCent phyloinformatics working group.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Ajax interface for the XRate command-line tool</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Lars Barquist</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ian Holmes</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Mathematical and computational techniques have completely transformed the biological sciences in the space of a few decades. What were once largely qualitative, descriptive sciences have become more quantitative and mathematical in their approach to studying living organisms. Nowhere is this more evident than in the science of phylogeny.<br>
<br>
XRate is a Unix command-line tool for the interpretation and analysis of stochastic phylo-grammars. Given multiple alignments and a phylo-grammar describing an HMM/context-free grammar encoding assumptions about mutation rates, etc., XRate will produce likely phylogenetic trees relating the the given alignments. It is my hope to develop an Ajax front-end for this tool over this summer.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Multi-language bindings to the C++ NEXUS Class Library</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Carlos David Suárez Pascal</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mark Holder</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 NCL (https://sourceforge.net/projects/ncl) is an open source library created for reading and writing of the NEXUS (http://en.wikipedia.org/wiki/Nexus_file)bioinformatics format allowing easy integration of NEXUS in open source applications. NCL supports most of the standard characteristics of NEXUS by means of a object oriented callback-driven design. One drawback of NCL is the non-existing and non-planned extension of NCL to scripting languages such as Python, Perl and Ruby. The goal of this SOC proposal is the development of bindings for these scripting languages employing SWIG, the Simplified wrapper and interface generator, which is an open source tool designed to facilitate the development of extensions from C/C++ to another languages.<br>
This proposal, if it is selected, will deliver bindings of NCL for the three languages mentioned (Python, Perl and Ruby), providing a way for rapid prototyping and easy development of applications supporting the NEXUS format.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Phylogenetic &amp; haplotype displays for GBrowse</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hisanaga Okada</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lincoln Stein</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 As genomic data from an increasing number of species become known and annotated, the demand to efficiently manage and display the data will increase.  The Genome Browser is an intuitive way to display information for one organism by stacking different tracks of information along the sequence in a genome.  To further add to this, it is proposed that genetic haplotypes, multiple sequence alignments and phylogenetic trees be added as new information tracks to the browser.  It will be envisioned that genomic data for a number of specific tracks for a number of species can be efficiently and intuitively by weaved together giving greater insight to the phylogeny of different organisms.<br>
<br>
The proposed timeline and order of activity would be the following:<br>
1) Break down the single image down to its individual tracks.<br>
* Have each track write to a single image<br>
* Using AJAX, have each track write and display to the web front only when requested<br>
2) For a single organism, add subsets of other organisms’ tracks that have orthologs.<br>
* Cache ahead of time sections of a genomes that are related to another organism’s genome sequence / coordinate / gene ortholog<br>
* or create a easy to use and update tagging system that refers one point of a genome to another<br>
* For a list of related organisms, find a section of their genome that relates to the main organism<br>
* Display the appropriate tracks for that organism parallel with the main organism<br>
3) Add the phylogenetic tree viewer<br>
* Cache ahead of time how the phylogenetic tree will be organised (TreeJuxtaposer?)<br>
* Display sections of the phylogenetic tree<br>
4) Add the multiple sequence alignments viewer<br>
* allow zooming in of a particular sequence possibly for a separate display<br>
* align with sequence data for other related organisms on different but parallel tracks<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Developing user-oriented, standards-based phylogenomics tools: PhyloSOAP and PhyloWidget</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gregory Jordan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>William H. Piel</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project aims to apply the standards, tools, and philosophy of modern web services design to a small area of bioinformatics, that of storing, querying, and editing phylogenetic trees. I plan to build upon available open-source bioinformatics libraries (such as Bioperl and Biojava) and data sources (the various taxonomy, ontology, and sequence databases) by creating two new tools: first, a web service for storing and retrieving phylogenetic tree data, and second, a web-based UI component that can utilize the web service to store, edit, and query phylogenetic trees created and modified by the user.<br>
<br>
By implementing its functionality using standardized technologies such as SQL, SOAP, and AJAX, this project will explore the ways in which the bioinformatics community can benefit from the large investment of time and resources put into developing the wealth of web standards available today. Specifically, I plan to (a) create a useful tool for phyloinformatics and (b) demonstrate how the specialized use of Web standards and user-oriented design can create a simple, effective, and modular tool for bioinformatics researchers. A brief outline of the project is as follows:<br>
<br>
1. Create a web service for storing and querying phylogenetic tree data.<br>
<br>
&nbsp;&nbsp;a. Use a BioSQL backend for efficient storage and querying of phylogenetic trees.<br>
&nbsp;&nbsp;b. Include the capacity for topological queries (see Wang et al. 2005).<br>
&nbsp;&nbsp;c. Use Bioperl or Biojava to create a REST- or SOAP-compliant interface to the PhyloSQL backend.<br>
&nbsp;&nbsp;d. Evaluate the service for its speed and memory efficiency.<br>
<br>
2. Create a web-based front end that allows one to query and manipulate trees stored in the database.<br>
<br>
&nbsp;&nbsp;a. Research the most desirable language and toolkit (AJAX, Flash, or Java).<br>
&nbsp;&nbsp;b. Identify commonly-used manipulations on phylogenetic trees.<br>
&nbsp;&nbsp;c. Create a dynamic web-based user interface for creating, editing, and storing phylogenetic trees.<br>
&nbsp;&nbsp;d. Document the UI and provide an API for its use and extension.<br>
&nbsp;<br>
3. (if all else goes well) Generalize the concept: create a code framework for database-driven, standards-based bioinformatics widgets.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Visualizing Phylogeographic Information</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Yi-Hsin Erica Tsai</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David Kidd</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Phylogeography has enjoyed an explosion of data from research on migration patterns of organisms to studies of population genetics and population structure. However, there is still no easy way to generate maps of DNA haplotype frequency data. Imagine a map with all sample locations marked, and centered on each location a pie (or stacked bar) chart is visible showing the frequency of each haplotype within the population. The size of each pie is proportional to the amount of samples genotyped in that population. Often these maps are drawn by hand in Adobe Illustrator or other difficult to use, proprietary map drawing programs (e.g. ArcGIS). In addition, this procedure becomes unfeasible with larger data sets. This method does not lend itself to viewing and analyzing multiple data sets simultaneously as is becoming more common in comparative phylogeography. I propose to develop a software package that implements such a viewer. This program would have broader applications than just to genetic data, any sort of frequency based information with a geographical component (e.g. % of sunny, rainy, snowy days) could be visualized.<br>
<br>
The product would be a web based application with ties to Google Maps or Google Earth. The web application would include a data manager that would export to KML. The KML would be used within the browser for visualization using Google Maps or could be exported to integrate with Google Earth. I envision three main components to develop. First, the data manager is needed to import, edit, and export data. Second, a visualization tool will generate the phylogeographic maps. Third, the visualization tool will be expanded to display multiple datasets simultaneously; for instance to compare haplotype frequency distributions of multiple loci or haplotype frequencies of multiple species. This program will allow manipulation of data within the application (e.g. grouping all rare haplotypes together, or only showing a subset of the populations) to generate new phylogeographic maps without need for creating and loading new input files. The goal for the program is to allow for easy visualization of phylogeographic data on a map and to facilitate subsequent spatial data analysis.<br>
<br>
This software could be extended to calculate population structure parameters, such as Fst, Da, and isolation by distance.  It could also be developed to compute more sophisticated spatial statistics or perform tests of congruence among datasets.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implementing a web interface for command line-based bioinformatics tools.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>James Leung</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Suzanna Lewis</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project aims to construct a web-based interface for the xrate tool. Given that the intended audience of xrate includes biologists who are both comfortable working in a Unix environment and those who would much rather work in a GUI or even a web-based environment, the &quot;wrapping&quot; of xrate in an attractive and intuitive interface would allow xrate and other similar tools to access a far larger user base. Ultimately it is hoped that such an interface would then be portable enough to be used on other similar tools to allow for easy deployment of any command line based bioinformatics utility.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Biodiversity conservation algorithms and GUI</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Klaas Hartmann</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tobias Thierer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Conservation managers are faced with the problem of having many species that are in need of conservation but limited funds to allocate to them. This raises the question of which species should be protected. One framework for prioritising species for conservation is the Noah's Ark Problem (NAP). The NAP combines a phylogenetic tree for the species of interest with species specific survival probabilities and conservation costs. The aim of the NAP is to allocate conservation expenditure such that future expected biodiversity is maximised. This results in a computational difficult problem -- the general problem may be NP hard -- however several algorithms have been developed by myself and others to solve variations of the NAP with particular parameter restrictions.<br>
<br>
At present no package is available that implements the various algorithms for solving the NAP. The only implementations that exist have been written for individual algorithms by a range of researchers in a range of languages. This severely restricts the application of these results to real conservation problems -- particularly as those people interested in applying these methods (eg. conservation managers) often have little mathematical or programming background.<br>
<br>
This project will implement the various algorithms for solving the Noah's Ark Problem, thereby encouraging future results to become available in the same package. A GUI will be built on top of this implementation that enables non-programmers to apply these methods and compare species prioritisations with those produced by related simple indices. This will create a common package where researchers can implement algorithms and end users can apply these results to their problems.<br>
<br>
BioPerl forms a good basis for this project as many related species specific indices are already implemented in Bio::Phylo. This project will produce species prioritisations from Bio::Tree::TreeI compatible objects and conservation information (eg. survival probabilities) using algorithms developed for solving the Noah's Ark Problem. The GUI will be cross platform deployable and easy to install. Good documentation will be produced that thoroughly describes the implemented algorithms and indices.<br>
<br>
Mentors: Tobias Thierer, Rutger Vos<br>

	</div>
 </td>
 </tr>
</table>
<a name='netbsd' />
<h2> netbsd </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Porting ZFS</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Oliver Gould</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Dieter Baron</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Sun Microsystem's Zettabyte Filesystem (ZFS), since Nov 2005, has<br>
proven to be a major breakthrough in filesystem technology, supporting<br>
features such as disk pools, snapshots, 'unlimited' scalability, and<br>
various other performance improvements over prior art.  Such<br>
advancements will make ZFS a major force in industry in coming years.<br>
<br>
A BSD-licensed implementation of ZFS is utterly impractical within the<br>
constraints of Google's Summer of Code (SoC).  However, porting the<br>
CDDL'd ZFS implementation present in OpenSolaris is feasible.  In<br>
particular, Pawel Jakub Dawidek has been able to port a significant<br>
portion of ZFS to FreeBSD.  His work provides a good basis for porting<br>
ZFS to NetBSD.<br>
<br>
Furthermore, OpenSolaris has published a high-level roadmap for<br>
porting ZFS to other platforms.  This outlines a path for success,<br>
which I shall follow.<br>
<br>
The primary objectives of this project are:<br>
&nbsp;- A functional zpool implementation<br>
&nbsp;- Documentation and plan for future development<br>
<br>
Secondary objectives include:<br>
&nbsp;- /dev/zfs<br>
&nbsp;- libzfs<br>
&nbsp;- ZVOL<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Running Kernel File Systems in Userspace</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Antti Kantee</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>William Studenmund</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of the project is be able to compile the same file<br>
system code both for userspace and the kernel.  This will provide<br>
several benefits mostly related to helping development of new file<br>
systems, but also benefit in testing existing file system code.<br>
A similar idea is running the entire operating system as a process,<br>
but it will not provide complete isolation especially in test cases<br>
for the implementation under test.<br>
<br>
As the project is highly nontrivial, the initial goal is to be able<br>
to run the same ffs codebase both in the kernel and userspace.<br>
The obvious long-term goal, which will be very closely kept in<br>
mind, is an environment to run all file systems in kernel- or<br>
userspace.  Also, this environment should be constructed in a<br>
fashion where code duplication and maintenance overhead is minimized<br>
as far as possible.<br>
<br>
The initial plan is to start adapting the NetBSD puffs interface<br>
to be able to link in-kernel file systems to and then start solving<br>
issues with emulating the &quot;bottom end&quot; of file systems.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improving the pkgsrc build system</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jörg Sonnenberger</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Johnny Lam</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The pkgsrc infrastructure has currently three majors issues:<br>
(a) It is impossible to build packages for other architectures.<br>
(b) For bulk builds, it is not possible to utilize more than one CPU in a safe manner or distribute builds across a cluster.<br>
(c) There's no infrastructure for automatic notification of maintainers when builds failed or to trace the state of a package over time and platforms.<br>
<br>
The first item is a requirement for moving to modular Xorg from pkgsrc for NetBSD itself. It is insane to try to support full cross-compilation for all packages, but can be done for a restricted subset like Xorg.<br>
The second item is about faster bulk builds, resulting in more up-to-date binary packages and better response times for developers.<br>
The third item is also important to help developers trace the state of the tree and avoid introduces issues over and over again.<br>
<br>
To address (a) I want to extend the tool frame work to deal with native vs. host dependencies. It is desired to add support for usin the buildlink3 framework with not-installed packages to allow full non-privileged builds. For (b) I want to either cleanup the existing Python-based prototype of the alternative bulk build system to make it ready for general deployment or implement the core components in C for higher portability. For (c) a combination of more intelligent output from the tools in (b), indices and query tools is planned.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Hardware monitoring and HAL port</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jáchym Holeček</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Quentin Garnier</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 To quote from http://www.netbsd.org/contrib/soc-projects.html#hal<br>
<br>
&nbsp;&nbsp;Almost all operating systems provide a way to notify userland of<br>
&nbsp;&nbsp;hardware changes. E.g. a new USB device was connected, a CD-ROM<br>
&nbsp;&nbsp;was inserted in a drive, a PCI Express card has been removed, etc.<br>
<br>
&nbsp;&nbsp;Unfortunately, there is no such functionality in NetBSD, which<br>
&nbsp;&nbsp;means that it is not really usable on systems where automation<br>
&nbsp;&nbsp;on hardware changes is desired. The most obvious example are<br>
&nbsp;&nbsp;desktop systems where one wants hardware to be managed<br>
&nbsp;&nbsp;transparently.<br>
<br>
This project aims to bring NetBSD in sync with other operating<br>
systems by implementing kernel event notification framework<br>
and a userland deamon to observe events and dispatch actions as<br>
configured. Events originate in the kernel (individual devices,<br>
autoconf(9) framework) and flow towards userland via a character<br>
device interface.<br>
<br>
NetBSD port of Freedesktop's HAL package will be created and<br>
provided in Pkgsrc, resulting in better integration between the<br>
base system and existing desktop environments -- KDE and GNOME<br>
are already available to NetBSD users. Kernel part of the project<br>
includes enhancements to the autoconf(9) machinery that are<br>
believed to be beneficial for other uses as well.<br>

	</div>
 </td>
 </tr>
</table>
<a name='neuros' />
<h2> neuros </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Project Lobster enhancements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Steven Robertson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ugo Riboni</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The OSD is an embedded media client and server, designed to blur the line between the computer and home entertainment for all kinds of multimedia.  Although many comparable platforms exist in this category, to this applicant's knowledge the OSD is unique in being both embedded and open-source.  Leveraging this trait will transform the Neuros OSD into a platform with an unmatched level of functionality and compatibility.  Ideally, the software developed by Neuros to run on the OSD would provide a common platform for the creation of a variety of community-driven tools and customizations, enabling seamless extensibility for users without sacrificing the integrated user experience of an embedded, application-specific device.<br>
<br>
Lofty goals, indeed.  Unfortunately, the current state of the OSD's software libraries and development environment makes casual development difficult and uninviting.  The existing community acknowledges this. In addition to an ongoing refactoring of much of the existing code to adhere to newer, more effective programming paradigms, there are a few efforts, known collectively as Project Lobster, to create an easy-to-use interface to the OSD's functionality from the lightweight scripting language Lua.  Most of these focus on creating simplified bindings for the libraries currently in use at the time, although a few have different goals, such as adding the ability to provide additional menu entries within the OSD's &quot;main app&quot; (in which most functionality currently resides) without having to modify and recompile the (monolithic) program.<br>
<br>
This project will enhance the level of completeness of Project Lobster.  In particular, this project aims to provide plugin functionality to the main application.<br>
<br>
For more information on Project Lobster, see this page: http://wiki.neurostechnology.com/index.php/Project_Lobster<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>ARM/DSP bridge</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christiaan Baaij</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Adam Torgerson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Project Title<br>
-------------<br>
ARM/DSP bridge<br>
<br>
Synopsis<br>
--------<br>
A combinations of userland tools and a linux kernel module to run code on the<br>
C54x DSP of the DM320 architecture.<br>
<br>
Project Details<br>
---------------<br>
Currently, the Neuros OSD only makes use of the DSP through closed source<br>
libraries that handle the encoding and decoding of video data and the playback<br>
of PCM data. The purpose of this project is to write a new interface between<br>
code on the ARM side and code on the DSP side. The current vendor of the closed<br>
source binaries has not released any specification on their interface and<br>
therefor the new interface will not be compatible with the current vendor code.<br>
<br>
The overall design of the project is the following:<br>
- Linux kernel module:<br>
&nbsp;&nbsp;Implements device interfaces to the DSP. For a very basic<br>
&nbsp;&nbsp;bridge/gateway at least two device interfaces should be present:<br>
&nbsp;&nbsp;* DSP control device that is able to reset the device and make it execute the<br>
&nbsp;&nbsp;&nbsp;&nbsp;code in the DSP program memory<br>
&nbsp;&nbsp;* DSP memory device that provides access to the DSP memory space for the<br>
&nbsp;&nbsp;&nbsp;&nbsp;userland application.<br>
<br>
- Userland application:<br>
&nbsp;&nbsp;A control utility for ARM/DSP bridge. Allows the user to load a DSP program<br>
&nbsp;&nbsp;and control DSP reset.<br>
<br>
The most minimal implementation of the project would allow the user to write a<br>
program for the DSP that is only able to get data through it's on-chip RAM<br>
(which also resides in the ARM memory space).<br>
<br>
Features that should be added to this minimal implementation before the end of<br>
Google Summer of Code:<br>
- Messaging service to allow communication between code on the ARM side and the<br>
&nbsp;&nbsp;DSP side. (Most likely an interrupt-driven routine).<br>
- Allocation of external memory for the DSP (internal RAM is somewhat limited).<br>

	</div>
 </td>
 </tr>
</table>
<a name='nmap' />
<h2> nmap </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Nmap Scripting Engine -- Infrastructure</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Stoiko Ivanov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Diman Todorov</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 During the last SoC Nmap was enhanced by a Scripting Engine, which gave<br>
the opportunity of developing tests on remote hosts or services, in<br>
order to get more information about them. While being fairly complete,<br>
and easy to understand, these scripts for the main part consist of<br>
copied boilerplate code. The aim of this project is to enhance the<br>
scripting engine by several nifty features, which would obsolete the copying. Furthermore scripts will become more concise and through this<br>
easier to understand. Documenting (the code itself and providing an api and examples) constitutes an major part in the project, because only if the Nmap-users out there know how easy script writing is, they will use it.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Feature Creeper and Bug Wrangler</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Doug Hoyte</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Fyodor Vaskovich</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 As I successfuly did last summer for SoC, I propose to work on adding features, fixing bugs, and assisting in other Nmap SoC projects.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Feature Creeper / Bug Wrangler</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Kris Katterjohn</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Fyodor Vaskovich</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 == Top Project Choice (If choosing one from the Nmap ideas page):<br>
<br>
'Feature Creepers / Bug Wranglers'<br>
<br>
<br>
== Are you willing and able to do other projects instead?<br>
<br>
'Slacker' looks pretty nice :)<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Feature Creeper/Bug Wrangler</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Edward Bell</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Fyodor Vaskovich</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Working on a selection of smaller features (common port list/moving massping/port state reasons) and fixing bugs.<br>

	</div>
 </td>
 </tr>
</table>
<a name='ogre' />
<h2> ogre </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Custom Memory Heaps and Object Allocators</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Timothy John Kelsey</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Steven Streeting</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will add a number of additions to the Ogre 3D engine via integration of custom manageable memory heaps for both debug and release builds. Allowing for more in depth memory debugging and the use of per object family heaps to improve handling of small object allocations. Overall resulting in a user controlled memory model for Ogre 3D.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Emulating Lesser Hardware Capabilities</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Juozas Gaigalas</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Wickert</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Most 3D applications are expected to work on a large variety of machines with widely different hardware capabilities. OGRE is designed with this expectation in mind and includes a simple, but effective mechanism for automatic fallback from advanced to simple graphics techniques (depending on the capabilities of user's graphics card). Although this mechanism is a gift for the end users, it makes things very difficult for the developers of OGRE applications. That is because testing both the advanced and simple techniques at the same time is very hard. There are two options for doing it: modifying the render system code/material definitions to trigger the use of each &quot;level&quot; of techniques and running the same program on several different machines. The second option may not be available to many users of OGRE, while the first option is repetitive,  time consuming and error prone. A better solution is to add a new option to OGRE that lets developers force the GPU fallback mechanism. This can be done by emulating the capabilities of less advanced GPUs. With this option testing what an OGRE application will look like on different video card should be as simple as changing a single line in a configuration file and restarting the application. This project does not add any cutting-edge features to OGRE. Instead it makes OGRE more developer friendly by saving developers' time. This means more community growth and more contributions to the OGRE project. Which means more cutting-edge features.<br>
<br>
This proposal suggests how to implement this emulation feature in three months. The proposal is split into four parts: interface, which defines how this feature can be used in OGRE applications, implementation, which suggests how this feature could be programmed, a preliminary test plan and the timeline/deliverables for implementing this feature.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Ogre Material Editor</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Brian Hudson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Casey Borders</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In Ogre, all aspects of an objects visual appearance are encapsulated in a Material. The Ogre Material Framework is a robust system allowing the programmer to define one or more rendering passes and optionally techniques for degrading gracefully based on a number of factors such as system hardware and/or level of detail.<br>
<br>
The goal of this project is to develop an editor for Ogre’s Material Framework. The Ogre Material Editor will provide the developer with Material Script and Shader editors, and allow them to enable/disable Passes and Techniques enabling rapid prototyping of new Materials. The Ogre Material Editor will be similar in appearance and functionality to the ATI RenderMonkey™ Toolsuite.<br>

	</div>
 </td>
 </tr>
</table>
<a name='olpc' />
<h2> olpc </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Game Development Infrastructure</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Lincoln Quirk</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kent J Quirk</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 PyGame needs to work well on the XO in order for developers to have an easy time making games. Right now it doesn't work well, and this project will make it work through whatever means necessary.<br>
<br>
Requirements:<br>
<br>
&nbsp;- A robust, platform-appropriate API that facilitates game programming in Python and PyGame on the XO.<br>
<br>
&nbsp;- A good-looking, well-performing demonstration game ported to the XO platform.<br>
<br>
&nbsp;- High-quality XO-specific documentation including examples.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Easy Game Toolkit</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Patrick DeJarnette</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kent J Quirk</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 While Pygame is extremely flexible for game development, it can be expanded by creating libraries that focus on simpler constructs commonly found in games.  This would reduce the learning-curve of Pygame, especially if children are the intended target, and also quickens game development.<br>
<br>
Below, I outline some ideas that are far from final, but should give some indication of the initial direction I would take if accepted.  These libraries would not be designed solely for the examples below, which merely illuminate certain aspects of the libraries.<br>
<br>
One idea is the concept of a particle class that has defined shape, position, velocity, and angle can be used to simplify many games in Pygame.  One could then add further properties as pairs that represent events and consequences. Examples of events include pressing or holding a key, collisions, global time events, and interval time events, while consequences alter properties of particles.<br>
<br>
For example, dual-player Pong could be considered as three particles, two of which, the paddles, are similar and have legal events corresponding to up and down keys.<br>
<br>
One can further simplify by including a general collision detector in the libraries, probably based on the Pygame sprite collision detectors.  In the Pong, the ball has collision with the paddle particles as an event whose consequence is altering the angle and velocity of the ball contingent on the properties of the collision such as position of the collision on the paddle and the paddle’s velocity.  The ball can also “collide” with the sides of the screen for various consequences.<br>
<br>
One can think of the background as particles with initial positions.  The main character sprite can have the property of “stickiness” associated with certain event-consequence pairs, that is, alterations to velocity instead get put to all other particles on screen so that the character stays in place while the background moves.  One can extend this to pseudo-stickiness, where the player has stickiness associated with a particular event-consequence pair based upon some further conditional or only a fraction of the velocity gets attributed to the other particles.  These give something like in Super Mario Brothers, where the screen scrolls only after Mario gets close to the edge.<br>
<br>
AI in these libraries can be conceived as particles who have consequences that later other event-consequence pairs.  Thus, a Koopa, once stomped on by Mario, changes its consequences associated with collisions.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implementing a PyGame toolkit for 2D games</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Roberto Faga Junior</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Samuel Klein</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Making games isn't a easy task, neither if programmers don't have sufficient tools. If we program a desktop application, we have GTK to provide easy window design and a lot of libraries to provide easy of each element. Programming a game is completely different, as we can't have too attention to game programming as we need to look for game design side, with designing story, drawing images, mixing audio, authoring videos, and so on.<br>
<br>
PyGaKit is a toolkit to provide specific features from PyGames, providing to programmer ease to make a determined type of 2D game. With a set of sub-kits and template system, where a template represents a structure to produce a determined game type, PyGaKit can help game designers to program a 2d game with few code lines, letting him to focus on game design. PyGaKit will be coded in Python, with PyGame library use. Also some media libraries can be used.<br>
<br>
Original idea project from:<br>
http://wiki.laptop.org/wiki/OLPC_Google_Summer_of_Code#Easy_Game_Toolkit<br>

	</div>
 </td>
 </tr>
</table>
<a name='ooo' />
<h2> ooo </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Improve the current notes implementation in OpenOffice.org Writer</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Maximilian Odendahl</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mathias Bauer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I would like to improve the implementation of notes and related issues in OpenOffice.org. Specifically, there are four areas that I would like to address:<br>
<br>
- Improving the visualisation of notes<br>
Right now, notes can hardly be recognized, as they are only represented by a tiny yellow box. The content only becomes visible when the cursor is placed hovering over the box. Additionally, there is no word wrap which makes reading longer text even harder. There is also no displayed information about the author of a particular note, nor are different notes distinguished by author through the use of, for example, different coloured boxes.<br>
My proposal is to improve this visualisation to show notes constantly on the margin area with a visual link to the note's place.<br>
<br>
- Usability of notes<br>
There are several usability issues involved, which make working with notes in Writer difficult. Improvements I would like to implement include easier editing, deleting of notes as well as deleting of multiple notes simultaneously and improvements to the notes menu layout. The exact changes need to be discussed with the Writer team.<br>
<br>
- Improve the navigator view of notes<br>
Currently notes do not wrap, it is not possible to delete several notes simultaneously and there is a random order without a means of reordering notes by creation time, author or document position. I propose to address these issues in the new implementation.<br>
<br>
- Improve the edit view dialog<br>
The current edit dialog is very basic and not visually appealing. It is very small and requires excessive scrolling and offers no spell check or other helpful accessories. This will also be addressed in my implementation proposal.<br>
<br>
<br>
This work will satisfy many user requested enhancements such as issue 6193, 16251, 23465, 38819, 45788 and 62625, and also fix several bugs related to the current implementation such as issue 48150 and 58867.<br>
<br>
As this is a constant request from the community and seems to be a major reason for staying with Microsoft Word, I would be very excited to work on this project and make a real difference to the application's usability and acceptability. I am fully aware that my proposal cannot be finished during the Summer of Code time, but I would like to take this opportunity to stay with the OpenOffice.org project after the Summer of Code program is over in order to continue improving the notes implementation, working with the user community and ironing out any possible bugs.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Integration of R into Calc</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Wojciech Gryc</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Niklas Nebel</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project will focus on integrating the &quot;R Project for Statistical Computing&quot; into the OpenOffice.org Calc spreadsheet application. While Calc currently provides a number of useful graphing and statistical functions, the amount of statistical tools available in R is much greater, though accessing them is often a challenge for non-technical users. This project aims to build an add-on to Calc that will integrate R into the software, allowing users to pass spreadsheet data to the software and present results within Calc rather than in a console or through the use of files external to Calc.<br>
<br>
This project aims to provide users with three features. After the integration takes place, users will be able to send scripts through R, with the output being placed as data within the spreadsheet. A second feature, aimed as less advanced users, will be a premade set of dialog windows (an &quot;R Wizard&quot;) that will allow users to choose from a set of functions and parameters therein. The output, again, will be stored within the Calc spreadsheet. A final feature of the add-on will be to allow users to use built-in graphics tools within R to actually display their data as graphs, networks, or other visual aids that are currently not built into Calc itself.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>AODL library / ODF toolkit</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Oleg Yegorov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Dieter Loeschky</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 AODL is a .NET module of the ODF Toolkit. It is written in C#  and provides a series of namespaces, interfaces and classes to handle OpenDocument Format Files directly without using OpenOffice API.<br>
Developers using it are not required to know the details of the format.<br>
<br>
At present time AODL supports the following features:<br>
• Creating, loading, manipulating documents in the text and spreadsheet formats.<br>
• Export loaded or created documents into the HTML format (text and spreadsheet documents).<br>
• Export loaded or created documents into the PDF Format. (this is in an early state of implementation and only available for text documents)<br>
<br>
The project is in a beta-stage now and could be enhanced in many different aspects. I have provided some ideas regarding it in the detailed description section.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improve UI Design and Layout</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ricardo Pereira de Magalhães Cruz</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Meeks</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently, OpenOffice.org interface layout is compiled into the binary and its format is not suitable for working on with a visual designer. Also, the layout is specified in absolute coordinates, which make it a hassle to add or remove widgets, and can result in truncated widgets due to internationalization. I propose to work on separating the UI writing from the code to XML-based files, and having the layout being expressed in relative terms.<br>
<br>
&nbsp;What needs to be done:<br>
<br>
* The infrastructure must be worked out so we can write container widgets, in order to have fluid layout. We want to re-use the current API the most, as well as to not break the current layout code. Widgets already have calls to calculate their minimum size and to change their size, and we may re-use at first the invalidate drawing notification for the purpose.<br>
<br>
* Some container widgets will have to be written. The API design should keep in mind that the layout will be done through XML, but of course also keeping it nice for those that may write it in code. Ordinary toolkits focus is in having programmers type the least; so they offer a set of containers, with different levels of granularity (for instance, wxWidgets offers 3 matrix-based containers and 2 vector-based containers). In a markup language you don't have to worry about either having methods with a massive number of arguments, or splitting them up and have programmers using references for the children or provide an index-based solution.<br>
<br>
* A XML format specification and implementation for the layout. We may want to try to borrow the naming of the widgets from OpenDocument's Forms for familiarity. For the specification, the heated discussion will be with regard to containers. We probably want it also possible to specify ids for containers, so we can manipulate them through code (though such an interface would probably be better built in the code). For the implementation, we need to hook the XML parser to the code that builds the current interface resource files.<br>
<br>
* Finally, dialogs must be ported to the new system. There won't be a chance to port them all, but we probably want to take care of the most used and rich dialogs (like all those from the Format menu) and also the ones that programmer's modify the most (like the Tools –&gt; Options).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Impress: OpenGL rendered transitions</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Shane Michael Mathews</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Thorsten Behrens</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 To add 3D transitions to the Impress application. Transition is an animation where one page is visible in the beginning and another in the end. It is used during presentation slideshow to switch pages.<br>
<br>
In the process of implementing OpenGL transitions an UNO API should be added to slideshow code, so that OpenGL transitions engine might be created as standalone UNO component. Current transitions should be refactored to another UNO component.<br>
<br>
The engine will get the previous and next pages and should render the transition at given speed.<br>
<br>
The participant should also implement at least 5 OpenGL transitions, rendered by the UNO component.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Complete User Interface respecting Aqua Human Interface Guidelines (Aqua Only)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ismael MERZAQ</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Bachard Eric</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The implementation of all the missing aqua controls will enable OpenOffice.org to be a real Mac OS X application, following better the aqua look and feel and the Apple Human Interface Guidelines. This will improve the user experience, and will make easier the transition to OOo for new users. With the X11 version of OOo on Mac OS X, users are a bit disturbed because OOo is not very &quot;aqua&quot;. And look and feel is something important for Mac users, maybe more than for windows or linux users. Indeed, some mac users prefer using NeoOffice (although it is slower than the current X11 version of OOo) or buying MS Office to have an aqua office application. Therefore it is important for OpenOffice.org to complete the implementation of aqua widgets.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Mac OS X Address book integration (Aqua / X11)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Omer Bar-or</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sebastien PLISSON</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to integrate the Mac OS X Address Book with OpenOffice.org (both Aqua and X11 versions), as described on the OpenOffice.org project page for the Google Summer of Code. This task would provide the equivalent of the Mozilla address book integration already found in OpenOffice.org, but using the Mac OS X Address Book API. Additionally, not mentioned in the project page, is the issue of combining two address books (Mozilla and OS X), which would require handling collisions or selecting one of the two address books to use.<br>
<br>
This project has four phases, the first three of which are described briefly on OpenOffice.org's project page. a) Familiarize oneself with the current OOo Mozilla Address Book integration - this task belongs first because it will be a guide for exactly which parts of the Max OS X Address Book API are important (see (b)). This task involves first experimenting with the Mozilla address book implementation by changing bits of the code and seeing how those changes manifest in the OOo address book functionality, then creating an equivalent to the Mozilla address book integration that works with a text file (since nothing makes a person more familiar with code than building it). b) Familiarize oneself with the Mac OS X Address Book API - after (a), the information needed from the Mac OS X Address Book should be known, so this task is largely a matter of reading up on the API and seeing what is available and in what forms. One place to look, if the API itself is unclear, is Quicksilver's Apple Address Book Module, which uses the API. The result of this task is a small program that uses the Mac OS X Address Book API to create the text file from which the section of code created in task (a) reads. c) Make a prototype for OOo Mac OS X address book integration - given (a) and (b), this process is straightforward. One replaces the reading from and writing to a text file from (a) with the interaction with the Mac OS X Address Book API from (b). d) Develop strategies for handling conflicts between the two address books - this task first entails familiarizing oneself with OOo's strategies for conflict resolution, especially if a strategy is already in place for address book integration. If a strategy is not in place, the second part of this task involves creating a strategy specific to address books. And, finally, if time permits, completing this task means prototyping the strategy using the Mac OS X Address Book and Mozilla integrations.<br>

	</div>
 </td>
 </tr>
</table>
<a name='openmrs' />
<h2> openmrs </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Clinical Data Visualization Tool</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hugo Rodrigues</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Darius Graham Jazayeri</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Medical Informatics often involves managing and processing large volumes of information. For example, clinicians are often forced to infer treatment plans through interpretation of large sets of historical, laboratory, and other test data for each patient. Researchers evaluate large retrospective patient cohort data sets to find particularly effective treatment protocols or previously unrecognized relationships between risk factors and the later presence of disease. Data managers evaluate 10s of millions of clinical observations to identify and correct nonsensical or outlier data. All of this work would benefit from modern advances in data visualization. This project aims at developing an interactive, web-based data visualization tool, using Flash and/or JavaScript technologies, with functionalities similar to Google Finance stock trend visualization tool.<br>
<br>
This &quot;widget&quot; will handle mainly numeric or categorical data. Numeric results usually have associated ranges (e.g., ranges defining the bounds of &quot;normal&quot; or &quot;critical&quot; values). Categorical data have coded answers like yes/no/unknown or codes for various disease conditions. All data are timestamped.<br>
<br>
Often, patients will have dozens of data points for each parameter. Clinicians and researchers will want to understand the trends of these values and how they relate over time. The work developed shall not only provide means to present data in a readily understandable manner, but also allow users to interact with the data to meet their needs.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Clinical Data Visualization Tools</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Sashikanth Raju S Damaraju</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Paul Biondich</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My proposal is to implement a graphing widget that enables the clinicians to interact with and analyze the history of a patient. As mentioned in the project page, I intend to use Flash and Javascript to do this in the fashion of the Google Finance Widget. The following are the key points of the proposal<br>
<br>
1.The current implementation allows the user to view graphs as an image generated by the server upon choosing a particular concept. Outside the flash widget, I intend to enable to clinicians to see the list of available data on the patient, as opposed to searching for individual concepts, whether or not data exists on it. This would be by altering the popup on the graph page (that currently does a great job of allowing the clinician to search for concepts to be graphed) to first display the available data and allow the user to dynamically filter the set by typing in the text box. They will be allowed to select multiple concepts to be graphed.<br>
2.Non numeric data:<br>
To be able to visualize non-numeric data on a timeline, the widget will use an interface similar to the MIT Simile's Timeline (http://simile.mit.edu/timeline/). This would be part of the Flash part of the widget that interacts with the Sidepanel to show more details of the particular event / reading. The sidepanel will also help to solve an occlusion problem (overlapping of elements) on the graph by moving the text off the graph. To the maximum possible extent, I will try to classify different types of data to enable some 'iconification' (or coloration) of the concept categories (as dots on the timeline)for easy understanding and reading.<br>
3.Tooltips &amp; Concept descriptions<br>
Like the Google Finance widget, the readings on the graph will be displayed on the top right corner. In addition to horizontal graph lines that guide the clinician with an easy visual reading of the graph. Hovering over a graph for  slightly longer will generate a tooltip in the flash widget providing a detailed description of the concept from the dictionary.<br>
4.One of the key points of this widget is the ability to add and remove concepts to be graphed without requiring a complete page reload. An XmlHttpRequest made by the 'Add concept' button will get the required xml data from the server and update the flash widget as soon as data transfer from the server is complete. The new concept to be graphed will be added into the widget, making the widget longer in size. The graphs could be ordered based on the level of criticality of the readings in addition to allowing a simple drag and drop to re-order the graphs. A small 'x' on a graph of a concept would allow the clinician to take it off the screen.<br>
5.Timeline:<br>
Like the Google Finance widget, a flexible timeline is a very important feature of the widget. This will allow the clinician to change the time duration visible in the view port by dragging the bar that stretches and contracts the time duration in the viewport. Alternatively, I will provide buttons to view standard durations such as 1 week, 1 month, 3 months, 1 year.<br>
6.Servlet:<br>
If any of the required functionality isn't already available, I will be creating tags and servlets to send the required xml as per the query from the widget. The Xml schema to be generated by the server will be decided upon at the start of the project. I also plan to send certain preferences within the xml, such as graph color, line style, opacity and other customizable settings<br>
<br>
7.Future Contributions:<br>
1.The same widget will be more useful if it can be deployed on other platforms. A minimum functionality applet would allow it's use on Blackberries, Pda's and possibly even mobile phones.<br>
2.The same widget will be helpful in creating a tool for demographic analysis and visualization of patients region wise.<br>
<br>
Development plan.<br>
The following is the sequence in which I will tackle this project. This project is of a good size to complete within the summer.<br>
<br>
1.Data generation: decide formats for data, preference parameters<br>
2.server -javascript – flash interaction<br>
Get the skeletal structure of the data flow in place. This would require getting the servlets and tags in place for the javascript to be able to call the server.<br>
3.Plotting – one concept<br>
Generation of a single concept graph with the proper data flow. Getting live data from the server<br>
4.Criticality visualization: a red line showing lower/upper bounds of the value. A shade of red to show that patients values have been/are critical.<br>
5.Auto Scaling of the graph based on current data values.<br>
6.Display data values of current mouse position. Axes independent (meaning the values would update over all concepts on the graph, not just the concept under the mouse)<br>
7.Complete Timeline (bottom panel)Pannable graph, using either the timeline or Graph.<br>
8.Flexible time duration in the view port.<br>
9.Generation graphs for multiple concepts.<br>
10. Add / Remove concept. Simple x for remove, filter through concepts in the popup to add.<br>
11. Non numeric – unique top level axes for displaying non-numeric data.<br>
12. Side panel (Ajax-ish) – integration with flash events<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Open Data Access Adapter and RESTful Web Service Module</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Michael Rudd Zwolinski</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Justin Miranda</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 OpenMRS is a useful tool for gathering data about patients, but it needs a way to easily generate meaningful reports based on this data.  BIRT is a standalone app or Eclipse plug-in that allows a user to design reports from data sources like SQL databases or static XML files.  BIRT and other open-source reporting frameworks would be great tools to use in reporting data from an implementation of OpenMRS, but right now this is a non-trivial operation.<br>
<br>
I propose the development of a BIRT Open Data Access driver, along with a simple RESTful web service that gives reporting frameworks a way to query into the OpenMRS database without having to manually piece together OpenMRS SQL tables.  The ODA adapter and web service would allow BIRT and other frameworks to easily interact with OpenMRS's database.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Logic Service Project</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Vladimir Mitrovic</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Burke Mamlin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Medical data is extremely complex. While a dictionary-based system provides tremendous flexibility in collecting data, consuming the data for decision support, reporting, research question, or even for display within the web application can be increasingly difficult. For example, even answering a simple question like &quot;is the patient HIV positive?&quot; may require a complex algorithm that considers the results of multiple lab results, temporal relations of results, orders, and questionnaire responses. Ideally, this &quot;business logic&quot; is defined in one place and easily accessible to all aspects of the system - e.g., whether we're displaying HIV status on a web page, generating a PEPFAR (http://en.wikipedia.org/wiki/PEPFAR) report, or executing a decision support alert, the same algorithm should be used. We call this bit of business knowledge a &quot;rule.&quot; The rules should be easily accessible and return predictable and flexible results.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Patient Matching, Record Linkage, and Data Aggregation Techniques</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Sarp Centel</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Shaun Grannis</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The distributed nature of health care information among different databases creates a need for uniquely identifying patients, and combining medical information about an individual among disparate medical systems. In this project, we are going to implement patient matching and record linkage methods to OpenMRS, which is an open-source electronic medical record system targeted to developing countries.<br>
<br>
In the initial phase of the project, probabilistic linkage algorithms which have shown superior accuracy in experimental studies will be added to OpenMRS. For instance, patient matching will be performed by a flexible method called &quot;Fellegi-Sunter model of record linkage&quot;.<br>
<br>
To measure similarity among different fields, a variety of comparison techniques will be added to OpenMRS. Some well-known techniques include Longest Common Substring, Jaro-Winkler distance and Levenshtein distance for calculating edit distance, as well as phonetic algorithms such as Soundex or NYSIIS.<br>
<br>
The final phase of the project consists of fully integrating these techniques into existing OpenMRS functionalities, and creating the necessary GUI’s for end users.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Mobile Data Collection Tools</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Matthias Nüßler</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Simon Kelly</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The proper treatment of patients requires efficient data management. Even if far from a clinic, relevant data must be available or collected. Mobile devices such as PDAs, Smart Phones or even simple cell phones are sufficient for these tasks in many cases. About all of them are Java-enabled and with their ability to connect to various networks, they could be used to retrieve and display relevant information as well as to submit collected data to a remote server. Such a data management tool should be able to run on a high variety of mobile devices. The transport of data from or to the server should be possible in several ways and not depend on a certain transport method.<br>
<br>
The goal of this project will be to develop a specification for a transport layer for the transmission of data (as xforms) which is independent of the underlying transport method. Implementations for transport via HTTP, bluetooth and to save the data on a filesystem (which may reside on storage media, such a SD cards) will be provided. Furthermore, the application will be generalized to support as many devices as possible and not only high-end devices such as Smart Phones and PDAs. Success or failure on this goal will be documented by test runs on a certain number of real devices.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Drug Order Entry Tools</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Desmond Elliott</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Hamish S F Fraser</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A paper-and-pen based system for drug ordering requires the prescribing physician to write a prescription which would then be passed onto a nurse who would then pass the prescription onto a pharmacist. This was - and still is - an error-prone process. The goal of this project is to refine the current drug order entry tool in OpenMRS to increase usability and flexibility. It should be easy for the physician to select commonly used drug regimens and order sets to help minimize the interaction but it should also be possible for the physician to drill down into the details of every aspect of the drug order.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Data Warehouse and  Reporting Framework Integration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gjergji Strakosha</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Justin Miranda</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will design and implement a data warehouse built on top of the OpenMRS data model, using open source tools (like Pentaho).<br>
<br>
This will be the basis for the creation of summary reports and calculation of performance/efficiency indicators, again using open source tools.<br>
<br>
Finally, I will integrate the above in the OpenMRS system.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>XML-based data exchange with the DHIS software – expanding the use of OpenMRS data</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Anders Bjarne Skjelten Gjendem</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Maros Cunderlik</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Develop data exchange routines between the patient-based OpenMRS and<br>
the DHIS, which is open source health management software using<br>
aggregated data. This will expand the usage of OpenMRS data and offer<br>
low income countries a more comprehensive and compatible suite of open<br>
source health care applications.<br>

	</div>
 </td>
 </tr>
</table>
<a name='opensolaris' />
<h2> opensolaris </h2>
<table>
 <tr>
 <th>Title</th>
 <td>i18n Emancipation Project</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>John Sonnenschein</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Garrett D&#39;Amore</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Re-implement the internationalization functions of libc ( libc_i18n.a ), which are currently legally encumbered binary blobs in order to allow a bootable open source only OpenSolaris system<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Porting Fast Fourier Transform Tools</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Raymond T Harper</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Rob Giltrap</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Various tools (MPrime, MLucas, GLucas) are used by the Great Internet<br>
Mersenne Prime Search (GIMPS) to search for Mersenne Prime Numbers<br>
using Fast Fourier Transforms.  They have also proven to be very useful in stress testing systems because of their computational intensity.  I propose porting these to OpenSolaris and optimising them for the various platforms upon which Solaris runs, especially SPARC and EMT64 (x86-64).  Additionally, I would write a GUI application for controlling, monitoring, and benchmarking the performance of these tools using GTK.  This tool would be useful both to those contributing to the Prime Number search and to those that need performance benchmarks from stress testing.  Finally, another addition to the original tools would be a module that can be used for communicating with the PrimeNet servers (those servers used for coordinating the Mersenne Prime Search) that can both be used in conjunction with the tools mentioned or easily modified to work with any others.<br>

	</div>
 </td>
 </tr>
</table>
<a name='osaf' />
<h2> osaf </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Progress Reports Management</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Vera Sheinman</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jeffrey Harris</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In the places we work, in the places we research and for our personal management, we need to follow and to report upon our progress once in a while (weekly, for instance). Usually, there are three main components to this: our goals, the completion state for each goal, and the progress from the previous report time. Although these needs are similar, we maintain plethora of (mainly manual) formats to write these reports for various purposes, spending our time, doing it inefficiently, getting confused by managing tasks from unrelated areas (plan a romantic dinner and write an abstract for GSoC 2007) with no possibility to generate high-quality automatic analysis of the data and separate, or combine the various tasks into one view when needed.<br>
Chandler is a PMI system, and it could provide a generic solution for tackling this issue.<br>
In this proposal a prototype system for convenient progress info management and combination over various areas of activity is suggested.<br>
I suggest the capability of tagging each task and its priorities (similar to GTD principles), but also the flexibility to use a single system for producing various reports in accordance to various prioritization systems. We may fill the report once, sending to the boss only the things that are relevant for the company, and judged according to the company's priorities, while providing ourselves with a wider view that includes our personal priorities. This way we may clearly see, when our priorities do not meet the company's policies, what percentage of time we dedicate to work etc.<br>
The main advantage will be that we won't have to maintain different lists in different systems, we will just tag each task, and create an appropriate progress report when needed.<br>
Certain elements of NLU may be needed to aggregate tasks by keywords, or to identify important dates, such as deadlines in the reports. These features will be left for future development.<br>

	</div>
 </td>
 </tr>
</table>
<a name='oscar' />
<h2> oscar </h2>
<table>
 <tr>
 <th>Title</th>
 <td>OSCAR LVS and HA Integration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ma Yuan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Edwards</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Open Source Cluster Application Resources (OSCAR) toolkit allows easy and flexible installation and maintenance of high performance computing (HPC) clusters. Often, large clusters needs Load Balance for web access and HA for the high availability of Critical Application. This project will Integrate IPVS(a Linux Virtual Server implementation) for web Load Balance and Linux-HA for High availability in OSCAR.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Globus/Condor Package for OSCAR</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>AMIT VYAS</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>DongInn Kim</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Grid Computing            -- Globus<br>
Cluster                   -- OSCAR<br>
High Throughput Computing -- Condor<br>
<br>
Clusters,Grid and high throughput computing projects(condor) are projects that help setting up computing infrastructures which are of importance. Clusters ,Beowulf, used to be isolated from other emerging technologies like Grid because of many reasons importantly ease of deployment and seamless integration.<br>
<br>
Grid software like globus have inherent  support for clusters and can be used easily with same grid interface. Today many deployments specially in University there exists mixed environments.<br>
<br>
Globus/Condor package will provide easy installation and configuration of those two software of top of clusters resources.<br>

	</div>
 </td>
 </tr>
</table>
<a name='osgeo' />
<h2> osgeo </h2>
<table>
 <tr>
 <th>Title</th>
 <td>GRASS Modules for line generalization and smoothing</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Daniel Bundala</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Wolf Björn Mikael Bergenheim</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The aim of this project is to implement a new line generalization and smoothing module to the GRASS system. All algorithms and methods proposed in this project work with a vector representation of lines. Line generalization is a process of transforming complex lines to the simpler lines. In the case of vector graphics this usually means the reduction of the number of points representing the line. The outcome of this process is always another line, which approximates the original line but has significantly less vertices. The advantage of this is that the new line is much easier to render and occupies less memory. For example, suppose that you have a very detailed map of a certain area and borders, rivers, roads… are stored as the vector lines. Then full resolution is impractical for global applications, but using line generalization we can efficiently produce maps of an entire area with smaller requirements to the system.<br>
<br>
The next logical step is line smoothing which, in general, is a process of transforming ugly zig-zag lines to the nice, natural looking smooth lines. This process can be applied to the lines after being generalized or even to the lines we want to look more realistic. Some of the line smoothing algorithms do not add any new vertices to the line. Hence, line generalization and smoothing is an ideal combination to reduce the complexity of maps without significant reduction of details.<br>
<br>
Since there exist many algorithms, heuristics can be developed to select the appropriate one and to choose appropriate input parameters to obtain better results.<br>
<br>
The original proposal is available here: http://grass.gdf-hannover.de/wiki/GRASS_SoC_Ideas#A_new_module_which_would_do_line_generalization_with_one_of_these_algorithms<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GDAL2Tiles - Utility for easy tile-based publishing of raster maps and KML SuperOverlay</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Petr Přidal</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Howard Butler</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Main issue of this project is to allow easy publishing of raster maps on the Internet. Your raster file (like TIFF/GeoTIFF, MrSID, ECW, JPEG2000, JPEG, PNG) is converted into a directory structure of small PNG tiles (TMS compatible), which you can just copy to the webserver. Simple webpages with viewers based on Google Maps and OpenLayers are generated as well - so anybody can comfortably explore your maps on-line and you do not need to install or configure any special software (like mapserver) and the map displays very fast in the webbrowser.<br>
<br>
GDAL2Tiles generates also necessary metadata for Google Earth (KML SuperOverlay), in case the supplied map uses EPSG:4326 projection. Usage of gdalwarp utility is recommended for converting a raster maps with another projection.<br>
<br>
World files and embeded georeference is used during tile and KML generation, but you can publish a picture without proper georeference too.<br>
<br>
Tile structure follows recommendation from OSGeo Tile Map Service Specification (http://wiki.osgeo.org/index.php/Tile_Map_Service_Specification).<br>
<br>
Now, generated tiles supports only local-profile from TMS, so they can not be used as overlay on top of Google Maps yet, this feature is on the TODO list.<br>
<br>
Original idea of this project was to implement a Raster Driver for GDAL with the same functionality, but for the purpose of SoC project stable utility was preferred in the end. Utility prototypes the future raster driver.<br>
<br>
Manual page for utility is part of the solution, as well as a document describing several existing tile structures with links to further documentation. Analyse of rotated SuperOverlay KML is done as well.<br>
<br>
For more info look at the project page:<br>
<br>
http://www.klokan.cz/projects/gdal2tiles/<br>
<br>
Utility gdal2tiles.py was accepted by GDAL community (trac ticket #1763). It is directly usable with existing stable versions of tools (GDAL, FWTools) and it is going to be distributed as part of GDAL tools.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Plugins for multidimensional raster data sources.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Daniele Romagnoli</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Simone Giannecchini</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 As part of the Google Summer of Code initiative I would like to propose myself for working with Open Source Geospatial Foundation on one of the ideas mentioned on the GeoTools project page (http://docs.codehaus.org/display/GEOTOOLS/Google+Summer+of+Code).<br>
<br>
I would like to develop a set of Java Image I/O plugins capable to provide a starting point for building GeoTools plugins to manage multidimensional data formats such as NetCDF, HDF, GRIB1. Of course, the limited amount of time available will force us to choose only a few of them.<br>
During this work, I would also like to study, design and, if time allows it, implement under the guide of an experienced Mentor a new framework for GridCoverages I/O (especially, N-dimensional GridCoverage), since actual GeoApi interfaces for GCE (OGC compliant) are deprecated and no multidimensional data management is actually developed.<br>
<br>
Last year, I participated to the Google Summer Of Code, to build a framework which provided an encapsulation of the GDAL library behind Image I/O plugins. This allows GeoTools developer to access many more coverage formats by simply extending and implementing the proposed framework and wrapping them inside GeoTools grid coverage plugins.<br>
&nbsp;<br>
As you know for sure, GDAL is a powerful Open Source library for reading/writing/processing raster data. In the proposal of this year I would like to use directly the available java libraries to handle these formats without relying on GDAL.<br>
<br>
Let me provide a brief summary of the most widely known multidimensional formats and libraries available in java.<br>
<br>
- HDF (Hierarchical Data Format) is a library and a multi-object file format created and developed by NCSA (http://www.ncsa.uiuc.edu/).<br>
<br>
- NetCDF. Quoting from (http://www.unidata.ucar.edu/software/netcdf/), &quot;NetCDF (network Common Data Form) is a set of software libraries and machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.&quot;<br>
<br>
- GRIB1 is a data format standardized by the World Meteorological Organization’s Commission (http://www.wmo.ch/)  for Basic Systems, which is commonly used in meteorology to store historical and forecasted weather data.<br>
<br>
My primary objective will be building at least a plugin for one of the introduced formats (or one profile of them). If the amount of time/work needed to achieve this task does not keep busy all the Summer Of Code slot, it would be great to develop more than a single plugin.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Caching data in uDig</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christophe ROUSSON</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ian Turton</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 UDig is a promising platform for building fully-integrated GIS applications.<br>
<br>
Among other very relevant ideas listed on the OSGeo page, some enhancements like caching the data and the ability to support intermittent network connections and limited bandwidth would be great, as these are still serious limitations when designing apps for the operational world, as we would like to do for forest management.<br>
<br>
Starting on a PhD on collaborative GIS tools, I lean towards using open source technologies and already explored JTS, Geotools and uDig APIs, and though not from a computer-science background, I feel at ease whith the platform capabilities while I think I will get much excitement in getting active involvement in the project.<br>
<br>
So I may be your man for a project which will deal with :<br>
<br>
&nbsp;&nbsp;&nbsp;* setting up multisource DataStores with the ability to choose the best available source from the list<br>
&nbsp;&nbsp;&nbsp;* implementing caches, using RAM or disk cache<br>
&nbsp;&nbsp;&nbsp;* handling asynchronously local edits so they can be committed when possible<br>
<br>
Please follow my link to get the full details of my proposal.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>JTileCache</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Christopher Whitney</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Justin Deoliveira</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Using GeoServer to serve geographic image tiles directly to a web client (such as OpenLayers) requires substantial computational effort on the server side.  Yet, the redundant and largely static nature of the problem makes it an ideal candidate for a cache.  Existing naive HTTP caches are often employed, but are not well tailored to the specific needs of WMS image tile requests.  One existing WMS-C (Web Mapping Service Caching server) exists: MetaCarta's TileCache.  TileCache provides a significant performance improvement for serving map tiles.  However, TileCache is typically run using mod_python, an environment that requires much considerable setup in addition to a J2EE deployment of GeoServer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In response to these needs, JTileCache will implement a WMS-C server modeled after TileCache, but written in pure Java.  JTileCache will be deployed as standalone web application, allowing it to cache local or remote GeoServer instances.  By relying on existing distributed cache frameworks, JTileCache would ease the deployment of multiple caching servers (useful to increase the number of concurrent browser connections), and allow the cache to exist in local memory, on disk, in a database, or distributed across the network.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GDAL: KML read support for the existing driver</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jens Oberender</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mateusz Loskot</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 KML is the data format for vector data use in Google Earth and Google Map. One can create his own file of interesting spots on his homepage or provide a KML file with places visited during last holiday.<br>
<br>
KML is similar to GML (Geographical markup language) specified by the OGC (Open Geospatial Consortium). Both describe geographical objects like points, vectors and polygones in an XML-structure.<br>
<br>
With the already existing KML write capability GDAL can produce files suitable for displaying in Google Earth. But it lacks support for reading KML files.<br>
<br>
With that feature it would be posible to add support for KML read to a lot of open source GIS software that is based on GDAL, like for example QGIS or the UMN MapServer.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Coverage model and operations for PostGIS</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Xing Lin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Timothy H. Keitt</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Geographical Information System (GIS) is playing a more and more important role in the world nowadays. As the central part of GIS, spatial database (SDB) techniques bring great benefit to GIS in the aspect of data storage, query and analysis. From Google Map/Local Search to Yahoo! Map, from handheld GPS device to location based service, there are already a great many of successful stories of how GIS is serving us in the everyday life. Luckily, we have many SDBs available to use today both in commercial and open source community. ESRI SDE and Oracle Spatial are two most popular products. On the other hand, among the open source family, PostGIS, which is a spatial extension to world's most advanced Open Source database PostgreSQL, is the most outstanding one. Spatial database has greatly improved the management of geographic data, including vector data (line, polygon, etc.) and raster data (like image).<br>
Unfortunately, most open source spatial databases only support vector data by following the OGC Simple Feature Specification for SQL. In fact, there is a great need for them to support the management of raster data model (in OGC terms, it is named Coverage). Among commercial solution to raster model in spatial database, a industrial standard for raster data model implementation in spatial database is badly required to improve the interoperability among different platforms. I believe my work will definitely benefit the open source community as well the GIS world with the enhanced spatial database of PostGIS.<br>
The work of my project will include a raster data model and its storage in PostGIS. Some import and export tools will also be developed to communicate the raster database with outside systems, such as popular image format.<br>
I have been using PostGIS and some other open source GIS products for one or two years. And I also have experiences in extending PostgreSQL on Windows (MinGW) or Linux platform (GCC+Vim). I think I could manage the task alone or together with some other people.<br>
(<br>
You can find my paper about this problem from the following link:<br>
http://rapidshare.com/files/22466517/GSQL-R_A_Query_language_supporting_raster_data.pdf.html<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or<br>
http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1370128)<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GeoServer Style Editor</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Anthony Manfredi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tim Schaub</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to design and implement a SLD style editor for GeoServer to make it easy for users (particularly those with minimal technical knowledge) to customize the appearance of GeoServer content. The design of the editing interface is critically important, and will focus on ease of use and flexibility.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>3D Rendering Pipeline for GeoTools</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hans Häggström</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jody Garnett</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The 3D Geo Renderer will provide a three dimensional view of GeoTools geographical data.<br>
<br>
The biggest challenge will be implementing a level of detail based loading and caching system for the geographical data.  In addition, the work will include a modular system of renderers for different geographical primitives such as lines and polygons.  Different 2D data fields should also be possible to visualize, e.g. by coloring the ground.<br>
<br>
Update: The wiki for the project is at: http://docs.codehaus.org/display/GEOTOOLS/3D+Rendering+Pipeline+for+GeoTools<br>

	</div>
 </td>
 </tr>
</table>
<a name='osuosl' />
<h2> osuosl </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Drupal/Google API Integration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Silas Snider</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Justin Gallardo</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My project (if accepted) would be to implement an integration component for Drupal. Since this is a large project, I would be most interested in attacking the SSO and provisioning component.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Help with OLPC project</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Darko Ilic</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Bradley William Morgan</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I myself come from the country far less developed then the western world, so I understand how hard it is to put things right in society with low level of education. World wide network has changed the way people of developed countries live, but for the kids in poor countries, it makes no difference, they are still in the dark. OLPC project has a chance to make a difference, to turn the light on. I strongly believe in the idea and I would really like to contribute.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Drupal / Google API Integration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Robert H Wohleb III</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Gregory A. Lund-Chaix</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Synopsis<br>
<br>
I will develop a base Google Apps API module for Drupal. This module will contain the core functionality to integrate with the Google Apps API. Further modules will be developed on top of this module to tie specific Drupal functionality into the Google Apps API.<br>
Project<br>
<br>
This project will center around 4 tasks. The first task will be to implement the base Google Apps API module. This module will not provide any user functionality, but will provide a centralized means to interact with the API. This design approach will keeps things clean while providing a platform for other developers.<br>
<br>
The second task will be to implement a provisioning module. This module will use the base API module and tie the creation of Google Apps accounts to Drupal account creation. The provisioning module can be configured to create a GMail account for new users to satisfy Drupal's email address requirement for new accounts. The provisioning module should also be allowed to pull user information from the Google Apps API and create Drupal accounts. This will allow scenarios where Google Apps account creation is driven directly by LDAP.<br>
<br>
The third task will be to implement a module to sync a user's Google Calendar to their Drupal calendar. User's will be able to add events in Drupal and see them in their Google Calendar. The opposite will also be true. This module should keep events as nodes to keep compatibility with existing Drupal calendaring modules.<br>
Benefits<br>
<br>
Google Apps provides a page creation tool. However, it only provides static content and is only available to the administrator. Linking Drupal to Google Apps will allow for a customizable CMS that is tightly coupled to other domains operations.<br>
Success<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Create the modules described above. The base API module should expose the full Google Apps API while hiding the difficult stuff.<br>
&nbsp;&nbsp;&nbsp;&nbsp;* The provisioning and calendaring modules should work with existing Drupal modules and methodology. It should ideally be transparent.<br>
<br>
Roadmap<br>
<br>
&nbsp;&nbsp;&nbsp;1. Publish design goals to Drupal developer list. Feedback will be extremely important to the implementation of the provisioning and calendaring modules. (until mid-june)<br>
&nbsp;&nbsp;&nbsp;2. Implement features in order specified above. Base API and provisioning modules are essential. The calendaring module will require more work to guarantee compatibility with other modules (until early august)<br>
&nbsp;&nbsp;&nbsp;3. Testing of features and debugging. (until end of SoC)<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Firefox kiosk extension</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Seth Lemons</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Eric Searcy</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project will center around developing a kiosk extension to allow Firefox to be used for online testing. The product would prevent the user from accessing sites other than the one designated by the administrator and from accessing other applications on the system. Normal browsing capabilities will be strictly limited by default and further restrictions will be possible through administrative settings (limiting access to a particular domain or list of sites, for example.) Normal system key combinations will be intercepted by the browser, thus denying the user access to other applications or settings.<br>

	</div>
 </td>
 </tr>
</table>
<a name='osvdb' />
<h2> osvdb </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Researcher Confidence Project</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Timothy F. Tutt Jr.</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brian Martin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Open Source Vulenrability Database (OSVDB) is and open source database created by and for the security community. The primary goal of the OSVDB is to provide accurate, detailed, current, and unbiased technical information on security vulnerabilities. The greatest benefit to this project is also its greatest downfall; open collaboration. Like Wikipedia anyone can add information or report vulnerabilities in a system. With so much collaboration going on it is hard to tell which researchers reporting these vulnerabilities are actually a reliable source.<br>
<br>
The purpose of the Researcher Confidence Project is to create a system for the OSVDB API which enables the tracking of researchers’ reliabilities. The project would determine the level of confidence that a particular researcher has and leave it displayed when this person reports vulnerabilities. This would give the viewers of these vulnerabilities a basis to decide whether or not to trust the validity of the posted vulnerability. A researcher’s confidence would be determined by their number of reported vulnerabilities and the number of which have proven to be accurate.<br>
<br>
As with all open collaboration projects, the best ways to identify potential problems are to allow vendors or collaborators to dispute particular vulnerabilities in OSVDB. A system will be developed which would allow vendors to comment on why a particular vulnerability is incorrect and it will also flag the vulnerability so it can later be checked and re-validated.<br>
<br>
This project will make use of the PHP programming language, the MVC design pattern, object-oriented programming and the OSVDB API in order to be successful.<br>

	</div>
 </td>
 </tr>
</table>
<a name='p9' />
<h2> p9 </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Improving Inferno SPKI Authentication</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Katie Reynolds</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Charles Forsyth</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project will add support for the Inferno authentication protocol to the Plan 9 and p9p operating systems. I will also improve the SPKI<br>
infrastructure in Inferno by implementing new components for this. These include a verification service for SPKI and a file server which stores SPKI certificates securely together with commands which interact with this. The project also includes adding support for authentication files to Inferno.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>A simple venti, vac and vac with manber/rabin fingerprinting block splitting (or a fossil) in limbo.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mechiel Lukkien</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Charles Forsyth</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project concentrates on first implementing a vac and a simple venti system in limbo.  Second, the vac program would be improved to use manber fingerprinting to split blocks, instead of using fixed size blocks as the vac from Plan 9 does.  This would lower data storage consumption by reducing duplicate data stored because inserting a byte somewhere in the middle of the file would only change a few blocks, not all subsequent blocks.  Alternatively, a fossil for limbo could be implemented, but that would be a more ambitious project (and note that the manber fingerprinting is not immediately applicable to a fossil system).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Porting Plan9 to OLPC laptop</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ameya Palande</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Uriel Mangado</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 OLPC (one laptop per child) is an innovative machine.<br>
This project is about Porting Plan9 operating system to OLPC laptop.<br>
<br>
OLPC uses OpenFiware instead of PC BIOS.<br>
Plan9 itself doesn't make use of BIOS calls but its boot loader uses BIOS calls. So we can't use Plan9 boot loader on OLPC.<br>
My project is to write a boot loader which can use open firmware<br>
client services to load Plan9 kernel. Also I need to write Plan9 device driver for display and USB thumb drive or NAND flash.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Alternative Implementations of 9P: PHP and JavaScript</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Anant Narayanan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Maht Lawless</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I quote from the 9P website:<br>
<br>
'9P is a network protocol developed at the Bell Labs for the<br>
Plan 9 from Bell Labs distributed operating system as the means<br>
of accessing and manipulating resources and applications<br>
transparently in a distributed environment'<br>
<br>
9P is a next-generation distributed file system that has several<br>
interesting use-cases, which is why it has been ported to several<br>
other Unix variants (plan9port) and also has been implemented in<br>
a variety of languages like Java, Python, Ruby, Lisp, TCL and<br>
even OCaml. I have noted, however, that there is no PHP<br>
implementation for 9P, and therefore propose a Summer of Code<br>
project for doing the same. In addition, a client for the 9P<br>
protocol in JavaScript will also be developed. At the end of the<br>
project, any 9P file system will be able to 'expose' itself over<br>
the web for the JS client to access, and PHP programmers will be<br>
able to access the 9P API in their PHP programs.<br>

	</div>
 </td>
 </tr>
</table>
<a name='pano' />
<h2> pano </h2>
<table>
 <tr>
 <th>Title</th>
 <td>New extensible modular GUI framework for Panorama Photography</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ippei UKAI</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Yuval Levy</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I have been involved in the hugin project for over two years now, and am currently maintaining the Mac OS X port and Japanese localisation. The tool is very powerful, and I have enjoyed making panorama photos with it very much.<br>
<br>
Some first time users complained hugin as it is today is not intuitive enough for simply stitching their photos, and indeed the concept of some of available features are so complicated that I have never known until last week for over two years.<br>
<br>
Since PanoTools is such a powerful toolkit, and the community is coming up with yet more powerful new features every month, I would like to move the entire community further forward by constructing highly extensible new GUI application, that easily accommodate new features and yet simple and intuitive for users from different levels of backgrounds so it also opens the door for more potential users.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Anti-ghosting HDR panorama blending and merging algorithm</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jing Jin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Pablo d&#39;Angelo</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 High Dynamic Range (HDR) Panoramas are formed by taking numerous pictures of different exposures, tone mapping them to an exposure that provides the most detail for the human eye, and stitching them into a single image. Since there are multiple base images per area in HDR imags, moving objects, such as people, result in semi-transparency, blurring, or incomplete objects. This phenomenon is called ghosting. Some commercial products support ghosting elimination, but most of them only work with small variations in the camera. The goal of this project is to devise a robust blending algorithm to eliminate ghosting in an HDR panorama.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Interactive Panoramic Viewer</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Leon Armando Moctezuma de Uriarte</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Aldo Hoeben</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Freepv is a part of the PanoTools Software Universe and it is an effort to make a universal viewer for the different VR file formats. Thus this project intends to add new features like basic support to some files and enhance the user interactive experience. Since Freepv is at an early stage of development other objectives are to get a stable OpenGL renderer and restructure some components to have a more intuitive extendible architecture.<br>

	</div>
 </td>
 </tr>
</table>
<a name='parsec' />
<h2> parsec </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Reach for the Stars clone</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Tyler Shaub</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Charles Lee Begg</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A Reach for the Stars clone, implemented as a Thousand Parsec ruleset.<br>
<br>
Currently, Thousand Parsec has only a couple playable test implementations. I propose to implement a complete game- a Reach For The Stars clone, by creating a TP ruleset. I will use the current protocol and client, expanding them where applicable. Also I will write a tutorial explaining how to create a ruleset, using the knowledge I've gained from implementing mine. Given time, I would also like to implement AI comparable to the original's.<br>
<br>
Implementing this new ruleset will benefit the project by showing how it can be easily used to implement a common and classic game (while assuring that it can!). Ideally, this will bring more attention to the project, and show off it's greatness!<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Ruleset Development Environment</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>James Gardner</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brett Nash</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 One of the major shortcomings of Thousand Parsecs as it stands is a lack of gametypes. The great strength of the project is its flexibility and the potential to add even greater flexibility as time progresses. To gain attention and interest, however, something substantial needs to be in place to draw people into the community. A well designed gametype, or even better, a diversity of gametypes, would greatly increase the appeal.<br>
<br>
To further that end this project proposes a development environment for rulesets, specifically focusing on Properties, Components and Designs in the initial implementation, but with the expectation that it can and will be extended to cover more of the development domain. The program will initially provide an interface to create, organize and link Components, Properties and Components with the ability to later export the objects into a server-usable form (a C++ class, for example).<br>

	</div>
 </td>
 </tr>
</table>
<a name='php' />
<h2> php </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Livedocs: The promised land</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hannes Magnusson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Wallner</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Livedocs introduction:<br>
&quot;Livedocs is a tool to display DocBook XML files in a web browser on the fly, without the need of building all HTML target files first. It was started as a project to simplify the task of PHP Manual contributors, to check their changes as they will show up in the documentation. To use Livedocs, a little preprocessing work is needed, but after that, the script collection even works on modified XML files.<br>
<br>
The main advantage of Livedocs for the PHP Manual is the dramatically reduced time-to-live interval, since modified XML files can be pushed to servers without the need of building all the HTML files even for small changes.<br>
Additionaly to this, Livedocs also does a good job of providing search<br>
results for keywords found in the manual, as well as keeping track of<br>
relations of translated files to their English equivalents, notifying<br>
readers, if they read a seriously outdated translation.&quot;<br>
(http://cvs.php.net/viewvc.cgi/livedocs/README?revision=1.17)<br>
<br>
Livedocs is said to be the solution to all our (php.net) documentation problems and I intend to keep that promise by any means necessary.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Cycle Collection in PHP</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Yiduo Wang</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Fredericus G Rethans</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The PHP interpreter currently uses a simple reference counting mechanism to keep track of variables in memory, freeing them when the number of references to them reaches zero. Although this system is simple and effective, its major weakness is its inability to handle cycles of objects referencing each other.<br>
<br>
Implementing an optional cycle collector similar to one described by Bacon and Rajan in &quot;Concurrent Cycle Collection in Reference Counted Systems&quot; into the PHP interpreter will address this weakness and is the goal of this project.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Debugger Frontend for Xdebug</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Adam Harvey</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Fredericus G Rethans</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Xdebug [1] provides a range of useful functionality for PHP developers, including detailed error information, code coverage and profiling support, and support for remote debugging using the GDB or DBGp protocols. At present, there are several DBGp implementations available as part of larger IDEs [2], however there is currently no standalone GUI application that can be run to debug applications using DBGp without tying the developer to a particular IDE.<br>
<br>
Under this proposal, a cross-platform GUI application will be developed that implements the DBGp protocol to allow PHP applications to be debugged using Xdebug in a development environment agnostic fashion. This application could then be further developed to include support for other run-time environments that support the DBGp protocol, which includes Python with Komodo [3] and may also include Ruby in the future [4].<br>
<br>
[1] http://xdebug.org/<br>
[2] http://xdebug.org/docs-debugger.php#clients<br>
[3] http://aspn.activestate.com/ASPN/docs/Komodo/4.0/komodo-doc-debugpython.html<br>
[4] http://dev.eclipse.org/mhonarc/lists/dltk-dev/msg00001.html<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Foreign Keys: another improvement to PEAR::MDB2_Schema</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Igor Feghali</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Helgi Þormar Þorbjörnsson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 PEAR::MDB2_Schema enables users to maintain RDBMS independant schema files<br>
&nbsp;&nbsp;&nbsp;&nbsp;in XML that can be used to create, alter and drop database entities (also<br>
&nbsp;&nbsp;&nbsp;&nbsp;called as DDL: Data Definition Language). Reverse engineering database<br>
&nbsp;&nbsp;&nbsp;&nbsp;schemas from existing databases is also supported.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;MDB2_Schema version 0.7.0, which was supported by a Google SoC 2006 project,<br>
&nbsp;&nbsp;&nbsp;&nbsp;introduced a new XML syntax to handle data manipulation. The ability to<br>
&nbsp;&nbsp;&nbsp;&nbsp;insert data into a database was improved, plus it is now possible to update<br>
&nbsp;&nbsp;&nbsp;&nbsp;and delete records (also called as DML: Data Manipulation Language).<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;It is now time to take MDB2_Schema one step higher: Foreign Keys support,<br>
&nbsp;&nbsp;&nbsp;&nbsp;which has been a feature frequently requested by PEAR users. The required<br>
&nbsp;&nbsp;&nbsp;&nbsp;XML additions has already been defined in conjunction with David Morse,<br>
&nbsp;&nbsp;&nbsp;&nbsp;a PEAR::DB_Table developer. The main goal is to keep compatibility between<br>
&nbsp;&nbsp;&nbsp;&nbsp;both classes. Methods to read and write MDB2 XML files with the XML syntax<br>
&nbsp;&nbsp;&nbsp;&nbsp;for foreign keys described below were recently added to the PEAR::DB_Table<br>
&nbsp;&nbsp;&nbsp;&nbsp;package.<br>
<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;XML definition:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;foreign&gt;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;constraint_name&lt;/name&gt;?<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;field&gt;field_name&lt;/field&gt;+<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;references&gt;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;table&gt;referenced_table_name&lt;/table&gt;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;field&gt;referenced_field_id&lt;/field&gt;*<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/references&gt;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;match&gt;full|partial|simple&lt;/match&gt;?<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;ondelete&gt;cascade|setnull|setdefault|restrict|noaction&lt;/ondelete&gt;?<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;onupdate&gt;cascade|setnull|setdefault|restrict|noaction&lt;/onupdate&gt;?<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/foreign&gt;<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Where the symbols denote:<br>
&nbsp;&nbsp;&nbsp;&nbsp;? : optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;+ : at least one instance<br>
&nbsp;&nbsp;&nbsp;&nbsp;* : zero or more instances<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;The referenced key is optional. If it is absent, it is assumed that the<br>
&nbsp;&nbsp;&nbsp;&nbsp;referenced key is the primary key of referenced table. The number and types<br>
&nbsp;&nbsp;&nbsp;&nbsp;of fields in the referenced key must match those of the foreign key.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Before the FK implementation however, I would like to get MDB2_Schema ready<br>
&nbsp;&nbsp;&nbsp;&nbsp;to be released as a stable package. Some test units are lacking<br>
&nbsp;&nbsp;&nbsp;&nbsp;(comparedefinitions(), initializetable() and parsed definitions) and there<br>
&nbsp;&nbsp;&nbsp;&nbsp;is no end user documentation yet, that is, documentation on how to use the<br>
&nbsp;&nbsp;&nbsp;&nbsp;API.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;MDB2 Home:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;http://pear.php.net/package/MDB2/<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;MDB2_Schema Home:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;http://pear.php.net/package/MDB2_Schema/<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Detailed Proposal:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;http://www.novadevel.com/m/ifeghali/soc/2007/proposal/<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Project Demonstration:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;http://www.novadevel.com/m/ifeghali/soc/2007/<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Project Download as it was at the Deadline time:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;http://google-summer-of-code-2007-php.googlecode.com/files/Igor_Feghali.tar.gz<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Refactory of Jaws internals</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nicolas Bérard-Nault</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David Coallier</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 It is not a secret to anybody that big applications are the motor of the development of languages. In fact, with them, we can test the limits of the language, detect bugs and suggest ameliorations. This also applies to PHP and is even more important in a period of intense development like the one PHP is living right now.<br>
<br>
Jaws, an incredibly powerful content management system written in PHP, is a good example of such an application. To keep its pertinence as a driving force of the PHP community, Jaws has to maintain a level of currentness with the fast-evolving PHP language. This is why it is intended in this Google Summer of Code project to revamp the internals of Jaws and migrate it from PHP 4 to PHP 6. This includes, but is not limited to, E_STRICT compliance, the systematic use of real object programming, Unicode character support, the transparent use of different database types and the use of the most current features available in PECL and PEAR, including if needed operator overload and the Standard PHP Library (SPL). This will not only improve the user experience but will also serve as a testing platform for the newest branch of the PHP project, promising the discovery of new bugs, the elaboration of new feature requests and the improvement of documentation. Overall, both the Jaws community and the PHP community will profit from this ambitious project to redesign the internals of Jaws with the most current available features of the PHP language.<br>
<br>
This project will contain three phases. The first one is the planning of the new internals, based on the current code base. This will be done in concordance with all the current developers of the project and my mentors and will last about two weeks. The second and longest phase is the actual development of the new internals, which will last eight weeks, during which contributions to the code base will be on a daily basis. The third phase is the testing phase, where the new code base is implemented in a real-life environment and extensively tested. Feedback will also be sent to the PHP-internals list for developers to see how well PHP6 performs in such a big endeavour.<br>

	</div>
 </td>
 </tr>
</table>
<a name='planetmath' />
<h2> planetmath </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Towards Estimating Authority of Users in PlanetMath.org</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Pawel Jurczyk</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Aaron Krowne</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Popularity of portals where users generate contents is constantly growing. However, despite the increased popularity, the quality of contents is uneven, and while some users usually provide good content, many others often provide bad answers. Hence, estimating the authority, or the expected quality of users, is a crucial task for this emerging domain, with potential applications to answer ranking and to incentive mechanism design.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Modularizing the Classification and Document Handling of NNexus</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>James Johnson Gardner</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Aaron Krowne</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Knowlege bases can be viewed as semantic network. For a user to learn about a particular topic in most cases requires reading other related articles. The PlanetMath.org auto-linking system, NNexus, tries to help users find related information. The auto-linking system performs the task of linking articles so that authors will not have to search to find related articles and manually link to them. The NNexus system is a one of kind process for a dynamic corpus. I propose to abstractify the handling of classification schemes to facilitate better link steering between documents in multiple corpora and modularize the document handling component of NNexus to allow for linking document types other<br>
than LaTeX.<br>

	</div>
 </td>
 </tr>
</table>
<a name='plone' />
<h2> plone </h2>
<table>
 <tr>
 <th>Title</th>
 <td>New transformation and indexing infrastructure for Plone</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hanno Schlichting</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Martin Aspeli</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Plone as a CMS provides functionality around managing content. Content can occur in many different variations but one kind that is frequently encountered is existing or external content stored as files. In order to manage those efficiently Plone needs to support indexing and searching such content as well as providing it in different forms. All this functionality is based on transformation of content from one form into a different one. Examples of these transformations include extracting text from PDF files to make their content searchable, extracting metadata information from media files to provide RSS news feeds and generating previews of OpenOffice documents.<br>
<br>
While Plone currently has support for some of these requirements in the core application and some through add-on products, there is a need for a centralized and easily configurable intermediate level which would allow to plug in new transforms and reuse existing ones in different contexts.<br>
<br>
The aim of this project is to design and code this new intermediate architecture and reimplement the already existing functionality to use this new architecture.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improved out-of-the-box WebDAV experience</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Sidnei da Silva</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Alexander Limi</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Plone has an incredible out-of-the box experience when used through a browser. It used to be like that too when used through WebDAV and FTP, but these days those are treated like second-class citizens in the Plone story. This proposal aims to bring Plone's WebDAV story up to speed with the latest improvements. Most of the needed pieces are already available, but Plone needs to be configured with sensible defaults.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>LinguaPlone</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ramon Navarro Bosch</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Martijn Pieters</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Plone has multilingue support with LinguaPlone product. This product is not migrated to use zope 3 technologies on Plone 3/3.5 and it does not provide the aproach of w3c on multiple language portals. The idea is to enable this feature as w3c specify using adapters.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>OpenDocument import, indexing, preview</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Joscha Krutzki</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lennart Regebro</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Plone lacks on OpenDocument support. I will make a portaltransform to import Opendocument files with images, indexing and preview according to  PLIP #155: Transformation and indexing.<br>
<br>
Benefits:<br>
<br>
Better integration with Office software.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Genesis: Next Generation of ArchGenXML</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Viðar Svansson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Reinout van Rees</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Genesis is the successor of ArchGenXML (AGX), a Zope/Plone code generator. It inputs models of web applications, such as UML diagrams, and outputs applications ready to be deployed on an application server.<br>
<br>
One of the aim of Genesis is to move the generated code to the Zope 3 Component Architecture. This means an overhaul of the AGX profile, use Zope libraries to perform the “heavy lifting” currently provided with the Archetypes framework. We will endorse convention over configuration and sensible default values with the Grok framework were possible.<br>
<br>
Genesis provides an excellent opportunity to utilise cutting edge code generation and modeling techniques, which can easily be extended for further research studies. It as well be relatively easy to generate code for other platforms from the models. However, this requires some abstraction of the metamodel.<br>

	</div>
 </td>
 </tr>
</table>
<a name='postgres' />
<h2> postgres </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Column-level privilege implementation for PostgreSQL</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Guodong Liu (刘国栋)</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Andrew Dunstan</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 PostgreSQL is the most powerful open source database management system. It is widely used and provides a good example on how to implement a DBMS. Due to requirements of my research project, I began to read the code one year ago; I'm familiar with the framework and the code organization, and have strong background of the query processing, i.e. the parser, rewriter, planner, and executor. Further more, I have tried to implement some interesting and indispensable functions which are not supported by PostgreSQL currently. For example, I have implemented the updatable views by automatically creating rules over PG 8.1.4, which is also an important function listed in TODO list. As my project in SoC, I want to implement the column-level privilege subsystem for Postgres.<br>
&nbsp;&nbsp;According to the SQL92 standard, there are four levels in the privilege hierarchy, i.e. database, tablespace, table, and column. Most commercial DBMSs support all the levels, but column-level privilege is hitherto unaddressed in the PostgreSQL, and I intend to implement it.<br>
&nbsp;&nbsp;I select the topic not only because it is required by the SQL92 standard but also because it is very useful in real word. With the feature, DBA can assign privileges in fine granularity, i.e. the column level, which is pre-requisite for protecting sensitive attributes. The function is so important as is listed in PostgeSQL's TODO list, but to the best of my knowledge, hitherto unresolved.<br>
&nbsp;&nbsp;I will implement the column-level privilege subsystem in PostgreSQL, which will allow DBA to manage privileges in column level. Generally speaking, the job can be coarsely divided into three parts:<br>
&nbsp;&nbsp;1. Modifying the parser for supporting column-level Grant/Revoke grammar.<br>
&nbsp;&nbsp;2. Recording column-level privilege information as meta-data in appropriate system catalog.<br>
&nbsp;&nbsp;3. Column-level privilege checking before evaluating SQL queries.<br>
&nbsp;&nbsp;I've made my plan after thorough thought, and I am confident to finish it in time.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implementing support for read-only queries on PITR slaves</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Florian G. Pflug</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Simon Riggs</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The support for PITR (Point-In-Time-Recovery) in postgres can be used to build a simple form a master-slave replication. Currently, no queries can be executed on the slave, though - it only replays WAL (Write-Ahead-Log) segments it receives from the master. I want to implement support for running read-only queries on such a PITR slave, making PITR useful not only for disaster recovery, but also for load-balancing.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Autovacuum Scheduling</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>German Poo-Caamano</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Alvaro HERRERA Muñoz</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will introduce a way to help the scheduling in order to allow the automation of VACUUM.  It will be oriented to implement the proposal made by Alvaro Herrera, which description was sent to pgsql-hackers mailing list and which is available at http://archives.postgresql.org/pgsql-hackers/2007-01/msg00684.php. I will give a global summarize of it, which are taken from that URL:<br>
<br>
Extend the catalog in order to support scheduling management.<br>
As it was proposed, it will include mahnagement for a group of<br>
tables and management of group of intervals of time.<br>
<br>
Group of tables will define which groups can be autovacuum in the same period of time, which could be set by the administrator; and, a group of intervals will define the period of time allowed to run the autovacuum for a group a tables.<br>
<br>
The implementation will be a sort of crontab job scheduling, where:<br>
* The group of interval belongs to the timing scheduled<br>
* The command to eexcute is vacuum<br>
* The group of tables will be argument for the command (what objects are involved for a certain interval).<br>
<br>
The syntax won't be as rich as cron, but it will provide the most common cases.<br>
<br>
On the other hand. It also should determine if a required to run vacuum after all and if the machine has resources to run in.  It will required to study about how to achieve this.<br>
<br>
Also, is required to define a way to notify the scheduler when a change in the schedule has been produced, it means, when the catalog is modified by the user.<br>
<br>
To accomplish it, the followings are more or less the steps involved:<br>
<br>
* Study the internals of the catalog, files involved and how to<br>
&nbsp;&nbsp;deal with the parts of code being changed by others during the<br>
&nbsp;&nbsp;projects.  It should be short with the right mentoring. Also,<br>
&nbsp;&nbsp;some help from cscope will be required.<br>
<br>
* Get the basics.  Define group of tables and group of intervals<br>
&nbsp;&nbsp;and how to deal with the scheduler.  In first instance, the<br>
&nbsp;&nbsp;very basic should be implemented in order to see the minimum<br>
&nbsp;&nbsp;functionality running.<br>
<br>
* Define and implement a way to determine if a table of group<br>
&nbsp;&nbsp;need vacuum or not.  Also happens studying the loads.  Probably<br>
&nbsp;&nbsp;will needed some minimum limits where the vacuum can run. Running<br>
&nbsp;&nbsp;a vacuum with high load should be done only manually.<br>
<br>
* Get the task running by the scheduler and define and implement<br>
&nbsp;&nbsp;a notification system to inform the scheduler that some task<br>
&nbsp;&nbsp;where modified.<br>
<br>
* Improve the crontab alike system.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Integrity check algorithm for data files</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Robert Mach</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Zdenek Kotala</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A final output of this project should be either a freestanding program or integration into the code of Postgres, which will be able to check the integrity of data stored in the database.<br>
The main benefit of this project should be the program itself and its proper functionality which should increase the trust in data stored in database, therefore increase the credit of PostgreSQL itself.<br>
I will focus on checking the internal structure (whether it corresponds with definitions), checking the validity of pointers/references and checking the validity of tables.<br>
The final product of this project should be helpful for administrators by detecting corrupted data as well for developers, who might find it useful to validate the data in database. The functionality of this product should be also very useful during running of regression test in order to find reasons of faulty behavior.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>[pgUnitTest] Query and stored procedure unit tests for PostgreSQL</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mickael Deloison</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mark Wong</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this project is to build a software able to complete unit tests on a set of queries or stored procedures for PostgreSQL. This means:<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Testing a query execution time (TEST_EXECTIME)<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Testing the number of rows returned by a query (TEST_ROWSCOUNT)<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Testing the result of a stored procedure execution (TEST_RESULT)<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Testing the presence of specific results (TEST_RESULTS)<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Testing the success of insert statements (TEST_INSERT)<br>
<br>
The program that runs those tests is a command line program. Test description is done in a XML file that is loaded with the command line. In order to make the test description easier a little scripting language is available. As an example:<br>
UNITTEST {<br>
&nbsp;&nbsp;&nbsp;&nbsp;EXECUTE<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SELECT name, surname FROM the_table WHERE age &lt; 20;<br>
&nbsp;&nbsp;&nbsp;&nbsp;WITH<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TEST_RESULTS;<br>
&nbsp;&nbsp;&nbsp;&nbsp;CHECK –i<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Name, surname<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Alfred, Newman)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(John, Smith);<br>
}<br>
We can see the '-i' option, meaning: case insensitive. Other options can be: '-l' or '-g', depending on the test type:<br>
&nbsp;&nbsp;&nbsp;&nbsp;* TEST_EXECTIME: no option<br>
&nbsp;&nbsp;&nbsp;&nbsp;* TEST_ROWSCOUNT: '-l' means &quot;less than&quot;, '-g' means &quot;more than&quot;<br>
&nbsp;&nbsp;&nbsp;&nbsp;* TEST_RESULT: '-i' means &quot;case insensitive&quot;<br>
&nbsp;&nbsp;&nbsp;&nbsp;* TEST_RESULTS: '-i', '-l' means the specified results are included in<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the results returned by the query, '-g' means the opposite<br>
&nbsp;&nbsp;&nbsp;&nbsp;* TEST_INSERT: no option<br>
<br>
An example of insert unit test is:<br>
UNITTEST {<br>
&nbsp;&nbsp;&nbsp;&nbsp;EXECUTE<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FOR 1..1000 {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INSERT INTO MY_TABLE VALUES ('%{integer(5, 10, 0, true)}%',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'%{string(&quot;[a-z]{5,10}&quot;, 10)}%',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'%{dictionary(mydict.txt, 0)}%',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'%{reference(other_table, column, 5)}%');<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br>
&nbsp;&nbsp;&nbsp;&nbsp;WITH<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TEST_INSERT;<br>
}<br>
This uses a special syntax in order to use data random generators and insert a lot of data with a FOR loop statement. This is also helpful to fill in a database in order to do other tests than unit tests.<br>
<br>
In the example above the query insert 1000 times:<br>
&nbsp;&nbsp;&nbsp;&nbsp;* A random unique integer between 5 and 5000 with no null value<br>
&nbsp;&nbsp;&nbsp;&nbsp;* A string composed of letters a to z and 5 to 10 characters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with 10% of null values<br>
&nbsp;&nbsp;&nbsp;&nbsp;* A string which corresponds to a line in mydict.txt with no null value<br>
&nbsp;&nbsp;&nbsp;&nbsp;* A value picked in other_table.column with 5% of null values<br>
<br>
In the script or in the XML file there is an option to tell the interpreter if PostgreSQL must rollback or not after the set of unit tests.<br>
<br>
We can provide a set of tests. There is a result file containing the result for each test:<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Success or fail<br>
&nbsp;&nbsp;&nbsp;&nbsp;* Result of the test<br>
This result file is in XML but on the command line we can specify to convert it to text or HTML or insert the results into a database.<br>
<br>
An example of use is:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pgUnitTest -i script.pgu -o report.html -f html<br>
This was an example where we provided:<br>
&nbsp;&nbsp;&nbsp;&nbsp;* The input script which has to be analyzed and executed<br>
&nbsp;&nbsp;&nbsp;&nbsp;* The output<br>
&nbsp;&nbsp;&nbsp;&nbsp;* The output format (txt or HTML or DB or XML)<br>
<br>
<br>
The XML output can be reused in order make a difference between outputs:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pgUnitTest -d file1.xml file2.xml file3.xml ... –o result.html<br>
This example shows how to make a diff between results to see differences. It is useful to compare different tests.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Full Text Search support in PostgreSQL GUI Tools</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ivan Zolotukhin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Oleg Bartunov</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 There are many users (especially novice) asking about better and easier configuration of Full Text Search in PostgreSQL (O)RDBMS, which is quite complicated currently. Even new FTS features (e.g. much clearer configuration with SQL syntax) in forthcoming PostgreSQL 8.3 release won't help much for users that want simple &quot;several clicks&quot; setup of a small system with full text indexing. Adding support of nice user-friendly FTS configuration in popular PostgreSQL GUI administration tools (phpPgAdmin and pgAdmin III) would help a lot to spread PostgreSQL among wide group of potential users. Also certain GUI features can be helpful even for experienced users, simplifying debug and configuration of amazingly flexible and powerful Full Text Search engine in PostgreSQL.<br>

	</div>
 </td>
 </tr>
</table>
<a name='psf' />
<h2> psf </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Corrected Title: Proposal to clean up urllib. CodingProjectIdeas/StandardLibrary/CleanupUrlLibProject</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Senthil Kumaran</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>George D. Montanaro</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In the Python Standard Library, the functions required to handle url specific operations is spread across different modules in the Internet Protocols Category; primary modules being urllib, urllib2 and urlparse. These modules are old,have overlapping functionality, few required features missing in one or all of the modules. These three modules stand a chance of cleanup on various bugs;inconsistencies; feature requests and implementation changes required in the code.  With the cleanup of the urllib modules, all the modules can be<br>
unified into a single module which will provide better interfaces to most commonly used methods in url handling.<br>
<br>
Many of the methods can be improved to an enormous extent using function decorators.The present modules are coded compliant with RFC1738, RFC1808 as reference and with certain properties of RFC2396 are included. These RFCS have become obsolete and have been superseded with a new RFC 3986 for URI and RFC 3987, a new protocol - IRI for handling unicode characters in URI.<br>
<br>
The unified module should incorporate methods and interfaces similar to as provided in the separate modules like mechanize, urlgrabber and can refer to modules which have tried to implement RFC 3986 compliant url handling mechanisms (as in 4Suite).<br>
<br>
With the changes in the code of url modules, the following bug-fixes,enhancement requests and feature requests are to be incorporated into this project.<br>
<br>
Bug Fixes:<br>
1) Implement a timeout method for the connection.<br>
2) [ 600362 ] relocate cgi.parse_qs() into urlparse<br>
3) [ 735515 ] urllib,urllib2 to cache redirections.<br>
<br>
Fixes with few modules:<br>
Patches<br>
1) [ 1648102 ] proxy_bypass in urllib handling of &lt;local&gt; macro<br>
2) [ 1664522 ] Fix for urllib.ftpwrapper.retrfile()<br>
3) [ 1667860 ] urllib2 raises an UnboundLocalError if 'auth-int' is the qop<br>
4) [ 1673007 ] urllib2 requests history + HEAD support<br>
5) [ 1675455 ] Use getaddrinfo() in urllib2.py for IPv6 support<br>
<br>
<br>
Changes.<br>
1) [PROPOSAL] [MAJOR] Unification of urllib, urllib2 and urlparse module into a single module.<br>
<br>
2) In the implementation, follow the RFC3986 for URI and RFC3987 for IRI as against the obselete ones in RFC2396,RFC 1738 and RFC 1808. Clean up the modules with the changes proposed in RFC3986,RFC3787 whereever the implementation is not compliant.<br>
<br>
3) Implement higher level interfaces to url module, which can accomplish most common tasks. The higher level interface definitions to follow the interfaces of the mechanize and urlgrabber module.<br>
<br>
4) Enable consistency in Proxy and Proxy Authentication Support.<br>
<br>
5) Provide HTTPRefreshProcessor, HTTPEquivProcessor,<br>
HTTPRobotRulesProcessor,HTTPRedirectHandler,HTTPRefererProcessor,<br>
HTTPRequestUpgradeProcessor Objects to urllib module.<br>
<br>
6) Provide Interface to urlgrabbing feature.<br>
<br>
7) urlparse brokenness issue is addressed in this discussion:<br>
http://mail.python.org/pipermail/python-dev/2005-November/058301.html<br>
And a new uriparse module was proposed:<br>
sf.net patch [ 1462525 ] URI parsing library<br>
<br>
It is required to analyze the changes required with this new uriparser library.Analyze this new library and understand the changes required in other url modules and changes required in the new urilibrary itself.<br>
<br>
8) Chache facility and query cache facility.<br>
<br>
9) Enable changes in other standard lib (socket, htmllib) modules which are used in urllib.<br>
<br>
10) Write units for all the fixes, changes proposed and write tests to other standard library changed areas.<br>
<br>
11) Understand the actual usage/implementation aspects when coding the<br>
requirements of a new standard protocol like RFC 3987 detailing<br>
Internationalized Resource Identifiers (IRIs).<br>
&nbsp;<br>
12) Document the new features and Update Existing Documentation.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>SymPy: Multivariate Polynomial Equations and Gröbner Bases</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Robert Schwarz</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Fabian Seoane</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Synopsis:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Extend SymPy to handle basic polynomial methods.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Implement Gröbner bases (with Buchberger's algorithm).<br>
&nbsp;&nbsp;&nbsp;&nbsp;Use Gröbner bases for elimination in polynomial equations.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Optional: Factorization of polynomials, using different fields.<br>
<br>
Benefits for the Python and mathematics/science community:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The SymPy package is a lightweight and easy-to-use CAS, build up<br>
&nbsp;&nbsp;&nbsp;&nbsp;from scratch in Python. As such, it has several advantages to<br>
&nbsp;&nbsp;&nbsp;&nbsp;other software packages. For educational purposes, students can<br>
&nbsp;&nbsp;&nbsp;&nbsp;easily study the algorithms without struggling with syntax or<br>
&nbsp;&nbsp;&nbsp;&nbsp;technical details. The full power of the `real' programming<br>
&nbsp;&nbsp;&nbsp;&nbsp;language encourages experimenting and prototyping new<br>
&nbsp;&nbsp;&nbsp;&nbsp;ideas. Compared to SAGE, a collection of rather sophisticated,<br>
&nbsp;&nbsp;&nbsp;&nbsp;specialized packages, SymPy is a good opportunity for students to<br>
&nbsp;&nbsp;&nbsp;&nbsp;explore the world of symbolic computation.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;While the calculus specific operations like integration and<br>
&nbsp;&nbsp;&nbsp;&nbsp;differentials form a great part of the source base, some more work<br>
&nbsp;&nbsp;&nbsp;&nbsp;in the domain of abstract algebra is needed. The Gröbner bases can<br>
&nbsp;&nbsp;&nbsp;&nbsp;be used in many different algorithms and have direct applications<br>
&nbsp;&nbsp;&nbsp;&nbsp;solving multivariate polynomial equations. Besides the<br>
&nbsp;&nbsp;&nbsp;&nbsp;implementation of the basis generating algorithm, more general<br>
&nbsp;&nbsp;&nbsp;&nbsp;methods are needed, like the computation of the greatest common<br>
&nbsp;&nbsp;&nbsp;&nbsp;divisor, division of polynomials and different monomial orders<br>
&nbsp;&nbsp;&nbsp;&nbsp;(lex, grad-lex, ...).<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If the time permits, general (non-trivial) factorization<br>
&nbsp;&nbsp;&nbsp;&nbsp;algorithms can be added, making use of finite fields or algebraic<br>
&nbsp;&nbsp;&nbsp;&nbsp;extensions to the rational numbers. Here, different<br>
&nbsp;&nbsp;&nbsp;&nbsp;representations are needed for different purposes: symbolic<br>
&nbsp;&nbsp;&nbsp;&nbsp;(anonymous) roots of irreducible polynomials, real/complex<br>
&nbsp;&nbsp;&nbsp;&nbsp;numbers, perhaps decomposed in radicals, as in<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x = sqrt(2/3) - i*sqrt(1/3)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Future ideas can be discussed and then developed independently.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Web.py: &#39;teh Communicator&#39;</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Drew Newberry</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Aaron Swartz</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The objective of 'teh communicator' is to provide a central website for people to come to and ask questions about web.py. IRC is a useful tool because people can get real time answers. However, IRC lacks useful archiving and threading utilities for conversations. teh Communicator seeks to alleviate that problem by creating an interactive IRC like experience through AJAX, while still providing robust archiving, threading and searching facilities.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Documenting Python Packages with Docutils</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Lea Wiemann</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David John Goodger</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently, the standard way to document Python Packages is using<br>
Python-specific LaTeX markup.  Many people either do not know LaTeX or<br>
do not want to use it for documentation.  As a result, many Python<br>
packages are not documented using LaTeX.<br>
<br>
It would be desirable to have an easy-to-use format to document<br>
packages that is more universally accepted than LaTeX.<br>
``reStructuredText`` seems like the ideal format for documentation,<br>
and it is already widely known and accepted in the Python community.<br>
<br>
I propose to make Docutils ready for documenting Python packages.<br>
This requires implementing the following features:<br>
<br>
1. Support for multiple input documents.<br>
2. Support framework for multiple output documents.<br>
3. Add markup (reStructuredText roles and perhaps directives) that<br>
&nbsp;&nbsp;&nbsp;allows documents to be marked up in a similar fashion as the<br>
&nbsp;&nbsp;&nbsp;current Python-specific LaTeX markup.<br>
4. Add Python-specific LaTeX output.<br>
5. Add HTML support for multiple output documents; add styling for the<br>
&nbsp;&nbsp;&nbsp;HTML output that resembles the look of current Python module<br>
&nbsp;&nbsp;&nbsp;documentation generated by the current system as closely as<br>
&nbsp;&nbsp;&nbsp;possible.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Updating Twisted Conch</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Paul Swartz</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Matthew Lefkowitz</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 SSH is the defacto standard for remote shell access.  It's a very extensible protocol as well, with support for TCP/UDP forwarding and file transfer.  Twisted Conch is a from-scratch implementation of the SSH version 2 protocol.  It's used in Twisted to provide in-process support for an SSH server, as well as in other projects to provide a Python library for connecting to SSH servers.  Conch is a project that enables a lot of functionality.  However, this functionality means that the interfaces can be complicated to use and complicated to test.  My Summer of Code project would be trying to rectify these complications.<br>
&nbsp;&nbsp;&nbsp;&nbsp;My project would fall into two related parts.  The first part would be updating the tests for Conch.  The current tests are showing their age.  They have race conditions and intermittent failures: in short, they are non-deterministic.  This part would involve both refactoring Conch to be more easily testable, and adding and fixing the tests.  The second part is making a higher-level interface to the implementation.  Most users of Conch (like most users of other SSH implementations) do not need full access to the protocol's power.  A higher-level interface, just giving access to a shell/command/subsystem and port forwarding, and the basics of authentication, would mean that more applications would be able to incorporate SSH effectively.  These two issues are the most frequent complaints from Conch users.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Three months is not a long time.  In that time, I'd like to see the tests be update to not depend on race conditions.  They should be updated to use the new Deferred functionality in Trial, and to not use depreciated functions.  I would also like to see an interface for Conch that makes connecting to an SSH server as easy as creating one subclass and calling reactor.connectSSH().<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Adding fields and waves to PySoy</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Eric Stein</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Arc Riley</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My proposed work would add force field functionality to the ODE integration code in PySoy.  These fields could be used to create water with waves, bouyancy, wind pressure, waves in water resulting from wind, etc.  Basic uses of the field code would be pre-implemented to allow PySoy users easy access to water, wind, and gravity source objects, but there would also be an interface to allow custom fields to be created for the specific purposes of a user.<br>
<br>
An extensible object, soy.bodies.fields.Field, would inherit from soy.bodies.Body for positioning.  I will override the collision methods of Body to determine the set of bodies that will be acted upon by the field.  This will define the field's shape.<br>
<br>
Other functions will determine the strength and direction of the forces produced, which can be applied to the bodies within the field, including other field centers.  This could, for example, be applied to planetary gravity simulation with multiple gravity sources orbiting each other.<br>
<br>
Detailed timeline:<br>
<br>
First week: working development setup and compiling of pysoy, repository access, read source to learn current codebase.<br>
Second week: write dummy code to become familiar with adding to pysoy, learn the way ODE is wrapped.<br>
Third week: learn pyrex; start writing python module, create classes and framework.<br>
Midterm: By this point, I should have a module that compiles and can at least detect the set of objects within the field.<br>
3rd quarter: All functionality, from this point on polishing documentation and bugfixing.<br>
Final: Optimized implementation of all goals with pydocs and an example game to showcase functionality.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>New Ticketing System for DrProject</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jeff Balogh</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Victor Ting-Wo Ng</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 DrProject is a fork of Trac (a web-based software project management portal) that has been customized for classroom use.  It is designed to introduce students to the tools that professional development teams use to coordinate their work.<br>
<br>
DrProject's ticketing system is simpler than Trac's or Bugzilla's, but it is still too heavyweight for one-term student projects.  On the other hand, a simple to-do list wouldn't be able to meet the needs of larger projects.  Rather than building a two-tier system, I would like to implement something that can grow as the users' project grows.<br>
<br>
In a fresh vanilla DrProject installation, a ticket will consist of a title (mandatory) and description (optional).  The author will automatically be recorded, and each ticket will be given a sequence number.  However, anyone who can modify a ticket can also add new fields to it.  Once a field has been added to any ticket, it is available whenever any new tickets are created.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Python 2.5 Language support in Jython</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Tobias Ivarsson</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>James Edward Baker</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The JVM is a great platform, it is widely used, available on many devices and there are a lot of great libraries and applications available on the JVM. Python is a great programming language, it is well suited for rapid development, prototyping and agile development methods. Jython unites these two great systems. Sadly Jython is not in an up to date state at the present time. To aid this Jython needs to be brought to a state where it is compatible with the latest version of Python. That is what this project aims at. I will provide work on the parsing of Python code and generation of byte code for the JVM. Ideas for solutions can come from the latest CPython implementation, and other implementations of dynamic languages on the JVM, such as JRuby or Groovy.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>PyPy Scheme interpreter/front-end</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jakub Łukasz Gustak</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Armin Rigo</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 PyPy project's main part is not Python interpreter implementation, but its configurable translator. It provides a good way to avoid writing interpreter for every language and platform. It provides tool-chain for translating front-end dynamic language into one of the back-ends (C, LLVM. CLI).<br>
<br>
Scheme is a dynamic language (dialect of Lisp) with unusual built in features like: delayed evaluation, macros and continuations. This project aims to write an front-end (interpreter) for Scheme for the PyPy framework.<br>
<br>
Part of the project if to find out if call-with-current-continuation (call/cc) can be implemented on top of the primitives the stackless transform provides. This can (probably) lead to possibility of implementing continuations (similar to Scheme ones) in Python.<br>
<br>
More details:<br>
http://codespeak.net/pypy/dist/pypy/doc/architecture.html PyPy architecture<br>
http://codespeak.net/pypy/dist/pypy/doc/translation.html PyPY translation<br>
http://www.schemers.org/ More about Scheme<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Web.py - Session management</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Karol Tarčák</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tom Berger</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Web.py has no real session management, it relies on fup to provide some session funkcionality. This project will create an object/dictionary oriented session management with capability to use different backends to storage session data.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improve test coverage of Python 2.6 standard library</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alan McIntyre</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Facundo Batista</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 There are several modules in the Python standard library which either have no dedicated test suites, or have tests that cover significantly less than 100% of the module code. I propose to improve the test coverage of the Python standard library by implementing new tests for at least four modules with little or no existing coverage.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Merge the C and Python implementations of the same interface</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alexandre Vassalotti</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brett Cannon</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 For the Summer of Code, I am working on one of the specifications<br>
for the implementation of Python 3000. My project consist of<br>
merging the slightly confusing double C/Python implementations of<br>
the certain modules (eg. cPickle, cStringIO, etc). Since the C<br>
implementations are slightly different from their Python counterpart,<br>
the merges will requires to port certain features to the C versions.<br>
<br>
Currently, the C versions try to reimplement completely the<br>
functionality of the Python versions. It would be better to<br>
reduce the C versions, such only the parts which are<br>
speed-critical remains. The rest of the functionally should be<br>
provided by the Python implementations. Therefore, during my<br>
project, I will also try to reduce the size of the C<br>
implementations.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Patch verification system for Python</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Michał Kwiatkowski</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Grig Gheorghiu</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this project is to provide a straightforward way to test patches from the Python bug/patch tracker on SourceForge (soon to be migrated to Roundup). This system will test patches and generate reports automatically, giving feedback only a few minutes after patch submission. Both sides of the patching process will benefit -- the patch submitter can find out and fix his mistakes much faster, while Python maintainers are given a solid base for a patch review. Once in place, the system will make the process of accepting patches less tedious and much more productive.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>New Ticketing System for DrProject</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>David Cooper</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Greg Wilson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 DrProject's ticketing system needs to be more scalable than Trac's, the project management tool from which its codebase is derived. For DrProject to better align with its goal of being specialized for classroom use, its ticketing system not only needs to be useful for small projects with short lifespans but also be appropriate for the demands of large ones. Rather than building a two-tier system, I would like to implement a new ticketing system that can grow alongside these projects as needed.<br>
<br>
The original proposal is available here:<br>
https://stanley.cs.utoronto.ca/csc49x/drproject/DrProject/wiki/DrProjectSoC2007<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Jython Compiler</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Damien Lejeune</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael Taylor</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Jython is the Java implementation of Python usefull to add all advantages of Python (facility,rapitidy of coding,etc) in a Java developement.<br>
The goal of this project consists in updating some functionalities and in enhancing the compatibility between CPython 2.5 and Jython. The main thing of this work will be to update JavaCC grammar and the bytecode generator written by Jim Hugunin 10 years ago.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>SymPy - Geometry Module</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jason Gedge</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>James Joseph Jewett</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently SymPy does not include a geometry module. This project<br>
proposes to fill that gap by starting the foundation for a geometry<br>
module. The base of the geometry package would be the Entity interface<br>
for a geometrical entity. Extending from this interface would be<br>
entities such as Points, Lines, Rays, Segments, Polygons, Circles,<br>
and so on. After creating different objects a user could then query<br>
different things about sets of objects such as 'Does X intersect with<br>
Y?' or 'Does X contain Y?' CAS systems do not traditionally contain<br>
geometry packages, but some take the analytic geometry approach to<br>
solve geometrical queries using algebraic representations. For<br>
example, a line can be expressed as an equation. Two lines can have<br>
simultaneous equations solved to find the point of intersection.<br>
<br>
Although not covered by this project, future development could include<br>
extending the geometry to three dimensions and inquiring information<br>
based on surfaces and volumes. Also, a more physics based approach<br>
could be taken to determine intersection of moving objects.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Create standard Image and Sound objects for the Python libraries</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mastrodomenico Lino</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Arc Riley</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 There is a big number of Python libraries, both inside and outside of the standard library, that deal with images and/or audio samples. A partial list is: Tkinter, Tix, wave, ossaudiodev, winsound, aifc, audioop, sunau, sunaudiodev, imageop, PIL, Pygame, PyOpengl, numpy, Pythonmagick, Pycairo, wxPython...<br>
<br>
Unfortunately almost all of them use different and incompatible classes for representing the same data, or simply use Python strings and leave to the application the responsibility to ensure that the correct metadata (e.g. bytes per sample) is used to interpret the raw bytes in the string. This is probably due in part to the fact that  the standard library lacks the necessary classes. This makes the exchange of images and audio between them not impossible but a bit harder and slower than it needs to be.<br>
<br>
The goal of this project is the creation of two standard classes for images and sound data, respectively, and the creation of patches for at least a big subset of the mentioned libraries to permit the interoperable use of these new classes. A subset of the PIL Image class can be a reasonable starting point for the new Image class, but, of course, the exact interface should be the result of a community discussion.<br>
<br>
This proposal is the result of a discussion on python-dev, see:<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;http://mail.python.org/pipermail/python-dev/2007-March/072341.html<br>
&nbsp;&nbsp;&nbsp;&nbsp;http://mail.python.org/pipermail/python-dev/2007-March/072348.html<br>
<br>
and subsequent messages.<br>
<br>
The new classes can also benefit from the new extended buffer interface. Quoting Greg Ewing: 'This would be an excellent test case for the enhanced buffer protocol that's currently being worked on.'<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Python-based equivalent to commercial modelling systems for optimization problems (AMPL, GAMS, TOMLAB etc)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Dmitrey Kroshko</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Alan G Isaac</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Hallo!<br>
(Excuse my bad English)<br>
<br>
There are lots of commercial modelling systems for numerical optimization like AMPL(www.ampl.com), GAMS(www.gams.com), TOMLAB are. Just see for example<br>
http://tomopt.com/tomlab/company/customers.php – tomlab users<br>
http://tomopt.com/tomlab/products/prices/commercial.php – tomlab prices<br>
<br>
My proposition is creating a free Python-based equivalent to them, + connecting some non-smooth &amp; network solvers that our optimization department researches, + inviting our collaborators from other optimization departments of our &amp; some other institutes to provide their own solvers.<br>
<br>
I know that this year PSF is concetrated in existing projects. However, this project will not be 100% something new, written from zero because it is based on<br>
1) existing m-code from my OpenOpt experience (see below)<br>
2) fortran standalone routines from our optimization department<br>
3) lots of scipy solvers + connecting to other, already written.<br>
<br>
Now afaik essential free optimization environment is absent, but I strongly believe it's just a matter of time, like appearing Linux vs Unix was. And maybe from your decision will depend, will it be Python-based or Ruby- or caml- or fortress- or Java- or something else (by someone else). For example, I know that there are some efforts to make it in LispNYC.org project GSoC ideas, see for example<br>
http://lispnyc.org/wiki.clp?page=soc07-details/quad-opt<br>
'automatic placement of legends on function plots'<br>
while those some scipy optimization solvers can't yield graphic output at all.<br>
<br>
Of course this task is not simple but, as you know, 1000-mile jorney starts with a single step.<br>
<br>
BTW there are usually some solvers for solving systems of non-linear equations (like MATLAB, scipy fsolve or my nonSmoothSolve) attached.<br>
<br>
I already had some experience with my OpenOpt for MATLAB/Octave (I made that one in a time free from work, without any money obtained), see http://www.mathworks.com/matlabcentral/fileexchange/loadFile.do?objectId=13115&amp;objectType=file<br>
&nbsp;there are some examples in directory OpenOpt/Examples &amp; some pictures generated automatically. See http://www.box.net/shared/3jmi2hj8lk for my CV and detailed proposition.<br>
<br>
The environment will provide scaling, unified convinient text &amp; graphics output, checking user-supplied analitical derivatives, parallel calculations (for example for numerical gradient/subgradient obtaining), easy comparison &amp; similar to TOMLAB unified for all solvers call:<br>
prob = NLP(myObjFun, x0, &lt;optional params:&gt; TolX=1e-4, TolCon=1e-3, doPlot=true, MaxTime=1e3, MaxIter =1e4, ...) (similar prob=LP(f, other_args), prob=QP(...), ...)<br>
r = prob.run(solverName (or names of some solvers), &lt;optional params&gt;)<br>
output structure r will include algorithm used, licence of the solver used, its authors, web homepage of the solver, time, cputime elapsed, and much more. Some of the info will be printed (by default) before or after solver's work.<br>
All of the above is already done in my OpenOpt version for MATLAB/Octave (parallel - currently only for objfun gradient obtaining, not constraints) but for many reasons (the main is pass-by-copy in MATLAB/Octave vs pass-by-reference in Python) I'm rewriting all the code to Python now &amp; intend to continue development using Python language. GSoC support would helped me very much.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Web-based front end for PyBlosxom</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Michael Goddard</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>William Guaraldi</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I would like to work on adding a web-based front end for PyBlosxom. The front end would be a PyBlosxom handler that directly accesses the file and permits plugins, allowing simple installation and contribute to its ease of use. The expected features are: entry manager, edit screen with toolbar for formatting, error screens for issues like missing write permissions, login screen, http uploads for images and miscellaneous files, flavour editor listing symbols, config editor, file manager, preview, auto save, drafts, and spell check.<br>
<br>
The web-based front end handler would first handle the request, such as logging in, deleting entries, saving entries, upload files, delete files, and so on. The handler would then calls for the appropriate renderer from within the front-end or a plugin. The front-end will choose between a series of HTML renderers or javascript enabled HTML renderers on the existence of a cookie which will be created during the login phase. The handler then calls the pathinfo callback and then the filelist callback. It will then render appropriately to the request.<br>
<br>
The entry manager will display the entries in pages of a user selected amount, defaulted at 50. Each list item would include a checkbox, the item path, title, and post time. By selecting checkboxes, a large group of items could receive an action such as a delete function. Additionally the entry manager is the file manager, including actions for folder and file management. They differ in the default space that they display and that the file manager does not allow file edits though the entry manager does. This screen enhanced with javascript to allow sorting by column in the page.<br>
<br>
The edit screen contains a large text area for the entry, a text box for title, a text box for the save path, an non-editable text box for post time, and a series of buttons at the bottom depending on if it is a new entry or an edit. These buttons either saving it as a draft or publishing it, updating or creating the entry.<br>
<br>
The config editor will generate a page based off of the config dictionary in PyBlosxom. It displays a text box for a single element, a text box for a list separating elements by line, and a text box for a dict separating the key value pairs by the equality symbol. An additional text box and button will display near the bottom and above the save and cancel buttons for creating new properties.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Pyjamas: Export desktop applications to the web.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Lluís Pàmies i Juárez</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>James Tauber</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Pyjamas is a python framework based on Google's GWT, that lets you write dynamic web applications without knowing the under-layer complexity of Javascrit, HTML, CSS and browser incompatibilities. Pyjamas provides a python GUI toolkit with RPC support that lets developers writing their own applications in a high level framework. Its main disadvantage is that developers need to learn a new toolkit<br>
and a new RPC architecture that keeps far the majority of them.<br>
<br>
The goal of this project is to use the pyjamas framework to build a wrapper for PyGTK that will convert its widgets into Web widgets. It will be done by intercepting the GTK UI element actions and converting to pyjamas code. The non UI GTK code like models, image processing or user code will be kept in the server side using the default GTK libs and will be accessible through pyjamas RPCs. The GTK main loop will be replaced to compile the code and start a light python web server serving the application.<br>
<br>
At the end of this project a representative set of GTK widgets will be<br>
implemented and we will be able to run simple PyGTK applications without doing any changes to its code. The application is expected to run as a single user only, and the resources available for this applications will be located in the server side.<br>

	</div>
 </td>
 </tr>
</table>
<a name='psu' />
<h2> psu </h2>
<table>
 <tr>
 <th>Title</th>
 <td>OBSearch: a distributed similarity search engine</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Arnoldo Jose Muller Molina</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Cynthia A. Brown</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Synopsis:<br>
<br>
This project is to similarity search what 'bit-torrent' is to downloads. All the clients will share the workload when performing queries.<br>
<br>
Details:<br>
<br>
Similarity search is required in many areas. Examples are DNA sequences, music and program matching. When an exact match is required, it is possible to access the data very efficiently. In the case of similarity search, one has to use special indexing techniques to reduce the amount of comparisons that have to be performed. There has been much research on the subject and several approaches that work well in practice have been developed. All these approaches are CPU intensive. This of course limits considerably the amount of clients a server can hold.<br>
<br>
Individuals or small companies who want to provide similarity search services cannot afford the infrastructure required to support such indexes. OBSearch can be used to distribute the workload among the users and reduce the investment to a few &quot;seeder&quot; servers.<br>
<br>
OBSearch achieves this by dividing the search space into n &quot;boxes&quot;. Each client that joins the network will support m boxes (where m is much smaller than n). Additionally, OBsearch can determine for any query which boxes have to be searched. This allows OBSearch to efficiently perform similarity searches. The library is modular, so you can also use OBSearch in a single computer. It is very fast! http://planet-soc.com/node/1527<br>
<br>
This project could benefit different communities that require similarity matching services on audio, source code, video, biology data, etc.<br>
<br>
By using these ideas, CPU-intensive information retrieval can be performed with just a few servers. Infrastructure cost is reduced considerably. Also, the approach is very general. The only thing that the user has to provide is a distance function that satisfies the triangular inequality(1).<br>
<br>
This project is being developed as part of Google Summer of Code 2007. The mentoring organization is Portland State University.<br>
<br>
Technicalities:<br>
<br>
Among similarity search indexing techniques, the pyramid technique is of special interest. In this approach, all the data is divided into an i number of pyramids (the user specifies i). A query can be answered by looking only at the pyramids that intersect it. It is very natural then to separate each pyramid into a client and apply a distributed approach for answering queries. The pyramid technique can only match vectors. In order to be able to match any kind of object, a dimension reduction technique called SMAP (Simple Map) is being employed. To further improve performance, we are employing a P+Tree (partitions the space so that the pyramid technique becomes more efficient) combined with K-means++.<br>
<br>
(1) Also the users can provide an 'almost metric' and with some tweaking the function can be forced to satisfy the triangular inequality.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>TracMetrix: Improve software project visibility through integrated project tracking and metrics repository</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bhuricha Sethanandha</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Barton Christopher Massey</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Trac is an integrated software configuration management and project management tool. There are many potential enhancements that can be developed to make Trac become an integrated tool to support quantitative project management. I propose TracMetrix as a Trac plug-in to collect software metrics information to support quantitative project management. The goal of this project is to create a collection of metrics from information available in the Trac database and a SVN repository. The main focus on provide an integrated software metrics infrastructure that leverage existing software metrics programs such as PyMetrics. TracMetrix will be written in Python and follow the TagsPlugin architecture that can be fully integrated into Trac. It will require the change of database structure to store the metrics information. Metrics collection will be done both interactively and background processes.<br>
<br>
TracMetrix will provide a collection of software metrics to help development teams govern their projects with higher degree of confidence. The scope of this project is to provide the most commonly used software quality metrics and agile software production metrics. It is designed to bridge the information gap between the software development team and management while trying to minimize the tracking effort required by developers. At the end, I will demonstrate the use of metrics information to assist software project planning and decision making.<br>
<br>
TracMetrix will help software development teams to better plan the project within an acceptable uncertainty by<br>
providing quality information to support decision making. TracMetrix will support agile software production metrics such as production rate, throughput, inventory, etc. In addition, TracMetrix will provide general metrics such as defect density, code base size in lines of code, number of defects, etc. The metrics and statistical information will be represented both textually and graphically.<br>
<br>
Google and other commercial software companies can use TracMetrix to improve their process performance thus providing better quality products at a lower cost. Open source communities can become more transparent thus allowing potential volunteers and users to better understand their projects in term of progress, product quality and creditability in delivering new capability. Researchers can use the data to perform more extensive analysis instead of spending time gathering the data provided by TracMetrix.<br>

	</div>
 </td>
 </tr>
</table>
<a name='rockbox' />
<h2> rockbox </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Metadata-on-buffer and album art implementation</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nicolas Pennequin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Paul Louden</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My proposal is to implement metadata storage on the file buffer, or &quot;metadata on buffer&quot; in Rockbox, and then to use it to implement basic album art support.<br>
The basic idea is to change how metadata for audio tracks is stored. Here metadata means information tags, but also other kinds of information: more generally, everything related to a track. Currently, metadata is stored in a predefined area of the memory, as a fixed number (32) of fixed size structures, and the file buffer is only used to store compressed audio data and codecs. This limits the number of tracks in the buffer to 32 and prevents any kind of special features (those that use more memory than mere short text tags) from being supported, because allowing them would require reserving 32 times the amount of memory required. The idea behind &quot;metadata on buffer&quot; is to move metadata storage to the file buffer, allowing a virtually unlimited amount of metadata for a given track, without having to allocate the same amount for each track. This would make adding certain new features like lyrics display or, in particular, album art much easier than currently and allow existing features like cuesheet support to be implemented in a more elegant way. It would also improve memory management and allow more flexibility.<br>
The main difficulty in this project is that large parts of the playback engine will probably need to be redesigned in order to make this possible.<br>
Once metadata on buffer is complete, I intend to implement basic album art functionality as an example of use. This is one of the top feature requests for Rockbox and the currently existing patch is the base for most of the unofficial builds. I would adapt the patch to make it use the concept of metadata on buffer. This means the support would be limited to loading external bitmap pictures. Supporting JPEG pictures (external or embedded) would require much more work and is a controversial issue among the Rockbox developers because it would require integrating the JPEG decoder into the core, so it may not be wanted.<br>

	</div>
 </td>
 </tr>
</table>
<a name='ruby' />
<h2> ruby </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Project: RSpec suite for Ruby implementations</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Florian Groß</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Marcel Molina</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Synopsis:<br>
&nbsp;&nbsp;Write a test suite testing basic and more exotic aspects of the Ruby language<br>
&nbsp;&nbsp;itself and its standard library. Make it as complete as possible.<br>
<br>
Benefits to the Ruby community:<br>
&nbsp;&nbsp;Lately, there has finally been a diverse sprout of alernative Ruby<br>
&nbsp;&nbsp;implementations. Some that come to mind are JRuby, Rubinius, Cardinal and the<br>
&nbsp;&nbsp;Queensland University of Technology's Ruby.NET implementation. Also, Ruby<br>
&nbsp;&nbsp;itself is changing quite a bit as it is becoming Rite.<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;All of these projects would be able to benefit from a good test suite testing<br>
&nbsp;&nbsp;Ruby. Here's some benefits a good test suite would offer:<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;* A formal specification for the Ruby language that is easy to verify.<br>
&nbsp;&nbsp;&nbsp;&nbsp;It's easy to know how which features of Ruby a given implementatio supports<br>
&nbsp;&nbsp;&nbsp;&nbsp;and which it doesn't by running the tests.<br>
&nbsp;&nbsp;* Documentation for exotic features and surprising behaviours. A good way to<br>
&nbsp;&nbsp;&nbsp;&nbsp;find sample code for a given API method as well.<br>
&nbsp;&nbsp;* Easy to see when the behaviour of a Ruby implementation changes. Both for<br>
&nbsp;&nbsp;&nbsp;&nbsp;developers (helps with accidently breaking compatibility) and users (to<br>
&nbsp;&nbsp;&nbsp;&nbsp;keep up to date).<br>
&nbsp;&nbsp;* Helps with finding undiscovered bugs in Ruby implemenations (and with not<br>
&nbsp;&nbsp;&nbsp;&nbsp;reintroducing discovered bugs once they have been fixed).<br>
&nbsp;&nbsp;* Huge refactorings to Ruby implementations become possible without fear.<br>
<br>
Project details:<br>
&nbsp;&nbsp;I think the core tests should be handled from an external Ruby interpreter<br>
&nbsp;&nbsp;which passes the application to the Ruby interpreter which is being tested.<br>
&nbsp;&nbsp;This way simple features of Ruby (control structures etc.) can be tested<br>
&nbsp;&nbsp;without the tested Ruby needing to handle the subset of Ruby used by RSpec<br>
&nbsp;&nbsp;and its dependencies.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Cover the core of Ruby with RSpec</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Pedro Del Gallego Vida</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Johnathon Hornbeck</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 There are a number of Ruby implementations available today. The &quot;standard&quot; implementation is the original C-language-based implementation, written by Yukihiro Matsumoto, and now maintained by him and a number of contributors. In the last year, emerge different Ruby Virtual Machine (VM), YARV, Rubinius, JRuby, Gardens Point Ruby .NET, XRuby or cardinal are some good examples among others [1]. The goal of this proposal is create a common set of specification (using rspec) for the Ruby core, that verify the correct and same behavior of the different virtual machines and implementation. I would like the specs be usable for any virtual machine implementation or implementation.<br>
<br>
&nbsp;&nbsp;The goal in writing a spec is to describe the expected behavior from the objects. Each specification should describe one facet of the behavior. Specs should prefer clarity and understanding over any other principle.<br>
<br>
&nbsp;&nbsp;Test Driven Development (TDD) has you define the behavior of your system by writing small tests that precisely define some small piece of your system’s behavior. Then you implement that behavior. Then you clean up &amp; improve your design.<br>
<br>
&nbsp;* language is for specs that describe language-level constructs.<br>
&nbsp;* core is for specs for any of the built-in classes in Ruby. These are documented at http://ruby-doc.org/core.<br>
<br>
&nbsp;I have wrote the first time about this a in the ruby-talk mailing list. Looking for some feedback from the community.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Rubyland: Extending Desktop Applications with Ruby</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Scott Ostler</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Austin Ziegler</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Rubyland is a way to aggregate and process application-triggered events, using Ruby. The goal of Rubyland is a desktop where any application's functionality can be extended and customized from a central location. For example, if I want to post emails from an address to a web api, I shouldn't need to learn a compiled plugin system just for my mail client; it should only be a few lines of Ruby, and it should work with as many clients as possible.<br>
<br>
To accomplish that, Rubyland consists of a Ruby service that runs on a client's computer, and collects events that event source plugins generate. For example, there is a notification framework called Growl for Mac OS X, and Rubyland contains an event source that forwards those notifications to Rubyland proper. Users can write their own event handler plugins by subclassing a generic handler class, defining what type of event to handle, and what to do with it. The user drops the Ruby file into Rubyland's plugin folder, and Rubyland takes care of the rest.<br>
<br>
Rubyland's event service is cross-platform, but the event sources I will write are Mac OS X specific. Unfortunately, I don't expect to have the time or experience to integrate other platforms into Rubyland, although doing so would be very valuable. My hope is that if one part of the Ruby community finds Rubyland useful, others will take notice.<br>
<br>
<br>
By the end of the summer, I hope to deliver:<br>
<br>
- a well-tested service to aggregate and handle the events of locally running applications<br>
- a dRB component to send and receive events over the network<br>
- a library to let Ruby code prompt the user with native dialog boxes<br>
- a GUI app to manage and showcase Rubyland<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>A Recorder/Code-Generator for FireWatir</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Helder dos Santos Ribeiro</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Angrez Singh</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project aims at allowing users to record normal usage on a website and then have a script generated that can reproduce such actions.<br>
<br>
This script is generated in Ruby and can be changed and mixed with existing Ruby code to extend its behaviour, using regular Ruby variables, loop constructs, etc.<br>
<br>
A parser is going to be built for Firefox logs of user-activity (extracted by existing free software extensions) with the ability to generate code for the browser-driving tool FireWatir.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Matrix module extensions/Various functionality extensions to Ruby&#39;s Matrix module</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bonchis Cosmin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Maurice Edward Borasky</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I would like to participate in a project suggested by Ruby Central, Inc., namely the one dealing with 'Extensions to the Matrix module'.<br>
<br>
I've used the Matrix module for a project involving distributed simulation of cellular automata, as part of a distributed application development framework that we developed in Ruby. The framework is called DObject, it is based on DRb, and it can coexist with Rinda too.<br>
The framework is open source and is to be published soon.<br>
<br>
To use the Matrix module we needed to extend it substantially, and I now understand the module quite well and am confident that it would be easy for me to extend it further with the functionality suggested by Ruby Central and also some of what I've developed already, if it is deemed generally useful.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Write a Ruby parser in ANTLR 3.0</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Haofei Wang</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Xueyong Zhi</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 new ANTLR 3.0 version ruby compiler -&gt; parser<br>
<br>
&nbsp;&nbsp;ANTLR is a very popular parser generator, and its 3.0 version is about to come out with big changes. Ruby is a beautiful language which i like.Currently there are lots ruby implementations, such as YARV, Rubinius, Jruby. Xruby is Ruby to Java compiler based on ANTLR(version 2.6.7).<br>
&nbsp;&nbsp;This project will try to release a new ANTLR 3.0 version ruby compiler based on the current Xruby project and make it compatible with ruby-head specification(1.9 series). If everything goes well, we can even have a ruby parser in ruby :)<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Framework for ETL and Data mining operations in Ruby</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Swanand Deodhar</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Shashank T. Date</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Main idea:<br>
&nbsp;&nbsp;&nbsp;The central idea and also a long term goal of this project is to create an ETL and Data mining framework for smart, quick and light weight data analysis using Ruby. As the idea can spread in multiple dicretions in this vast field, i am going to focus on Data extraction and Data transformation for the summer.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Apotomo Model-Driven Development Kit for Rails</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nick Sutterer</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Patrick Hurley</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Apotomo is a framework which helps speeding up the application design-, implementation- and maintaining process for rails projects. It emphasizes the 'model first, implement later!' approach where developers can concentrate on writing cool business logic instead of spending hours for moving one section of the application to another part of the UI or racking their head about how to write a pluggable user interface where components can dynamically be added or removed to the GUI. Apotomo does all this.<br>
<br>
Central place of any apotomo-driven rails project is the application model tree. It provides rendering of the user interface, handles addressing, urls, parameter passing, access control, automatical documentation of components, automatical tests and a component-oriented developing environment.<br>
<br>
The developer can model the application with a graphical editor or in pure ruby, using Apotomo widgets. Graphical widgets like pages, sections, notebooks, or tabs provide a clean and modular way to design the user interface. Behavioural widgets like parameter domains handle the interaction between the widgets. Implementation of the actual business takes place in logic widgets.<br>
<br>
Goal of this project is the development, documentation and community-building of the Apotomo rails plugin and the graphical model editor.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Extending Debugging Capabilities for Ruby on Rails</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Minciu Dumitru Eugen</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Steven A Bristol</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Currently, debugging Ruby on Rails applications is quite a difficult business. When in development mode, in case of any exception, Rails will throw a bunch of (sometimes unusable) information on the screen as an HTML page and that's about as much as Rails can do for you. This project aims to change that by providing a more interactive development environment for Ruby on Rails applications.<br>
<br>
What I'd like is to implement some functionality that allows Rails to function in a more REPL-like fashion. When an error is encountered, the error page should present the developer with an IRB session, similar to why's &quot;try ruby&quot; so he can interactively inspect and debug things.<br>

	</div>
 </td>
 </tr>
</table>
<a name='samba' />
<h2> samba </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Improving winbindd in Samba4</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Kai Blin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stefan Metzmacher</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Application for the Google Summer of Code 2007<br>
<br>
Proposed project: Improving winbindd in Samba4<br>
<br>
Samba4 contains a basic winbind implementation, but it is still lacking many features. The Samba4 Domain member page lists a couple of<br>
requirements that winbindd would need to work for Samba4, and speaking to Tridge on IRC hinted that he'd like to see winbind to be fully async.<br>
<br>
Deliverables for the project would be:<br>
* winbindd supports fully async user/group info, enumeration and auth commands<br>
* NTLM caching<br>
* PAC/info3 caching<br>
* Automated tests for the above functionality<br>
<br>
I have two years of experience in programming C in real projects, having completed both the 2005 and 2006 iterations of the summer of code for the Wine project. I have also contributed a couple of patches to Samba, mostly dealing with adding features to ntlm_auth. I would like to use this opportunity to familiarize myself with other areas of the Samba source code.<br>
<br>
I would like to add that I have also applied for a Wine project. Should I be accepted for both projects, I would let you and Wine decide what I should work on, I am really interested in both the Wine project I applied for and this project. In fact, time permitting, I would try to get both projects done, putting the unpaid project on the back burner if scheduling problems should arise.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improved vectored/asynchronous I/O support for Linux CIFS client</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Kirill S. Kuvaldin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Steve French</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The CIFS VFS is a virtual file system for Linux to allow access to servers and storage appliances compliant with the SNIA CIFS Specification version 1.0 or later.<br>
<br>
&nbsp;&nbsp;The current version of CIFS VFS makes use of multipage readahead and writebehind Linux kernel 2.6 routines. These routines enable a filesystem to submit multiple page read or write requests in a single operation. However, currently cifs_readpages() and cifs_writepages() routines are designed in a way that allows only &quot;sequential&quot; read and write file operations.<br>
<br>
&nbsp;&nbsp;The project is aimed to evaluate and test different approaches of utilizing more efficient parallelized/asynchronous versions of cifs_readpages() and cifs_writepages() functions.<br>

	</div>
 </td>
 </tr>
</table>
<a name='scons' />
<h2> scons </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Automatic build graph generation for SCons modeled on Automake</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Maciej Paweł Pasternacki</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>J. Gregory Noel</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 As of now, SCons functionality is similar to standard Make's -- it<br>
takes build graph description as input and from this graph it produces<br>
required targets.  Aim of the project is to augment SCons with<br>
functionality similar to GNU Automake which automatically generates<br>
Make's Makefiles (i.e. generate build graph description based on<br>
high-level project description, and complying to GNU packaging<br>
guidelines).<br>
<br>
Final product will include Python API for high-level project<br>
specification for SCons within SConstruct/SConscript files, inner<br>
program logic that generates relevant build graph from this<br>
description and transition tool to convert from Automake to SConstruct<br>
(without full Automake support, but supporting most common use cases).<br>
<br>
Project will be developed in test-driven manner and based on mock<br>
project descriptions for real-world non-trivial applications that are<br>
now Automake-based.<br>

	</div>
 </td>
 </tr>
</table>
<a name='scribus' />
<h2> scribus </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Imposition plug-in for Scribus</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mateusz Haligowski</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Riku Leino</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 While Scribus is being developed rapidly and getting closer to proprietary solutions, it still lacks one feature that is extremely useful for people who want to print professional documents: imposition. So, as a Google Summer of Code 2007 project, I would like to prepare an imposition plug-in for Scribus. It has been an urgent enhancement for a longer time and is reported on project’s bugtracker[1].<br>
<br>
The goal of this project is to provide an easy-to-use solution for printing multiple pages on both sides of the sheet of paper. It is intended to be a wizard, which will allow user to decide the size of the paper, and as a result it will create new Scribus file, with ready-to-print pages.<br>
<br>
After some discussion with Scribus developers, I decided that the options implemented in the plug-in will include:<br>
» booklet printing<br>
Allow printing previously arranged pages on a larger sheet of paper, so that after cutting the pages will make a booklet.<br>
» printing business cards<br>
Allow printing an original page multiple times on a fixed grid on the print sheet, taking into consideration both sides of the sheet.<br>
» printing n-folds<br>
Scribus already supports 3-folds and 4-folds. However, printing them may be quite tricky, because of folding lines.<br>
<br>
The target user of the plug-in is a user, who:<br>
» wants to print on a home printer<br>
It often happens, that user needs to print a single copy of a large document. In that case, Scribus will automagically design printing for the user effectively. Other cases are brochures on 3-folds, or double-sided bussiness cards. I intend to prepare a plug-in which will fully support this application.<br>
» has to prepare a job to be sent to a professional printer<br>
In most cases, the imposition is handled by specialists in the printing house. However, when it comes to simple documents which are to be printed in many copies, a popular way to limit expenses is self-prepared imposition.<br>
<br>
As imposition is a complicated and difficult process, I am aware that the plug-in is is not meant to replace the high end tools used by professional printers.<br>
<br>
[1] http://bugs.scribus.net/view.php?id=83<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Add Math Support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hermann Kraus</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Andreas Vox</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Rationale<br>
---------<br>
I have often wanted to have a tool that allows complicated layouts but is still<br>
easy to use. This is exactly what Scribus does. However, for scientific<br>
papers it lacks one main capability: Formulas. So I want to add this feature<br>
as my Summer of Code project. Interest in this enhancement is expressed<br>
by many people in the bug tracker [1][2] and by Debian users [3] and it's<br>
also listed as a desirable feature in the Scribus roadmap [4].<br>
<br>
<br>
Overview<br>
--------<br>
The goal of this project is to add easy-to-use math support to Scribus.<br>
As the task of writing a complete math typesetter is too large for SOC, a<br>
different approach is used. It is inspired by the Quark XPress(tm) plugin<br>
MATHSETTER [5]:<br>
<br>
o Let the user enter LaTeX source either directly or in a more user-friendly<br>
&nbsp;&nbsp;way via a graphical editor.<br>
o Apply a LaTeX template to this, so the user only has to type the formula<br>
&nbsp;&nbsp;and not a whole TeX document.<br>
o Run LaTeX on this source.<br>
o Display LaTeX's output in a frame while still keeping the<br>
&nbsp;&nbsp;(LaTeX-)formula as a property, so the whole thing stays editable.<br>
<br>
Use cases<br>
---------<br>
<br>
o Scientific posters<br>
&nbsp;&nbsp;It is very hard (if not impossible) to create good-looking posters<br>
&nbsp;&nbsp;with LaTeX but it's easy to add formulas to LaTeX documents. On the other<br>
&nbsp;&nbsp;hand it's very easy to create good posters with Scribus, but a complicated<br>
&nbsp;&nbsp;process is necessary to add just a single formula. The ability to use LaTeX<br>
&nbsp;&nbsp;for typesetting the formula and then post-processing it in Scribus (easily<br>
&nbsp;&nbsp;possible, after all it's just a vector graphic from Scribus' point of view)<br>
&nbsp;&nbsp;would greatly simplify this.<br>
<br>
o Math/Physics teachers<br>
&nbsp;&nbsp;At school, I've seen a lot of teachers who created their tests with Microsoft<br>
&nbsp;&nbsp;Word and relied on its formula editor or even on basic text formatting<br>
&nbsp;&nbsp;(sub-/superscript). They added any &quot;complicated&quot; math symbols (vectors,<br>
&nbsp;&nbsp;integrals, etc.) by hand to the printout. Obviously, the full power of<br>
&nbsp;&nbsp;LaTeX is something they are unwilling to learn (and it is probably not<br>
&nbsp;&nbsp;required for them). So I believe they would be happy to have a WYSIWYG<br>
&nbsp;&nbsp;tool that supports embedded formulas.<br>
<br>
Deliverables<br>
------------<br>
o Math support<br>
o Patches to Scribus to integrate an external UI editor<br>
o Python bindings<br>
<br>
[1] http://bugs.scribus.net/view.php?id=128<br>
[2] http://bugs.scribus.net/view.php?id=1030<br>
[3] http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=270618<br>
[4] http://wiki.scribus.net/index.php/1.3.x_Roadmap<br>
[5] http://www.bluesky.com/mathsetter/index.html<br>

	</div>
 </td>
 </tr>
</table>
<a name='scummvm' />
<h2> scummvm </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Improving AGI engine (Sarien)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Kari Antero Salminen</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Yevgen Sandulenko</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Improving AGI engine (Sarien)<br>
<br>
This project is about improving the recently adopted<br>
Sarien engine that is used to play Sierra's Adventure<br>
Game Interpreter (AGI) games, for example King's Quest I-III,<br>
Police Quest I, Space Quest I-II etc.<br>
<br>
What's to be done during this project:<br>
* Implementing AGI256 and AGI256-2 engine extensions.<br>
* Finish implementation of Apple IIgs sound.<br>
* Finish implementation of predictive input.<br>
* Add Amiga style (colored menus).<br>
* Add a Hercules emulation mode.<br>
* Fix bugs triggered by fan made games and<br>
&nbsp;&nbsp;also by official Sierra games.<br>
* Document engine better and all the fixed bugs<br>
&nbsp;&nbsp;thoroughly.<br>
<br>
How does this benefit ScummVM, its users &amp; developers:<br>
* AGI engine is made more compatible with official<br>
&nbsp;&nbsp;and fan made games.<br>
* One of the best source for AGI music and sound<br>
&nbsp;&nbsp;effects is utilized when Apple IIgs sound support<br>
&nbsp;&nbsp;is finished (Tandy and Apple IIgs are probably<br>
&nbsp;&nbsp;the best sounding AGI versions there are).<br>
* Playing becomes easier and faster when predictive<br>
&nbsp;&nbsp;input for the text is implemented.<br>
* AGI games' interface becomes nicer looking by<br>
&nbsp;&nbsp;adding Amiga style colored menus.<br>
* A little bit of nostalgia is made available by<br>
&nbsp;&nbsp;implementing the Hercules mode support.<br>
* Thorough documentation of the engine and the<br>
&nbsp;&nbsp;fixed bugs makes supporting the AGI engine easier<br>
&nbsp;&nbsp;in the future (Of course the documentation will<br>
&nbsp;&nbsp;need keeping it up to date so this isn't instant<br>
&nbsp;&nbsp;panacea).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>ScummVM Filesystem API redesign</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>David Corrales López</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Max Horn</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This is my proposal for the ScummVM Filesystem API redesign. The new design should solve present problems, such as: creation of the filesystem node objects, method naming convention, existing code cleanup, lack of functionality and scarce documentation.<br>
<br>
Given the complexity of ScummVM, a flexible backend for managing files will ease the further development of engines, and help make the existing code cleaner. It will also help debugging, since code will centralized and easier to comprehend. Additionally, extensive documentation will also be created during the development of the project.<br>
<br>
Through the usage of careful object oriented design, I expect to solve the current issues, providing a much improved -and documented- implementation of the architecture transparent Filesystem API.<br>
<br>
Finally, the testing phase will ensure that no regressions occur, and integration with the current modules is correctly verified.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Mixer Improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Timothy Stephen Mason</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kostas Nakos</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project involves overhauling the audio backend of ScummVM, with<br>
a particular focus on how AudioStreams are resampled and mixed in<br>
preparation for being sent to an output device.  In particular:<br>
<br>
&nbsp;* For high-power machines, the current linear interpolator may be<br>
&nbsp;&nbsp;&nbsp;selectably supplanted by a lowpass filter which resamples with a<br>
&nbsp;&nbsp;&nbsp;far smaller amount of error.<br>
<br>
&nbsp;&nbsp;&nbsp;Although high-quality resampling cannot recreate any frequency<br>
&nbsp;&nbsp;&nbsp;information lost during to the original sampling process, improved<br>
&nbsp;&nbsp;&nbsp;resampling will make the best possible use of any sound data<br>
&nbsp;&nbsp;&nbsp;provided with the games.<br>
<br>
&nbsp;* For low-end machines, the current audio backend will be improved<br>
&nbsp;&nbsp;&nbsp;such that current latency issues no longer cause stuttering of<br>
&nbsp;&nbsp;&nbsp;sound.  This may require the implementation of double-buffering.<br>
<br>
&nbsp;* Improved API support for audio, allowing greater flexibility for<br>
&nbsp;&nbsp;&nbsp;developers.  Among other things, the ability to dynamically change<br>
&nbsp;&nbsp;&nbsp;the sampling rate of AudioStreams will be added, as well as other<br>
&nbsp;&nbsp;&nbsp;such options demanded by the various sound formats that ScummVM<br>
&nbsp;&nbsp;&nbsp;supports.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>ScummVM Tools</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Sean Murray</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kostas Nakos</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Name:	Sean Murray<br>
Project Title:	ScummVM Tools GUI<br>
Benefits:	The tools provided for ScummVM work well, but they are somewhat unorganized and difficult for beginners to use.  By both unifying the command line interfaces and creating and optional GUI the process can be vastly simplified.<br>
Deliverables:	Unify command line interfaces<br>
&nbsp;Design base GUI structure<br>
&nbsp;Create extraction tools GUI<br>
&nbsp;Create compression tools GUI<br>
&nbsp;Create script tools GUI<br>
&nbsp;Create encoder tools GUI<br>
Schedule:	I expect the project to take the entire length of the program.  Unifying the command line interfaces should take a relatively short amount of time, perhaps 1-2 weeks.  Since most of the code is already written and only needs to be reorganized I expect this task to be fairly simple.  Before I begin coding the GUI I plan to create a mockup of the preliminary layout.  By planning out the complete design and what classes and objects I will need to create I believe that the actual GUI programming should be much easier.  This should take another 2-3 weeks.  Creating the different GUI elements will take the majority of the time, probably 4-6 weeks.  I plan to spend any surplus time implementing an automatic game compressor where the program will take an original copy of a game, copy all the required data files, and perform any requested compression.  I believe that this would vastly simply the process of extracting a game.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improved game script bytecode decompiler for ScummVM</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Andreas Scholta</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Johannes Schickel</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Since most of ScummVM's supported game engines are driven by<br>
bytecode scripts, having a tool to convert such scripts into<br>
a human readable format (code) can prove useful for debugging<br>
existing engines as well as help implement support for new<br>
ones.<br>
<br>
ScummVM's existing bytecode decompiler, /descumm/, exclusively<br>
translates bytecode used by SCUMM games. Although being<br>
generally functional, it exhibits a number of flaws that inhibit<br>
it from living up to its full potential.<br>
<br>
Writing an improved bytecode decompiler initially based on<br>
/descumm/ offers more opportunities than just fixing flaws<br>
in the original implementation: if the core of the decompiler<br>
is generic enough it can also serve as the foundation for<br>
decompilers for other bytecode dialects, ideally providing<br>
a general framework for bytecode decompilation.<br>

	</div>
 </td>
 </tr>
</table>
<a name='silverstripe' />
<h2> silverstripe </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Improve SilverStripe CMS Usability</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Elijah Lofgren</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sean Harvey</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Improve the usability of the SilverStripe CMS by implementing suggestions from a recent SilverStripe Usability Report and working with the SilverStripe community to make the CMS easier for everyone to use and enjoy.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Search Engine Optimization for SilverStripe</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Will Scott</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brian Calhoun</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project will increase the Search Engine Optimization (SEO) of the SilverStripe Framework by adding Google Sitemaps and Google Adwords support. Google Sitemaps support will allow for the Google search engine to index all pages within a SilverStripe site efficiently and will allow for specification of the most important pages. Adwords support will allow users to add paid search terms to individual pages and will allow them to manage Adwords campaigns from within the SilverStripe framework. Both of these additions will synchronize with Google to create a simple and powerful interface. The focus is on usability and simplicity. Initial setup of the additions will require only Google account credentials and marking pages will be integrated into the current page properties section of the Framework. The underlying code will be flexible so that it can be easily adapted to changes in the Google APIs. The technologies involved are PHP, JavaScript, the Google APIs, SQL for data storage, and the SilverStripe Framework.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Online photo editing software / New upload process / New garbage collection features</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mateusz Ujma</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Samuel Minnee</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Photos became more and more important way to spread information over Internet. Silverstripe has some basic functionality with dealing with them. But this functionality had to be improved and new features need to be added.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Online photo-editing software will allow user to resize, crop and rotate photos directly from silverstripe CMS. All process will take place inside browser so no longer user will hassle with desktop photo editing applications. Apart from photo editing my project includes improving current upload process and adding new garbage collection features.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Support for Multiple Databases</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Philipp Krenn</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brian Calhoun</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 SilverStripe is a thriving CMS with a unique set of features, but currently it only supports MySQL.<br>
This project is going to introduce a database abstraction layer with support for MySQL, PostgreSQL, and MS SQL – others might be added as well, but these three present the core for a broader adoption of SilverStripe.<br>
The explicit aim of this project is to enhance SilverStripe's functionality and maintainability. Greatest care will be taken to ensure that the abstraction layer will not hinder further development, but enable a simple, yet powerful and extendable evolution.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>SilverStripe Mashup with Wordpress and Others</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Quin Hoxie</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Samuel Minnee</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will make the SilverStripe compatible with popular web-based services to allow the CMS to build from other well-established technologies rather than compete with them.  The integrated services will include Flickr, YouTube, Wordpress, and other popular web services, time permitting.  The Wordpress integration is the most notable, as it would allow arguably the most popular blogging software to work hand-in-hand with SilverStripe.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Internationalisation</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bernat Foj Capell</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ingo Schommer</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The possibility of finding a certain CMS in their own language or at least have the possibility of translating it is something that many possible non-English users mind when choosing which one they will use. The aim of this project is to provide full multilanguage support for SilverStripe and for this goal a framework for i18n will be built and documented, and it will be tested with the contribution of two new translations.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implement OpenID and do security audits</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Markus Lanthaler</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Hayden Smith</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My idea is to implement OpenID (support OpenID authentication and act as an OpenID provider), in Silver Stripe. This would be a great gain for Silver Stripe and go much further then the proposed idea. I’m also interested in doing security audits/tests for Silver Stripe or work on the localization.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Google Maps support for SilverStripe</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ofir Picazo Navarro</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Hayden Smith</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will contribute to SilverStripe by creating an easy-to-use and user-friendly Module for the SilverStripe Framework to allow any application created using SilverStripe to access the fantastic features available from Google Maps, which include embedding maps in webpages, adding custom overlays (markers and polylines), and modifying default behaviour of the map.<br>
Users will benefit in such a way they will be able to plot on a Google Map any kind of information generated on the website or web application, such as visitors' origin, bandwidth statistics per region, etc.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Mash-ups for the SilverStripe CMS &amp; Framework</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Lakshan Perera</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Matt Peel</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Think of an instance where you have to host a conference and you feel the need of sharing its goodness with the rest of the world. You would see the web as the most suitable medium for this task. However, setting up a website on its own may not deliver the content to the right audience, or spread the word wide enough. With the advent of the community driven web (or the so-called web-two-point-oh) each piece of information holds its own value. Flickr for images, YouTube for videos and Del.icio.us for bookmarks are some popular examples of services that have grown to become vital components of this new Web. To make the best use of such services, you need to tailor your content correctly to be promoted on each of these communities. The trick would be to spread your content far and wide, yet manage it all from one central location, retaining the identity.<br>
<br>
People would love to have such features integrated with their Content Management System (CMS) itself, avoiding the hassles of content publishing and reusing. SilverStripe has grown by leaps and bounds to become a CMS that is admired for its simplicity and usability. A feature enhancement that makes the above scenario a reality would not only make the CMS even more attractive, but also expand SilverStripe’s userbase.<br>
<br>
Aim of this project is to integrate several popular web 2.0 APIs (namely Flickr, YouTube and Technorati) with the SilverStripe CMS framework to allow people to build Mash-ups easily.<br>

	</div>
 </td>
 </tr>
</table>
<a name='sipcomm' />
<h2> sipcomm </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Audio/Video Mailbox for SIP Communicator</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ryan Ricard</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Emil Ivov</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Basic Specifications:<br>
&nbsp;I plan on implementing an answering machine/mailbox for SIP communicator as a plugin that will:<br>
&nbsp;-Automatically connect a call after some amount of time.<br>
&nbsp;-Play an 'outgoing message' from an audio or video file.<br>
&nbsp;-Record audio/video from the caller to a file.<br>
&nbsp;-Cut off the recording after a certain time/filesize.<br>
&nbsp;-Notify the user that a message has been received.<br>
&nbsp;-Allow the user to listen to messages in one click.<br>
&nbsp;-Allow the user to delete messages or save them in a separate location<br>
&nbsp;-Allow custom outgoing messages - your boss hears one message, your mom hears another<br>
&nbsp;-'Just Work' without any configuration (including sane defaults for outgoing message, maximum message size, etc.)<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Shared Whiteboards for SIP Communicator</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Waechter Julien</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Yana Stamcheva</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 SIP Communicator is an audio/video Internet phone and instant messenger that supports some of the most popular instant messaging and telephony protocols such as SIP, Jabber, AIM/ICQ, MSN, Yahoo! Messenger and soon others like IRC, and IAX.<br>
<br>
The purpose of this project is to implement whiteboard support for the SIP Communicator.<br>
There are five steps in the project :<br>
1. Present a state of the art document of existing protocols that enable shared whiteboards.<br>
2. Describe and evaluate existing Java implementations of either the protocols enumerated in the document above or other custom solutions.<br>
3. If necessary we should envisage the option of crafting our own implementation of a whiteboard protocol.<br>
4. Integrate the implementation inside the SIP Communicator<br>
5. Create the whiteboard user interface.<br>
<br>
The original proposal is available here:<br>
http://www.sip-communicator.org/index.php/GSOC2007/SharedWhiteboards<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>SSH Support in SIP Communicator using JCraft SSH2 Java Implementation</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Shobhit Jindal</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Pavel Tankov</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project aims to provide SSH services integrated in SIP Communicator which will give the users the extra facility of communicating with remote machines over SSH from the comfort zone of chat windows. This facility can prove very useful for network admins in managing/supervising their network, and also for support teams of an organization where technical support staff will be able to help their customers while talking/chatting with them.<br>
<br>
This project aims to fulfill the following primary objectives:-<br>
<br>
*-* Treat remote machines as their buddies.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Users will be able to add remote machines to their buddy lists by creating an account(passive) of the SSH type by providing details such as machine name/IP address, port, username, password, HTTP proxy, even a nick name and icon :-) etc. When the account is enabled, the messenger will display an appropiate representation of the machine status such as online(machine reachable[pinging] and SSH services are enabled), offline(machine is unreachable), unknown[machine is reachable but SSH services are unreachable).<br>
The user will be au fait with the status of the machine as it will be updated periodically :-)<br>
<br>
*-* SSH sessions to be emulated as chat sessions<br>
&nbsp;&nbsp;&nbsp;&nbsp;Users starting a chat conversation with a remote machine(online) will be able to start SSH sessions(even multiple sessions at the same time by clicking again on the machine icon in his buddy list) with remote machines. Here a message sent from the user to the machine will be sent as command to remote machine and its output will be emulated as a chat response from the remote machine. Shortcuts for interupting the command, putting the current job into background etc will also be provided to the user.<br>
&nbsp;&nbsp;&nbsp;<br>
*-* [Optional] File transfers<br>
&nbsp;&nbsp;&nbsp;&nbsp;Users will be able to upload/download files to/from the remote machine.<br>
&nbsp;&nbsp;&nbsp;<br>
Some simple yet useful[cool] Features<br>
*-* User-defined Macros<br>
&nbsp;&nbsp;&nbsp;&nbsp;Users will be able to store macros which will expand to various commands during active sessions.<br>
*-* Bookmarking directories<br>
&nbsp;&nbsp;&nbsp;&nbsp;Users will be able to bookmark their favourite directories.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>SRTP support for SIP Communicator</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Su Bing</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Romain  Kuntz</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The main purpose of this project is to provide SIP Communicator the ability to transfer media data in a secure way. This can be achieved in a number of ways. However, I will use SRTP to realize this requirement.<br>
<br>
SIP and RTP are used by SIP Communicator as its signaling and media transfer protocol, other applications which support SIP and RTP (with proper codec) can communicate with SIP Communicator easily. If we want this compatibility when we are using encrypted media streaming, we shall use a standard way to implement stream encryption. SRTP is a security profile for RTP that adds confidentiality, message authentication, and replay protection to RTP. It is a Proposed Standard<br>
in the IETF Audio-Video Transport Working Group, and is defined in RFC 3711. So, SRTP is certainly the choice.<br>
<br>
My work is divided into 3 parts:<br>
1. Implementing SRTP Protocol in the form of a JMF plug-in using Java programming language (and C/C++/JNI if necessary).<br>
<br>
2. Integrating this plug-in with SIP Communicator. Make necessary changes for SIP Communicator in order to allow it establishing secured media session through SRTP protocol.<br>
<br>
3. Setting up an experiment. Show that this SRTP implementation is practical, i.e. test communication with other SRTP enabled SIP Applications.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implement SIMPLE in SIP Communicator</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Benoit Pradelle</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Martin André</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 As requested by the SIP Communicator team, I'll finally implement SIMPLE in SIP Communicator. This description is not anymore reflecting the work I'll do.<br>
<br>
RSS flow support in SIP Communicator :<br>
<br>
First step : evaluation time.<br>
<br>
The really first thing that I'll do is to browse the Internet to find some Java RSS parsers. These parsers will have to respect some constraints :<br>
- The most important of them is to be licensed under LGPL.<br>
- Then the library has to be compatible with all the currently used versions of RSS.<br>
- I'll check how active is the community around the lib, how many programs are using this parser.<br>
- I'll test all the parsers that I'll find, and see how they react to bogus flows and more generally to some complex flows.<br>
Considering all these parameters, I'll choose the library I'll use for the project.<br>
<br>
Second step : coding time.<br>
<br>
Once a protocol stack has been chosen, development can start.<br>
Before some technical details, here is the way I will integrate RSS flows with SIP Communicator :<br>
Every RSS flow will be a contact, always online. Flows will be displayed in a standard conversation window. Every X minutes, flows will be downloaded and displayed, each channel of the flow will be a message. Once a message has been displayed, it will be memorized to not being displayed again. The account options will allow the user to configure the amount of time between server checks and if messages displayed must be forgotten when SIP Communicator stops. The user can send messages using this account, they will simply be displayed locally.<br>
<br>
I'll consider that an account has two parameters: the amount of time between server checks and if messages displayed must be forgotten when SIP Communicator stops. I'll implement the OperationSetBasicInstantMessaging using a Timer and a TimerTask to check messages from the server and simply echo local messages. I'll use the HistoryService to register messages of the flow to not display them again on every server check. A very simple OperationSetPersistentPresence will be implemented and will always say that a contact is online. I'll also do, all along the development, some SLICK test cases and execute them as far as I develop a new functionalities.<br>
Everything else will be done more or less as described in the documentation.<br>
<br>
Final step : support time.<br>
<br>
At this point everything should be coded, but the work isn't finished yet. I'll write more comprehensive SLICK tests and check if everything is ok with some real RSS flows. I'll also prepare some technical documentation for the most tricky parts of the development to help future developers to understand my work.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Support for RSS flows</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mihail-Alexandru Balan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Vincent Lucas</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 SIP Communicator's plug-in-based architecture allows simple adding of new protocols, in terms of interfacing effort. One innovative protocol, with a lot of potential to be unleashed would be supporting RSS feeds (RSS, ATOM, etc.) as contacts in the contact list. Updates to the feed would be presented to the user as instant messages from the respective contacts, thus allowing a seamless experience. This protocol could be enhanced in a number of ways:<br>
&nbsp;&nbsp;* replying to a RSS feed makes sense in certain situations. Why not make that possible too?<br>
&nbsp;&nbsp;* as RSS is an increasingly used and well-standardized protocol, the user might even migrate from the role of simple consumer to that of producer of RSS feeds. Some of the possibilities and scenarios will be discussed later on.<br>
&nbsp;&nbsp;* using message history support, SIP can be transformed in a lightweight feed reader. What about adding feed import/export options (OPML)?<br>
More details and in-depth planning are to be found in the detailed description.<br>

	</div>
 </td>
 </tr>
</table>
<a name='smc' />
<h2> smc </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Unicode Standard Malayalam Font</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hiran V</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Hussain K.H</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 To design a Unicode (UFT-8) standard Malayalam decorative font in Open Type Font which resembles to the calligraphy pattern following the guidelines provided by the Swthandra Malayalam Computing Team and to publish it under the GNU GPL.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Basic Voice Recognition System for malayalam</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Shyam k</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Santhosh Thottingal</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The aim is to make a basic voice recognition system for malayalam, having the ability to recognize the fundamental units of speech in malayalam.The software receives sound signals from the microphone and that is compared with each of the fundamental speech units of malayalam , using the characteristics formant frequencies of each of these units.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>mallutux, A Malayalam Typing Tutor</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mobin M</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Praveen A</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to implement a malayalam Typing Tutor under GNU General Public License. I plan to implement it like &quot;Tuxtype&quot; so that children can play and learn simultaneously.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Comprehensive malayalam input system for GNU/Linux</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jinesh K J</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>suresh p</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 AIM: The project aims at developing a complete solution to malayalam input to a GNU/Linux machine.<br>
<br>
Existing System: Existing system is a ISCII based keyboard layout which is used commonly. There is also a Pheonetic keymap prepared on top of SCIM.<br>
<br>
Requirements: The Proposed system aims at developing a complete system integrated malayalam input scheme. It avoids the necessity of installing a third party software.<br>
<br>
So it must be a<br>
1.system integration.<br>
2.Must provide a better phonetic mapping.<br>
3.A module to provide better accessability to the existing ISCII system by a GUI keyboard is also proposed.<br>
<br>
System Design:<br>
<br>
Contains different modules for various input methods,<br>
<br>
1. A pheonetic keymap based on SCIM.<br>
2. A Graphical keyboard for easier input of malayalam.<br>
<br>
The above two module are aimed at making the malayalam input to the system easier.<br>
<br>
to make input simpler<br>
<br>
1. xkb or xmod based xorg system is included to give malayam support in the root system level.<br>
<br>
A module to support the M18N system is also included in the design.<br>
<br>
These are the various modules in the project.<br>

	</div>
 </td>
 </tr>
</table>
<a name='squeak' />
<h2> squeak </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Developing a package model</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Damien Cassou</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stéphane Ducasse</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Traditional Smalltalk systems such as Squeak and VisualWorks were not historically designed to be package-aware. Class categories consist in assigning a label to a class. This labels are intended to structure and classify group of classes. This suffers from the following shortcomings:<br>
<br>
- No meta information for packages (comments and license will be really useful for example).<br>
- No simple API to access package content (class definitions, class extensions...).<br>
- No way to add instances variables to classes outside of the defining package.<br>
- No dependency mechanism which leads to very difficult deployment problems.<br>
- Each tool redefining the notion of package: browsers, SqueakMap, Monticello, Universes...<br>
- No refactoring support (renaming, moving a definition from a package to another...).<br>
<br>
This proposal aims to:<br>
<br>
- Create a new extensible model which contains meta information for packages. Each package will be able to define dependencies, recommended packages, comments... Each package will contain a set of class definitions, class extensions and class modifications.<br>
- Improve current tools (such as code browsers and versioning systems) to support packages.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improving the Compiler Frameworks</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mathieu Suen</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Marcus Denker</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Squeak's compiler framwork is hard to understand and not easy to extend. Over the last years, a number of projects used the compiler framwork from the Closure Compiler (the NewCompiler) for experiments. Even with some progress (e.g. the compiler backend has been extended to support old-style non-closure code and extended to support 3.9 pragmas), many things are needed until the NewCompiler can replace the old squeak compiler.<br>
The goal of this project is to improve the closure compiler with regard to the code it generates for closures. The Student should design and implement a number of schemes to optimize the perfomance of closures.<br>
This project follows the previous one (which was part of ESUG SummerTalk 2006) around the new generation compiler.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>A Squeak HTML/CSS Viewer</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jérôme Chauveau</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Todd Blanchard</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project consist in building a simple web page viewer able to display HTML/CSS contents.<br>
For example, a such tool will permit to display mails with HTML code and will be usefull for previewing pages during Seaside application development.<br>
The goal is not to build a browser - just a modern HTML/CSS renderer based on http://www.squeaksource.com/htmlcssparser<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Collaborative Development</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Benjamin Vanderheyden Schroeder</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ralph Johnson</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The Croquet environment, built on top of Squeak, provides a rich 3D space for collaboration. Squeak has good tools for browsing and editing source code, but none of these are available inside Croquet. We propose to develop Croquet versions of the Squeak programming tools, which could then be shared for collaborative development. Development sessions, including sound and video, could be recorded for later viewing. This would be especially useful for creating demonstrations for use in teaching.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>“One Wiki to Rule Them All” - Pier Improvements, Addressing Scalability Issues and Implementing full Text Search.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Oleg Korsak</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Keith Patrick Hodges</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to help a Squeak team to extend Pier usability, improve scalability and performance. To enhance usability means that users will be able to import/export markup not only in Pier syntax but also in other syntaxes.  This will be implemented through a new master-parser called a “switching wrapper”.<br>
<br>
The second goal is to try to address known scalability issues. For example, a lot of time is wasted when removing one page – all the pages are traversed to find and remove any internal links that point to the deleted page. Pier stores all the data in memory and with 17000 page example – a single page deletion can take approximately 3 seconds. This becomes a much bigger performance problem when  not all of the data is being stored in memory, as is the case when the Magma OODBMS is enabled as a persistent store. In this case the greater part of all page data is stored on the disk, so a traversal of all pages brings particularly low performance. In order to improve scalability there is a need to look at implementing caching strategies so that data which will be accessed many times is available as needed.<br>
<br>
The third goal is to build upon the caching facilities developed above so as to provide a 'Full Text Search' facility designed for very large Pier sites that use Magma as a persistent store.<br>
<br>
On completion of this Google Summer of Code project, Pier will be available as a solution to users looking for an easy to configure and extend upgrade to their existing legacy wiki's. Particularly commercial environments looking to manage and extend their unofficial intranet wiki's in the longer term.<br>
<br>
The scalability testing results will not only demonstrate that Pier is scalable, but also it will potentially benefit a number of projects that are using the Magma OODBMS.<br>
<br>
Finally the 'Full Text Search' capability, while being an essential part of any large wiki, will benefit the 'Gjallar Issue Tracker' project which is currently using external tools for indexing content.<br>

	</div>
 </td>
 </tr>
</table>
<a name='squirrel' />
<h2> squirrel </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Put all your nuts in the same basket</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Antoine DELIGNAT-LAVAUD</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Thijs Kinkhorst</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Squirrelmail has been around for quite some time now, and the script needs some cleanup of its architecture.<br>
<br>
The first thing to improve is the configuration system. There should definitely be an administration pannel to make setup and maintenance easier tasks. All those configuration variables should be put together ; if possible plugins should be able to add their tabs to the administration pannel). For user preferences, there should be an abstract class filled with default values set by the administrator, some private and some public (depending on whether the users could edit them). If for some reason one of the default value is modified, it should impact all accounts.<br>
<br>
Second point, the help system deserves some improvement ; it might be a somewhat ungrateful task to ground rewrite it, but that's what SoC is all about, now isn't it ? A single help button should redirect to the right topic page, including in the administration pannel (that would spare a lot of configuration error, because everyone is always too lazy to read the documentation before installing), and plugins as well (maybe some kind of help page index that plugins would update ?)<br>
<br>
The plugin system could be made a bit more flexible, but maybe some features should be included in the core distribution (I'm thinking about S/MIME or/and GNUPG, since I have already some PHP code ready for that).<br>
<br>
Finally, I'd like to finally see a _template system_ for squirrelmail. The idea has been on mailing lists for so long, but it really needs to be done. IMHO, the main reason people get discouraged from using SM is that they want to be able to customize it a lot more (I know, it's a kind of trend nowadays, what with blogs and sharing services popping all around).<br>
<br>
There are so many template systems out there, the choice for one needs to be discussed with the coding team... or why not write a new one from ground, lightweight and well fitted ?<br>
<br>
Anyway, I belive there is enough work to have a busy summer of coding.<br>

	</div>
 </td>
 </tr>
</table>
<a name='stsci' />
<h2> stsci </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Google Sky</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Daniel Kloeck</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Alberto Conti</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 General improovement of google sky<br>
<br>
Create a double precision polygon class with boolean set operations.<br>
Create a convertor from STC to KML.<br>
Optional: &lt;other VO Standards&gt; to KML (most important: VOTable).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Concrete mathematics and difference calculus extension module for SymPy CAS project</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mateusz Paprocki</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ondrej Certik</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Solving discrete problems is vital in several branches of<br>
science. This includes, to name a few, dynamic systems and<br>
chaos in physical sciences, also algorithms analysis and<br>
optimization in computer science.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;In most cases we are dealing with some sort of recurrence<br>
relations, and with definite and indefinite summations. This<br>
needs proper tools for solving it in a simple and elegant way.<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;However, software in the market for solving the mentioned<br>
problems is, in most cases, over-complicated and not obvious<br>
to non-programmers. This gives me motivation to design and<br>
implement an extension module in the field of concrete<br>
mathematics and difference calculus, to SymPy - a lightweight<br>
computer algebra system written entirely in Python.<br>

	</div>
 </td>
 </tr>
</table>
<a name='svn' />
<h2> svn </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Merge Tracking Auditing</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Hyrum K. Wright</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Rall</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Implement Merge Tracking Auditing, specifically commutative author and revision reporting, as defined in the merge tracking functional specification.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>An augmented diff representation</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Charles Acknin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Malcolm Rowe</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Synopsis<br>
=========<br>
Subversion's subcommand 'diff' currently generates a Unified-Diff format output to display the differences between two paths.  While this is fine for contextual-capable files -- that is, line-based files with a textual mime-type, e.g. text/* -- this method does not support directory-tree structural changes, Subversion's metadata changes nor binary files changes.<br>
<br>
This project aims at enhancing Subversion's differential facilities by providing a new serialisation format that would encompass all situations and changes that can arise from versioning trees as mentioned above.  It involves designing and implementing such a format into Subversion's libraries and client which would then be able to both generate and apply the so-called patch.<br>
<br>
Benefits<br>
=========<br>
Enhancing Subversion's diff system would help in several ways:<br>
&nbsp;- supplying an output that fits best with patch(1); I'm thinking about file operations such as renaming and copying with which 'svn diff' current output is not suitable for later application by patch(1)<br>
&nbsp;- providing a full differential support so that it's possible to produce a patch carrying just any information that happened to change between two paths; this file could be sent by email and applied elsewhere thanks to the appropriated reversing command, also part of project.<br>
&nbsp;- this could be a good start to build a patch management system in the svn core<br>
<br>
<br>
Deliverables<br>
=============<br>
A significant contribution to Subversion diff environment that may be a patch impacting the Client Layer libraries and svn client.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Python Binding Update</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Sage LaTorra</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>David James</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 -Title:-<br>
Python Binding Update<br>
<br>
<br>
-Synopsis:-<br>
Currently, the Python binding for subversion is incomplete and not very consistent with Python style. My project will be to update the current Python binding to be complete, and to create a new binding more in line with Python style.<br>
<br>
<br>
-Benefits:-<br>
1. Completes the Python binding, allowing full manipulation of subversion from Python.<br>
<br>
2. Provides a new Python binding that fits Python style. This new biding will be written as a separate update to the old Python binding (deprecating it), so that existing code may still use the old binding, but the new binding will better fit the Python style.<br>
<br>
3. Allow more users to more easily manipulate subversion. Python is currently a very popular language, so providing an efficient and effective binding will make subversion more useful to many people.<br>
<br>
<br>
-Deliverables:-<br>
1. Design documents and code documentation (in comments and in external documents) to make further work easy.<br>
<br>
2. Updates to the existing Python binding to complete functionality.<br>
<br>
3.A new binding (based on the old) to provide a more Python-ish binding.<br>
<br>
-Project Details:-<br>
1. Binding Updates. The current binding lacks some functionality that should exist. I would update the binding to expose all functionality in the underlying API.<br>
<br>
2. The existing binding would still be useable. My work with the existing binding would be primarily to add functionality.<br>
<br>
3. New Binding. I would also build a new binding with the goal of matching existing Python style. The new binding would essentially be a wrapper around the old one, providing a Python-ish interface for future developers.<br>
<br>
Based on existing issues, I have started to look for specific areas the existing Python binding is lacking in. This process would be aided by my mentor and the subversion community.<br>
<br>
This project would deprecate the old bindings: they could still be used (and would have new functionality) but the new bindings would be preferred, since they will more closely match Python style.<br>
<br>
My work would essentially have two phases: updating the existing bindings to completely cover the API, then writing the new binding to encapsulate the same functionality.<br>
<br>
<br>
-Project Schedule:-<br>
<br>
April 9 - May 28: Design and set up. I'm already fairly familiar with the use of subversion and some subversion bindings, this period would be used to become very familiar with the API and any other code needed. During this time, I will produce design documents including a more detailed plan and a description of the new Python wrapper to be created. Tests will also be designed to allow ongoing testing during the rest of the development.<br>
<br>
May 28 - July 28: Updating of existing binding. This period will be dedicated to adding to the binding so that the binding exposes the full functionality of the API. Testing will be ongoing, based on the tests designed in the first phase.<br>
<br>
July 28 - August 10: Creation of new wrapper. With the design work already done in the first phase, the implementation will hopefully be fairly simple (but I'm not naive enough to assume this will be the case). This time will also allow for extended testing of the underlying binding, since the new wrapper will be built on top of the existing binding. Testing of the new binding will be ongoing.<br>
<br>
August 10 - August 20: Final testing and documentation. Most documentation will be produced during the coding process, but this will leave time to fully document (including a few useful howto examples). This also provides some time for big fixes, since I'm sure there will be some.<br>

	</div>
 </td>
 </tr>
</table>
<a name='swarm' />
<h2> swarm </h2>
<table>
 <tr>
 <th>Title</th>
 <td>defobj portability across ObjC runtimes</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nima Talebi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Scott Christley</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 One of the tasks that was required for Swarm to run natively on Mac OS X was for it to work with the Apple ObjC runtime instead of the GNU ObjC runtime. This work is working in a prototype stage, but needs to be cleaned up and optimized. The main work is keep phase switching mechanisms in defobj functional with the Apple runtime, and to ensure that probes work.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Separation of model from viewer</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gennady Telegin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Marcus G. Daniels</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 To gain qualitative insights to how a model implemented with Swarm behaves under different circumstances, it is useful to be able to look at it, collectively, as it runs. For quantitative understanding, it is necessary to make measurements. Swarm provides infrastructure to visualize and measure simulations, but they are essentially attached to a single display and process. It would be useful to completely abstract away measuring simulations from running them such that 1) it was possible to attach to a running model on one system using any other system, such as using a web browser, and 2) that from the simulation's point of view there was no difference between an observer recording time series statistics and one showing, for example, a space of heatbugs. There are a wide variety of technologies to consider for something like ranging from XML-RPC/SOAP for messaging to shared memory segments for accessing large, densely populated spaces.<br>

	</div>
 </td>
 </tr>
</table>
<a name='ubuntu' />
<h2> ubuntu </h2>
<table>
 <tr>
 <th>Title</th>
 <td>bughelper &quot;data center version&quot; - making bug-triaging more easy!</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Markus Korn</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Holbach</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 bughelper is a tool written and maintained by Ubuntu's BugSquad to<br>
help triage bugs. This &quot;Summer of code&quot; - Project will mainly focus on<br>
restructuring the code and build a &quot;data center version&quot; to<br>
centralize the process of fetching information from launchpad.net, the<br>
bug triaging platform used by Ubuntu.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>A Gdebi Qt/KDE Frontend for Kubuntu</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Martin Böhm</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jonathan Riddell</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Kubuntu, the sister project of Ubuntu using KDE as its desktop environment of choice, lacks the ability of installing .deb packages in a straightforward way. Ubuntu solves this by using gdebi, a package installer with a command-line frontend and a GTK frontend. My intention is to create an easy-to-use, internationalized KDE frontend for gdebi, useful for Kubuntu and all the other GNU/Linux distributions that use the .deb packages.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Automatic boot and application start file prefetching</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Krzysztof Lichota</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tollef Fog Heen</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Application for Google Summer of Code 2007: Krzysztof Lichota<br>
&quot;Automatic boot and application start file prefetching&quot;<br>
<br>
= Idea =<br>
<br>
Disk access is one of the main reasons of slow application startup.<br>
Ubuntu's main competition (Windows XP) has been providing for a long<br>
time a feature to analyze application and system startup and prefetch<br>
necessary files into memory when application is started again.<br>
Also files are reorganized on disk for faster access during system boot and application startup. Currently, although several attempts has been made, there is no such end-to-end, automatic solution for Linux systems and I want to implement it.<br>
<br>
= Current state =<br>
<br>
There were some attempts to provide boot and application startup<br>
prefetching, but all have some problems and none of them works as expected.<br>
I have examined the following solutions:<br>
&nbsp;* Ubuntu boot readahead<br>
&nbsp;* Preload<br>
&nbsp;* Bootcache/filecache<br>
<br>
Full text of examination of current state is available at<br>
http://www.mimuw.edu.pl/~lichota/soc2007-prefetch/application.html<br>
<br>
Conclusions:<br>
Currently available solutions, while providing partial solutions, do not provide complete and automatic solution for prefetching. In particular:<br>
<br>
&nbsp;* None of them is able to intercept application startup<br>
&nbsp;&nbsp;&nbsp;automatically, analyze its behaviour and prefetch necessary files<br>
&nbsp;&nbsp;&nbsp;in efficient manner.<br>
&nbsp;* There is no complete defragging solution to lay out files on disk<br>
&nbsp;&nbsp;&nbsp;in groups which should be fetched together.<br>
&nbsp;* None of them provides lightweight tracing facility which can be<br>
&nbsp;&nbsp;&nbsp;used during each boot.<br>
<br>
= Project =<br>
<br>
I would like to concentrate on delivering prefetching solution for<br>
everyday use by casual users, leveraging prior solutions where<br>
appropriate and providing missing parts of complete and automatic<br>
prefetching:<br>
<br>
&nbsp;* Hook into application startup for analysis and prefetching.<br>
&nbsp;* Add lightweight tracing solution for booting and application<br>
&nbsp;&nbsp;&nbsp;startup.<br>
&nbsp;* Add offline tool to change layout of files on disk for faster<br>
&nbsp;&nbsp;&nbsp;prefetching.<br>
&nbsp;* Add prefetching of filesystem metadata.<br>
<br>
Implementation will be concentrated on most important parts (subject to analysis of benefit and implementation complexity) with the main goal to deliver working automatic solution at the end of project, leaving less obvious benefits as secondary goals. Filesystem specific parts will be done for ext3 as default file system in Ubuntu and most often used for desktops.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>GNota - A teachers gradebook for Edubuntu</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Leandro Batista Lameiro</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tom Hoffman</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 GNota - A teachers gradebook for GNOME<br>
<br>
== Project proposal ==<br>
* Mentor: Tom Hoffman<br>
* Student: Leandro Lameiro (lameiro at gmail dot com)<br>
<br>
My proposal is to develop a student managing application, to automate repetitive teacher tasks and have some basic students information archiving.<br>
<br>
The rationale is: The best free software to do that is OpenGrade ( http://www.lightandmatter.com/ogr/ogr.html ), that is not as good as it could be, is unmaintained and has an unintutive TK interface. Teachers need programs to do that, score calculations (and the other management tasks that Coon is going to do) are very boring and repetitive, and Edubuntu, as a education-oriented distribution, needs that to attract teachers and making their lifes easier is the way to go.<br>
<br>
The application will be able to manage students, grouping (tagging) them by classes (or any kind of grouping the teacher would like), manage basic information about the student himself/herself (such as name, missed classes, telephone numbers, behavioral/academic problems, photographs) and obviously, grades. Teachers will be able to enter the scores, and GNota will calculate the final score, using various algorithms (for example, arithmetic averages, weighted averages, average of the best N grades, etc) and determine if the student was approved in the subject, using some customizable rules like final score greater than 5.5 (or B-, or 3, this is customizable) or missed classes less than 75% (or 70%, also customizable).<br>
<br>
Also, the teacher will be able to tag the assignments (homework, test, project) and review the works later by tags. A good use case for this is to make evaluations in the end of the year of what kind of work the students learned more or to view scores for 'projects'.<br>
<br>
GNota will be flexible enough to let the teacher modify final scores, ignore certain scores in the average and missed classes, assign tasks to particular students (not to the whole class). Also, it will deal with different grade systems (Brazil uses 0.0-10.0 but USA uses A-F, it will also be able to do 0-100 and 1-5 systems).<br>
<br>
'''Great usability''' is a priority for this project!<br>
<br>
GNota SoC page suggested using MySQL. I strongly disagree with that. MySQL (or any kind of full-fledged database server) installation is too complicated to most non-technical users (like history teachers). Also, it would be a very big dependency and GNota doesn't need that. A SQLite database is fast enough and has the advantage of being simpler to take gradebooks from the teacher's computer to the school computer.<br>
<br>
A reminder asking to backup the gradebooks will also be shown regularly as suggested. This should be very easy using SQLite (a file copy operation).<br>
<br>
I plan to make it very modular, so that the core could be reused with other front-ends and applications (like schooltool or a qt interface for KUbuntu).<br>
<br>
If I have time in the end of the project, I will do:<br>
# A conversion for OpenGrade to GNota. This should be easy to do, as OpenGrade gradebooks are plaintext.<br>
# Very good looking interface.<br>
# Ubuntu package.<br>
# Excel / OpenOffice.org calc export<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>LDAP out-of-the-box</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Patrick Clancy</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Rodrigo Pereira Braga</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Posted on Ubuntu's wiki page for the Google Summer of Code 2007, a project to incorporate “LDAP out-of-the-box” was suggested.  The past few weeks I have been considering whether or not integrating the Fedora Directory Server would make a good GoogleSoC project for Ubuntu; today I checked the wiki site, and it appears that my question has been answered.<br>
<br>
The Fedora Directory Server uses LDAP for user authentication and is a GUI program that makes keeping track of users and groups incredibly easy.  It will work nicely with networks using active directory, and is known to be very reliable.<br>
<br>
The problem with FDS is that it's not easy to setup on Ubuntu.  I've tried unsuccessfully to deploy FDS on a small (1 server, 10 client) network last summer.  I was severely limited by time, so I only got to spend a day on trying to get it to work.  So, I propose that an additional program be written to facilitate the setup and installation of the Fedora Directory Server so that Ubuntu can become a more attractive Linux distribution for “home and small to medium sized business networking applications.”   This program would be written in Python, use GTK+ for the UI, and it would be targeted for Ubuntu.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>PyStart - Python Programming teaching/testing program</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jason Lee Roy Brower</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Pete Savage</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 PyStart will give teachers a way to work with programming students. And best of all, the students programs can be graded almost automatically will very little review from the teacher. PyStart will review code for the proper entries in the code and for the proper output. It will be created for beginners of programming. The goal of PyStart is to teach the basics of all programming skills. For example, loops and variable types.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Ubuntu bootloader manager</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Tomé Rosa Vardasca</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jordan Mantha</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A simple bootloader manager in the installation, to choose the order of the operating systems, customize the appearance and some settings.<br>
<br>
&nbsp;* https://wiki.ubuntu.com/BootloaderManager<br>
&nbsp;* https://launchpad.net/ubuntu-bootloader-manager<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Crypt manager</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Kévin Dunglas</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ioan Monoses</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 See http://code.google.com/p/crypt-manager/ for details !!<br>
<br>
Confidentiality of data stored on a computer is critical for a lot of company and organizations. It can be dramatic if confidential data (i.e : stored on laptop) are thieved and diffused.<br>
<br>
GNU/Linux, and especially Ubuntu, must provide an easy way to ensure security and confidentiality of important data.<br>
<br>
<br>
I plan to develop mainly one application which allow to encrypt some directories in your home.<br>
<br>
The GUI will be similar to Apple FileVault [1], wrote in Python and using GTK+ as toolkit (PyGTK / Glade).<br>
I will use cryptsetup [2] as backend which is already available in the Universe repository [3].<br>
<br>
If I still have time after that I will code a tool doing a job similar to &quot;clear my tracks&quot; in Mozilla Firefox. It will delete all temporaries files created by the system, and purpose to remove logs.<br>
<br>
[1] http://www.apple.com/macosx/features/filevault/<br>
[2] http://www.saout.de/misc/dm-crypt/<br>
[3] http://packages.ubuntu.com/edgy/admin/cryptsetup.html<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Accessibility improvements with the help of Beryl/Compiz and Orca</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Kristian Lyngstøl</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Henrik Nilsen Omma</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will improve the accessibility features in Beryl/Compiz and bring them in line with existing accessibility tools, specifically; Orca. Beryl/Compiz offers hardware accelerated magnification, and has the most important functionality, but is not really tailored for the needs of visually impaired. I will improve this by making the zoom feature follow focus with the help of Orca. The inverse color functionality is also helpful, but it would be even better if a specific color could be filtered, so green could be substituted for blue if you are red-green color blind, for instance. I will create this functionality to improve the accessibility value of Beryl/Compiz.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Accessibility enhancements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Guillaume Seguin</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Henrik Nilsen Omma</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this project is to improve overall accessibility to visually impaired users through a composited WM like Compiz or Beryl. It aims to tighten the links between the current accessibility frameworks like Orca and the WM to deploy its compositing capabilities in an useful and transparent way, such as providing an easy to use color filter for colour blind users. Any other feature that the WM could provide to improve accessibility will be considered. The relevant configuration components will be integrated in the distribution's current accessibility setup GUI and kept as simple and intuitive as possible for the end-user.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Handy Network Load Monitor and Traffic Inspector - Administration Tool</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Lucas Mazzardo Veloso</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Rodrigo Pereira Braga</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 * Summary<br>
&nbsp;&nbsp;In this project I'm proposing a new Ubuntu Administration Tool aiming to extend the Ubuntu Administration Suite now available. The project consists of: developing a new network load monitor to expose more network informations; developing an integrated tool combining a handy sniffer, a lightweight traffic analyzer and a set of customizable actions that can be executed on available connections on the fly.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Mouse Gesture Recognition for the Desktop</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Gerd Kohlberger</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Henrik Nilsen Omma</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My proposal is a mouse gesture application for the Gnome desktop,<br>
which can be used to launch any application on the desktop with<br>
a configurable mouse gesture. It will also provide a dbus interface to send commands to applications. It will use the Xevie X Extension to intercept all mouse events on the desktop and will use a compositing manager to provide on screen drawing capabilities.<br>
<br>
Another focus will be the user interface. It will take full advantage of a composited environment to provide a next generation UI.<br>

	</div>
 </td>
 </tr>
</table>
<a name='umit' />
<h2> umit </h2>
<table>
 <tr>
 <th>Title</th>
 <td>new: UmitWeb: the Umit web frontend</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Rodolfo Carvalho</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Adriano Monteiro Marques</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 UmitWeb is a project to make possible to Umit do remote scans throught the web.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Umit Independent Features Proposal</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Frederico Ribeiro</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Adriano Monteiro Marques</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My proposal is to develop the independent features of Umit and improve its usability and functionalities in such a way that it can turn into a more realible and powerful tool for network administrators.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Umit Interface Editor, [Profile and Wizard Editor]</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Luis Antonio Bastião Silva</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Adriano Monteiro Marques</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The aim of this project is to make a profile editor and a wizard, so the user can improve UMIT's features (add, edit and remove options).<br>
Actually UMIT doesn't have a profile editor and to change something, the user needs to edit XML files manually. Profile/Wizard Editor will change all interface's profile/wizard, i.e., add and remove new features of nmap.<br>
Profile and Wizard Editor will change in run-time the interface of UMIT (Wizard and Profile).<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Network Inventory, Scheduler &amp; Co.</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Guilherme Henrique Polo Gonçalves</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Adriano Monteiro Marques</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 UMIT Network Inventory aims to provide simple and efficient ways for detecting and showing changes in your network(s). It keeps a historic for Devices by Inventory that includes everything that happened to each device[1]. Also, it provides graphical ways for viewing changes over time easily. It also includes a host discovery to help detect your devices inside your network more easily.<br>
<br>
To this Inventory work, I will need to do a Scheduler for UMIT aswell. UMIT Scheduler is a nmap scan scheduler that works based on schemas, each schema is compound of a name, scan command, a scheduling  schema[2], and other optional settings. It supports the cron syntax and should run everywhere Python runs without problems.<br>
<br>
Also, a new database schema needs to be created so it can stores nmap xml scan output in an efficient way. This is where UMIT databaseng<br>
comes, it is a Python package that will handle the conversion XML -&gt;<br>
database, besides calculating differences between scans, executing searches and other features UMIT Network Inventory may need.<br>
<br>
<br>
[1] It is possible to configure data removal after N days. Default is<br>
to never erase data, but you may configure it to do so. After data<br>
is erased, it is not recoverable and you also lose part of your<br>
Historical data. This may change in the future.<br>
<br>
[2] Scheduling schemas are created inside Scheduler Editor, each schema is compound of a name and a cron date format. You may use the same scheduling schema in one or more Scheduler schemas.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>NSE Facilitator and Independent Features</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Maxim I. Gavrilov</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Adriano Monteiro Marques</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The idea of the NSE facilitator is to provide a better integration of Umit, Nmap and NSE in such a way that even a newbie could easilly run and share scripts with a few clicks, instead of finding them in the web, downloading, reading documentation to know how to use it with Nmap and running a long command to be able to use it.<br>

	</div>
 </td>
 </tr>
</table>
<a name='videolan' />
<h2> videolan </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Implement advanced subtitle support for VLC</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Philip-David Lamparter</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sigmund Augdal</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Nowadays, with international shipping and multi-cultural nations, an increasing number of people prefers to watch videos with the original audio track. However, since most people wouldn't be fluent with all the source languages they come across, subtitles are in widespread use to overcome this.<br>
<br>
The set of subtitling formats supported by the VLC player currently covers simple formats. One of the rather widely used formats, SSA/ASS, is not properly supported though - probably due to its capabilities for advanced styling, animation effects, and even drawing commands.<br>
<br>
My goal for this Summer of Code project is to provide VLC with rendering capabilities for this format. Ultimately, I'm desiring 99% compatibility with what's considered the reference for it: the Windows renderer &quot;VSFilter&quot;.<br>
<br>
To achieve this goals, I already started implementing a standalone filter for this purpose, called asa. Therefore, a rough outline of my plans is:<br>
1. Create bindings between VLC and asa.<br>
2. Fix the remaining bugs and missings in asa.<br>
3. Look for and cover extended usage cases in both VLC and asa (subtitle picture streaming, drawing mode, OpenType glyph substitution support)<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Overlay Video Filter for VLC</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Søren Bøg</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Antoine Cellerier</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal for this project to develop a video filter for VLC to allow third party<br>
applications to overlay static and dynamic alpha-blended images ontop of a VLC<br>
video. The idea here is to provide VLC with a video filter that is comparable to<br>
what bmovl and bmovl2 provide for MPLayer. What that is, is a video filter that<br>
enables third party applications to get access to a piece of shared memory or<br>
similar, in which the third party application can draw something. The third<br>
party application can then notify VLC that the shared memory has been updated,<br>
and VLC will then composite the image into subsequent frames.<br>

	</div>
 </td>
 </tr>
</table>
<a name='vim' />
<h2> vim </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Integrating vim editor with eclipse</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nageshwar Mannem</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Abraham Moolenaar</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 &quot;Many people use Eclipse and many people use Vim. But they don't work together very well.&quot;<br>
This project main objective is to integrate the vim editor with eclipse IDE as a plugin.The missing thing in eclipse is powerful editor and in vim is an IDE.<br>
<br>
There is already a plugin called Eclim. But this is Eclipse integration in Vim.There is another plugin viPlugin. But this is not a open source project. We need to pay to use it. (I didnt try this)<br>
<br>
The project is hosted here.. http://code.google.com/p/eeedit<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improve Vim GUI support on Mac OS X</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jiang Jiang</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Abraham Moolenaar</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Create a new branch of gui_mac.c to:<br>
<br>
1. Completely remove all deprecated (most of them are from Mac OS 9) function calls including Font Manager, File Manager, Apple Events and QuickDraw.<br>
<br>
2. Make use of the new Human Interface Toolbox (HIView, HIToolbar) model to create more user friendly GUI components, for example, GUI Tab, Dialog, Toolbar.<br>
<br>
3. Improve graphics rendering performance and i18n support with Quartz/ATSUI drawing/text layout APIs.<br>
<br>
4. Find out other possible improvements to the GUI functionality of vim, provide Mac OS X implementation for it.<br>
<br>
I've gain some experience on Carbon programming and the source code structure of vim when developing the patch described in http://wiki.macvim.org/wiki/VimPatches/ATSUI, so I'm confident to continue the current work and take it to a higher level.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improve regexp performance</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ian Young</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Russell Cox</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 As mentioned on the ideas page, Vim would benefit greatly from using a faster algorithm to match regular expressions.  This project will implement an engine that uses the &quot;Thompson NFA&quot; algorithm, either writing one from scratch or using the TRE engine (found at &lt;http://laurikari.net/tre/index.html&gt;).  Project goals are seamless integration of the new engine into Vim, including a mechanism for reverting to the old algorithm for tricky cases like backreferences, and  a testing suite to verify correctness.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Vim bug fixing</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Martin Toft</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Abraham Moolenaar</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The many features of Vim makes it a really great editor, however, as the list of features grow, it is important to keep all of them working flawlessly. Users trust Vim when editing even their most important files and must be spared as many unpleasant surprises as possible. I have chosen 14 known bugs to focus on and categorized them into &quot;General Bugs&quot;, &quot;Syntax Highlighting Bugs&quot;, &quot;Completion Bugs&quot;, and &quot;Documentation Bugs&quot;. The general bugs that I wish to fix are:<br>
<br>
- When setting 'keymap' twice the b:keymap_name variable isn't set. (Milan Berta, 2007 Mar 9) Has something to do with 'iminsert'.<br>
- &quot;:lockvar&quot; should use copyID to avoid endless loop.<br>
- More-prompt is skipped when doing this; (Randall W. Morris, Jun 17)<br>
&nbsp;&nbsp;&nbsp;&nbsp;:au<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;Space&gt;<br>
&nbsp;&nbsp;&nbsp;&nbsp;b<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;Space&gt;<br>
- &quot;:confirm w&quot; does give a prompt when 'readonly' is set, but not when the file permissions are read-only. Both can be overruled by &quot;:w!&quot; thus it would be logical to get a prompt for both. (Michael Schaap)<br>
- When 'bomb' is set or reset the file should be considered modified. (Tony Mechelynck) Handle like 'endofline'.<br>
- &quot;:py&quot; asks for an argument, &quot;:py asd&quot; then gives the error that &quot;:py&quot; isn't implemented. Should already happen for &quot;:py&quot;.<br>
- Allow more than 3 &quot;:match&quot; items.<br>
- When pattern for &quot;:sort&quot; is empty, use last search pattern. Allows trying out the pattern first. (Brian McKee)<br>
<br>
Syntax highlighting bugs:<br>
<br>
- C syntax: &quot;#define x {&quot; The macro should terminate at the end of the line, not continue in the next line. (Kelvin Lee, 2006 May 24)<br>
- C syntax: {} inside () causes following {} to be highlighted as error. (Michalis Giannakidis, 2006 Jun 1)<br>
<br>
Completion bugs:<br>
<br>
- C completion: doesn't work after aa[0]-&gt;, where aa is an array of structures. (W. de Hoog, 2006 Aug 12)<br>
- Completion menu: For a wrapping line, completing a long file name, only the start of the path is shown in the menu. Should move the menu to the right to show more text of the completions. Shorten the items that don't fit in the middle?<br>
<br>
Documentation bugs:<br>
<br>
- Write &quot;making vim work better&quot; for the docs (mostly pointers): *nice*<br>
&nbsp;&nbsp;&nbsp;&nbsp;- sourcing $VIMRUNTIME/vimrc_example.vim<br>
&nbsp;&nbsp;&nbsp;&nbsp;- setting 'mouse' to &quot;a&quot;<br>
&nbsp;&nbsp;&nbsp;&nbsp;- getting colors in xterm<br>
&nbsp;&nbsp;&nbsp;&nbsp;- compiling Vim with X11, GUI, etc.<br>
- There should be something about spell checking in the user manual.<br>
<br>
Some of the bug descriptions are vague and will need to be discussed with developers and bug reporters.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Vim: Regexp Improvement</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Xiaozhou Liu</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Russell Cox</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 =========<br>
SYNOPSIS<br>
=========<br>
I will improve Vim's regexp performance by using another regexp engine. The new engine will improve pattern searches and syntax highlighting in particular, while maintaining compatibility with the existing regexp engine.<br>
<br>
<br>
========<br>
PROJECT<br>
========<br>
My effort will focus on making a new, high-performance regexp engine, and making ensure that it is 100% compatible with the existing one.<br>
<br>
Instead of coming out on-the-fly, the new engine will get inspiration from other existing regexp libraries. Good candidates include GNU's grep, TRE etc.<br>
<br>
The matching process will also be hybridized with a separate algorithm for exact string matching, eliminating impossible text from being considered by the full regexp engine, which makes it even faster.<br>
<br>
The success criteria is:<br>
- First of all, the behavior of the new regexp engine must be correct.<br>
- The new regexp engine really beats the existing one in performance.<br>
- 100% compatibility with the existing one.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Vim Eclipse Plugin</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>David Anthony Terei</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Abraham Moolenaar</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will combine the power of vim with eclipse by allowing vim to be used as a plugin for eclipse which replaces the eclipse editor. This will include allowing vim to be used from within eclipse itself and also integrating the two together so that eclipse features such as code assist can still be used from within the vim plugin.<br>

	</div>
 </td>
 </tr>
</table>
<a name='wikimedia' />
<h2> wikimedia </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Comprehensive Automated Multimedia Recoding for Wikimedia</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Michael S. Baynton</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brion Vibber</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Audio and video can instruct and inform in ways unattainable by words and still images. Currently, audio and video have only limited support and are often cumbersome to access in MediaWiki and the various projects of the Wikimedia Foundation. This project seeks to allow Wikimedia's sites to more effectively leverage the power of audio and video resources. To achieve this, a reliable and expandable system is proposed to automatically recode contributions from numerous digital a/v formats to a single, royalty and patent free compression standard. With the ability to generate such a library, Wikimedia would be poised to easily present a vast range of audio and video to their visitors using an in-browser streaming player.<br>
<br>
Now track my progress and read the full proposal at my blog, http://mikeswikidev.wordpress.com/<br>

	</div>
 </td>
 </tr>
</table>
<a name='wine' />
<h2> wine </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Improve sound in wine</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Maarten Lankhorst</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Marcus Meissner</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In linux, the most used sound backend for wine is OSS, this is years obsoleted and doesn't work well with modern linux systems. This is one of the weak sides of wine, and I want to propose to improve the ALSA sound backend to be as good a backend as OSS, or if possible an even better backend.<br>
<br>
This requires changes in the DirectSound emulation code, and in the winealsa driver. I have played around with it before, but as far as I can tell a lot of things need to be changed in the dsound and winealsa code:<br>
<br>
* DirectSound doesn't have proper support for secondary buffers at driver level<br>
&nbsp;&nbsp;None of the wine drivers needed it before, but the directsound software mixer works horrible, I'll try to get that working as well as fallback, but the mixing should really be done in alsa code if possible.<br>
<br>
* Locking and Unlocking buffers in directsound doesn't forward to secondary buffers when needed<br>
&nbsp;&nbsp;This is very important for secondary buffers in alsa, as I want to use it for making sound run properly, hopefully it will work.<br>
<br>
* Limitation of alsa: buffer size cannot be arbitrarily big, a workaround is needed, most likely buffer emulation in winealsa<br>
&nbsp;&nbsp;This is tricky, as it means writing from 1 bigger buffer into a smaller buffer, since we can assume that in those cases the buffer is big enough that a buffer underflow doesn't happen, it means that we can run a timer that fills the buffer.<br>
<br>
* Winealsa currently doesn't have support for AUX and mixer controls<br>
&nbsp;&nbsp;This is needed to manipulate the mixer the same way as it's manipulated under windows and wine, I don't think it's hard to accomplish but it's worth it for applications that play around with volume controls.<br>
<br>
* Remove the seperate thread used in winealsa, rework the code so it's not needed any more<br>
&nbsp;&nbsp;The current thread only causes stuttering of audio, it's better to remove it entirely by using alsa lock and unlock calls, which notify that there is some sound that can be played. Alsa then takes care of the playing etc so we wouldn't have to handle it.<br>
<br>
* Implement dscapture for winealsa<br>
&nbsp;&nbsp;Sound capture code in alsa currently only exists for wave in, and not for directsound, this means that applications that use dscapture use a lot of cpu to get it working, applications like counter strike source take a deep performance hit from it.<br>
<br>
* (Most importantly) Make ALSA run so well, people wouldn't want to use OSS driver any more.<br>
&nbsp;&nbsp;No explanation needed. If this is true, ALSA can become the standard driver in wine (instead of OSS)<br>
<br>
===<br>
Why?<br>
The direct3d code in wine is getting better and better each release, games work better and better, but for sound in those games people still use OSS or a badly working ALSA driver, I want to game on my linux system and not have to close all other applications to get proper sound, since OSS wants to have exclusive access to sound.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>The DIB Engine</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Jessie Laine Allen</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Huw D M Davies</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 To move software GDI graphic operations from X Windows to Wine. Also called the DIB engine.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Tablet PC support in Wine</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Carl John Klehm</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Richard Kegel</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My would be project is to implement Tablet PC support in WINE.  This will entail implementing at the very minimum InkObj.dll (the libraries a tablet aware application uses) and wisptis.exe, a program that passes off the raw input received from a digitizer (tablet like device).  At the very very best enough infrastructure would get implemented in order to allow Microsoft OneNote to run. Finally a more realistic outcome would be for a respectable Ink application like xThink Calculator to be up and running.<br>
<br>
The master plan:<br>
<br>
1)InkObj.dll provides the basic classes and methods that an application can use to handle the events generated from a digitizer.  This infrastructure would be where I would start.  Having these libraries implemented will be vital to exposing the guts of the Tablet PC subsystem.<br>
<br>
2)The system to implement next would be wisptis.exe. (Windows Ink Services for Pen Tablet Input Subsystem .exe)  This application manages the signaling received from the digitizer and passes events off to user32.dll and InkObj.dll.  This will allow wine to recognize a digitizer in exactly the same manner as Windows would (HID implementation differences notwithstanding)<br>
<br>
3)Having implemented the above 2 objects it should now be possible to run the basic sample applications from the Tablet PC SDK on Wine.  This milestone would show that the minimum plumbing for Tablet PCs is in place.<br>
<br>
4)Analyze which additional APIs should be implemented based on usage by the SDK sample apps and xThink Calculator.<br>
<br>
5)Push hard to get xThink Calculator working.  This milestone would prove that a respectable amount of applications should be supported. This stage is my best guess at what time will allow me to accomplish this summer.<br>
<br>
6)Next would be to implement the low level API of IRealTimeStylus and friends from RTSCom.dll as it is sure to be used in fun creative ways that will provide exciting opportunities for bug fixing. Parts of this dll may need to be implemented sooner in the process as xThinkCalc and the sample apps may use it.<br>
<br>
7)Fix any remaining problems with the SDK sample applications.<br>
<br>
8)Finally implement Ink helper libraries IACom.dll,  InkDiv.dll, InkEd.dll, and PIPanel.dll.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Improve WIne&#39;s built-in text editors</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Alexander Nicolaysen Sørnes</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Eric Pouech</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Wine is an open source implementation of the Windows API, and it currently contains two of the standard Windows text editoers, Notepad and WordPad, both of which are C applications.<br>
<br>
Improving these programs, where the main area of work will be on WordPad, is a great way to learn about and be comfortable with the Windows API, but it also has benefits to the project: the programs are used by many Windows applications, and WordPad can, if improved sufficiently, be used as a testcase for Wine's RichEdit implementation.<br>
<br>
Patches will be submitted to the wine-patches mailing list, available at<br>
http://www.winehq.org/pipermail/wine-patches/<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Windows Printing subsystem bridge (i.e. use WIN32 drivers to print from wine)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Marcel Philipp Partap</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Detlef Riekenberg</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 While many many printers are supported on *N*X through the excellent CUPS drivers suite, a few are not. Unfortunately those include my thermal serial printer, which only comes with a Windows driver in various tastes. Now as WINE's printing system mainly receives printed documents from the application, makes PS of it and hands it to the locally available *N*X printing system, the only thing that's really missing is the print spooler, monitor, proccessing chain... Did I say only? There sure is a lot of work to be done but in any case, it'd might also help the folks from ReactOS. So the milestones to having support for WIN32 printer drivers in WINE look something like this:<br>
M0: coming up with a clean concept how to do things the right way<br>
M1: rudimentally implement the most basic DRV/spooler communication<br>
M2: make it print a first graphic on my printer<br>
M3: improve compability/usability, testing...<br>

	</div>
 </td>
 </tr>
</table>
<a name='winlibre' />
<h2> winlibre </h2>
<table>
 <tr>
 <th>Title</th>
 <td>A Windows-Based Application Packaging System</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Edward Ropple</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Pierre-Jean Coudert</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 One major factor that is keeping open-source adoption back is a lack of a seamless, painless install process on the market-dominating Windows operating system. To facilitate open-source adoption, a standardized system of application and library packaging is necessary.<br>
<br>
This proposal provides a possible solution to this obstacle.<br>
<br>
<br>
http://blacken.superbusnet.com/gsoc/2007_wpm.html<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>OpenTouch – open source framework for multi-modal input devices</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Paweł Sołyga</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>CACHET Bertrand</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 OpenTouch is a solution for multi-modal application development. The goal of this software project is to create an open source framework that will be able to handle and process input from multi-modal devices such as multitouch screens based on FTIR. It should allow for gestural, multiple point interfaces, and a non-programming approach to gesture prototyping.<br>
<br>
The OpenTouch platform aims to be a layer between the input device and the final GUI application. It's designed to be cross-platform with support for internal and external applications as simple application gateway, blob tracking, gesture recognition and much more. Using this kind of software and a multitouch screen we would open new chapters in human computer interaction.<br>

	</div>
 </td>
 </tr>
</table>
<a name='wordpress' />
<h2> wordpress </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Hierarchical Page (list) Management using jQuery</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bernardo de Pádua dos Santos</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Michael D Adams</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Wordpress has a feature that allows users to write individual pages, in addition to the traditional blog entries. This feature brings Wordpress closer to the domain of CMS applications. In the latest version of Wordpress, 2.1, users have to go through an extenuating process to change the order that the pages are displayed. They have to open the edit form for each page to change its order number. This approach works for blogs with a small amount of pages, but becomes too frustrating for the ones with a larger amount, where the user would need to change a large number of page order numbers just to change the order of one page. A better way to order pages is an essential feature to make Wordpress a better CMS system and would have a direct impact in the productivity of content publishers.<br>
<br>
Using AJAX is probably the best approach to solve this problem. Users could be able to “drag and drop” pages in the page list in control panel, in order to change the order of a page. This would make changing the order of a page very intuitive and quick. There are, however, a large number of obstacles that need to be handled in order to implement such feature. For instance, as the number of pages in the list grows, pagination should occur, and it would make it harder for the user to change the order of a page, should he desire to place a page to appear before or after a page that is not being show in the current screen. Also, pages can be hierarchical in Wordpress, what makes it more difficult to handle both pagination and the drag and drop feature.<br>
<br>
The proposed project would be to implement such a “drag and drop” functionality for pages in Wordpress, using the jQuery javascript framework. This implementation would probably mean redesigning a great deal of the page list in the Wordpress control panel and implementing callback functions via AJAX (using jQuery).We would also investigate the need to implement a pagination mechanism to go along with it, and do it in the case the benefits would improve usability for users with a large number of pages, since it would also have its drawbacks. We could, for instance, implement a more “flexible” pagination, which would require list of page hierarchies to appear complete in its screen, what would reduce such problems.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Create Unit Test Framework for Editor Formatting</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Luc Bizeul</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lloyd Denis Budd</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The goal of this project is Test a Wysiwyg Java Script editor as a black box  (or as near to black as possible).<br>
<br>
After chose the apropriate way for test it and automatize it, I will focus on test scenario.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Comment Panel and Commenting System Additions</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Mike Grouchy</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Peter John Westwood</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 This project would entail a complete overhaul of WordPress' comments panel as well as a small portion of the WordPress comments system. The main purpose of the project is to put comments in context with the users blog. This would include relating individual comments to their posts within the comments panel as well as allowing users to respond to comments directly from the comments panel in a simple efficient manner. The goal is to make comments searchable/sortable on given parameters such as post title,date, author, etc. as well as threading comments to give them context within individual blog posts.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Easier template tags</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Keith Bowes</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Andy Skelton</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The templates offered in WordPress are very powerful because they allow you to use the full power of PHP together with the WordPress API to customize it as much as possible.  However, this system is not easy for people who aren't familiar with PHP.  In fact, many people continue to use MovableType or Blogger because those systems offer these easy HTML-like tags.  This project would implement the ability to use those tags.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>WordPress Update Plugin</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Dion Hulse</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robert Deaton</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose a Plugin/Theme update system for WordPress.<br>
I plan that it should:<br>
* Allow Notification of Plugin/Theme updates,<br>
* Allow searching of Open source repositories,<br>
* Allow single-Click install of Plugins/Themes,<br>
* Allow Plugins/Themes to be updated from within the Control panel,<br>
* Check Requirements for Plugins/Themes before installing<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Helping create a better content management structure for a popular online utility</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Corey A. Shaffer</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Brian C. Layman</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A content management system assists users in organizing and controlling their resources.  The main reason to use a CMS application is to improve the organization of content.  A quality CMS application can provide numerous benefits to an individual and/or company ranging from increased growth capacity to increased site flexibility.<br>
<br>
WordPress, an online blogging site, is looking to improve its CMS features in an attempt to offer its users a more efficient way to organize and manage their content.  Improvements made to the CMS features of WordPress would help create a much better content control structure for the popular site.<br>
&nbsp;&nbsp;<br>
An analysis of three of the top CMS applications will be done to search for CMS features currently not supported by WordPress.  A thorough analysis that will show how and why CMS is so effective for these sites and why their features can benefit WordPress will be completed and documented.  The features documented will then be evaluated, designed and implemented into the popular blogging site.  Depending on the results of the analysis of top CMS applications, several features could be added that would ultimately make working with WordPress an easy and stress-free experience<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>WordPress Market and Suitability Research and Prototyping</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Celeste Lyn Paul</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Matt Mullenweg</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 WordPress is an incredibly powerful and popular Content Management System used to help people manage their own websites and blogs around the world. In order to continue to be the best CMS out there, they have expressed a need for product research of incredible depth.  In order to know if they are meeting market and user needs, the first step would be a comparative analysis to evaluate WordPress with its peers.  This comparative analysis would lead to a better understanding of missing features or functionalities which WordPress could and should provide its users. Finally,  prototypes of these missing functions will be coded which can then be integrated in to WordPress during the next development cycle.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Internationalization revisited</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Matthias Bauer</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Nikolay Bachiyski</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I am interested in working on the 'Internationalization revisited' ideas suggested on the WordPress wiki &lt;URL:http://codex.wordpress.org/GSoC2007#Internationalization_revisited&gt;. My experience with localization/internationalization and gettext includes localizing various projects (such as the SourceForge.net website, among others) as well as implementing localization functionality for others. I fixed plural forms handling in php-gettext (and thus, WordPress) and wrote a number of test cases for Habari's implementation of a gettext parser/handler.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Adding Podcasting Support</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ronald Heft</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Lloyd Denis Budd</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Most podcasters maintain blogs notifying their subscribers of new episodes. Unfortunately, WordPress only supports the basic enclosure. In the current state, podcasting has evolved beyond the enclosure, using proprietary feed information from iTunes. Many podcasters also maintain multiple formats of their podcast, each requiring their own feed.<br>
<br>
My idea involves enhancing WordPress' support of podcasts. To best aid podcasters WordPress would need support for multiple formats and podcasts, support for custom podcast feeds, and inclusion of iTunes information. With the rise of video podcasts, WordPress should not forget them either. My idea would include adding support for video podcasts as well.<br>
<br>
All of these inclusions would be managed easily and efficiently in the WordPress GUI. Podcasting should be as simple as blogging. Podcasters should not have to worry about the technical details of podcasting; they should be able to upload an episode and have WordPress handle the bulk of the work.<br>

	</div>
 </td>
 </tr>
</table>
<a name='wxpython' />
<h2> wxpython </h2>
<table>
 <tr>
 <th>Title</th>
 <td>GUI Unit Testing Framework</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Frank Tobia</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kevin Ollivier</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Testing frameworks are invaluable for software development. User Interface testing is overlooked all too often to the detriment of development projects. In the case of wxPython, whose functionality is GUI components, a proper suite of GUI testing is a must.<br>
<br>
This project will create a unit testing framework suited for the GUI nature of wxPython. The framework will be easy to write new tests for and extend, and contain an initial set of unit tests.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Refactoring XRCed to use extendible plug-in architecture</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Roman Rolinsky</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robin Dunn</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 XRCed is a visual editor for XML files conforming to the XRC resource<br>
format. XRC files are used by wxWidgets C++ framework and wxPython<br>
Python GUI toolkit for storing user interface elements (dialogs, menu<br>
bars, toolbars, etc.). XRC resources can be loaded by an application<br>
at run-time in text or binary format, or embedded into a source file.<br>
<br>
XRCed at present supports all core interface elements implemented in<br>
wxWidgets, and requires updating its source to include support for new<br>
elements or properties added recently. This is not difficult, but<br>
requires the knowledge of some XRCed's internal data structures. In<br>
particular, this will be very useful for wxPython developers using<br>
interface elements implemented in Python modules which do not have<br>
corresponding C++ implementation and thus not supported by wxWidgets<br>
XRC library programmed in C++.<br>
<br>
The main goal of this project is to provide an easy-to-use extendible<br>
plug-in architecture for implementing custom interface elements as<br>
loadable from an XRC resource file. This feature can be used by<br>
developers contributing to wxPython project to provide a &quot;native&quot; XRC<br>
support for wxPython library modules. XRCed is shipped with wxPython,<br>
so the developers will have new plug-ins available immediately after<br>
upgrading to a new version of wxPython. In addition, more experienced<br>
developers will be able to create plug-ins for their own widgets,<br>
providing a uniform way to set the interface element properties and<br>
eliminating the need to use special &quot;placeholder&quot; elements in the<br>
resource file.<br>
<br>
Related to this goal is the problem of embedding XRCed into IDE<br>
projects such as SPE IDE (Stani's Python Editor). This requires<br>
refactoring and providing an API for using XRCed as a library (or a<br>
plug-in).<br>

	</div>
 </td>
 </tr>
</table>
<a name='wxwidgets' />
<h2> wxwidgets </h2>
<table>
 <tr>
 <th>Title</th>
 <td>XTI Metadata Completion</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Francesco Montorsi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Stefan Csomor</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 XTI was planned as the successor to wxWidgets run-time type information and also XRC as a way of describing controls to allow ‘discovery’ of their properties and events, and eliminate the need to write an XRC handler for each control. It could allow a binary custom control facility to be added to wxWidgets that would promote more of an ‘ecosystem’ around third-party components. GUI design tools could load and manipulate new controls without prior knowledge of them. XTI was funded by Borland and is partially implemented within wxWidgets. The tasks for this project include re-evaluating the design, implementing at least a representative sample of class descriptions, making sure it compiles on a good range of compilers, implementing loading of XTI GUI layouts, and demonstrating dynamic loading of binary custom controls into wxWidgets applications.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Complete wxDataViewCtrl</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bo Yang</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Robert Roebling</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 wxDataViewCtrl is a new wxWidgets class for displaying data in tabular or tree form, or a combination of the two. Ultimately it is intended to be easier to use and more powerful than the existing wxTreeCtrl and wxListCtrl classes. Right now, the class has an initial GTK+-specific implementation and the beginning of a generic implementation that could be used on other platforms. If this class can be finished, it will be a substantial contribution to wxWidgets and its users as well as a satisfying challenge in UI class design and implementation.<br>
&nbsp;The main tasks of this project includes implementing wxDataViewModel and wxDataViewTreeModel classes, implementing a generic version of wxDataViewCtrl and implementing support for wxTreeCtrl features in wxDataViewCtrl API.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>wxWidgets Web Port</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>John Wilmes</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Julian Smart</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I will port wxWidgets to the web platform.  When compiled against my code, a normal wxWidgets application that uses only widgets from the minimal or controls samples will run as a web application, with the original compiled code running on the server, and generated client-side code running in a web browser.  This project will include mapping widgets to HTML, distributing the wxWidgets event model between the browser and the web server, translating wxWidgets sizers into CSS layouts, and writing code for process management so that the same application can server multiple clients.  My code will largely consist of a wrapper around the Wt C++ Web Toolkit.<br>

	</div>
 </td>
 </tr>
</table>
<a name='xmms2' />
<h2> xmms2 </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Kick Ass Visualization using SHM/UDP</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Johannes Jordan</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Tobias Rundström</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Visualization is clearly among the features XMMS2 as a decent music<br>
multiplexing system still lacks. But XMMS2 needs it to leave competition in the<br>
dust. As also being part of the project's longterm wishlist[1], my task is to<br>
port existing visualization code to the transforms API[2] and extend it to<br>
provide PCM data; utilizing wavelet transformation is considerable as well.<br>
<br>
Data is to be transmitted to clients using shared memory, or UDP as fallback<br>
for networked clients (or on platforms where POSIX SHM is not available).<br>
To test the new framework, the XMMS Rootvis plugin[3] is to be ported, and<br>
to get access to a broader range of existing visualization plugins, a<br>
libvisual[4] client is to be implemented.<br>
<br>
________________________________<br>
&nbsp;&nbsp;&nbsp;[1] http://wiki.xmms2.xmms.se/index.php/Help_Wanted<br>
&nbsp;&nbsp;&nbsp;[2] http://wiki.xmms2.xmms.se/index.php/Transforms<br>
&nbsp;&nbsp;&nbsp;[3] http://freshmeat.net/projects/xmms-rootvis/<br>
&nbsp;&nbsp;&nbsp;[4] http://www.sf.net/projects/libvisual<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>XMMS2 IPC Autogeneration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Thomas Coppi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Anders Waldenborg</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 My project proposal is autogeneration of IPC code for XMMS2, using the<br>
description on http://wiki.xmms2.xmms.se/index.php/Summer_of_Code_2007/Proposed_projects as a starting point.<br>
<br>
The project will be split into two parts, generating the server code and the client code.<br>
<br>
A high-level description of this functionality would be created and used to generate the code for this. The client side currently consists of an xmmsclient library that provides a high-level C interface to the XMMS IPC protocol, and is used as a 'glue layer' by the higher-level language bindings, such as perl and python. The work on this side would consist of defining a high-level description of the interface provided by xmmsc, generalizing it a bit, and then generating the C binding from this. The server-side consists of generating code that can serialize/deserialize commands and arguments from the client side and properly dispatch them to the correct code inside the server.<br>
<br>
I will then need to test the C binding extensively for problems as the rest of the bindings depend on its correctness. The language I will be using for generating the code is Python.<br>
<br>
Tentative Schedule<br>
------------------<br>
April 11 - May 27: Integrate with the XMMS2 community, flush out remaining details of planned implementation, become more familiar with the development tools/practices used by XMMS2 (git, waf).<br>
May 28 - June 4:Create the high-level description of the IPC server side.<br>
June 5 - 21:Code the python program to generate the server-side code.<br>
June 22 - 29:Test the generated code against existing bindings for correctness,regressions, etc.<br>
June 30 - July 6:Create the high-level description of the IPC client side.<br>
July 7 - 25:Code the python program to generate the client-side code<br>
(C binding first)<br>
July 26 - August 3:Test the xmmsc binding<br>
August 4 - 20:Generate and test remaining bindings.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implementing Service Clients</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ning Shi</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sébastien Cevey</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Service client idea empowers XMMS2 with unlimited expendibility.  Different service clients can register themselves to the server so that when normal clients want to tag a music file for example, the service client will know what to do.  Or normal clients want to look up some data from MusicBrainz.org, service client can perform the search and return the results to the normal clients.  In this way, normal clients can share additional features provided by different service clients without having to implement them in every normal client over and over again.<br>

	</div>
 </td>
 </tr>
</table>
<a name='xmpp' />
<h2> xmpp </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Implementing &#39;Personal Eventing&#39; in the Openfire Jabber server</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Armando Diaz-Jagucki</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Gaston Dombiak</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Personal Eventing via Pubsub (PEP) [1] is a recent addition to the Extensible Messaging and Presence Protocol (XMPP), the core protocol of the Jabber Instant Messaging network. Personal Eventing allows for a user's Jabber ID to act as a virtual publish-subscribe (Pubsub) service [2] enabling the user to publish notifications of event changes relating to their personal state. Subscribers to a user's PEP service can then be notified of information such as User Mood [3] (how the user is feeling), User Tune [4] (music the user is listening to), or User Geolocation [5] (current geographical location of a user). This project's primary goal is to implement PEP in Openfire [6], a Jabber server written in Java.<br>
<br>
<br>
<br>
_____________________________________________________<br>
&nbsp;&nbsp;&nbsp;[1] http://www.xmpp.org/extensions/xep-0163.html<br>
&nbsp;&nbsp;&nbsp;[2] http://www.xmpp.org/extensions/xep-0060.html<br>
&nbsp;&nbsp;&nbsp;[3] http://www.xmpp.org/extensions/xep-0107.html<br>
&nbsp;&nbsp;&nbsp;[4] http://www.xmpp.org/extensions/xep-0118.html<br>
&nbsp;&nbsp;&nbsp;[5] http://www.xmpp.org/extensions/xep-0080.html<br>
&nbsp;&nbsp;&nbsp;[6] http://www.igniterealtime.org/projects/openfire/index.jsp<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implement XEP-33 Extended Stanza Addressing and other XEPs on ejabberd</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Bernardo Antonio de la Ossa Pérez</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Mickaël Rémond</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose to implement 'XEP-0033 Extended Stanza Addressing' as a component on ejabberd. This protocol aims to reduce traffic between Jabber servers when both of them support the protocol, and the clients send broadcast messages. ejabberd's MUC and PubSub components will be updated to use this protocol.<br>
<br>
This protocol is already used on several Jabber servers and clients. Implementing it on ejabberd is an important step on the adoption process.<br>
<br>
To allow me to get some experience on XEP-reading and implementation, I also propose to implement (or update) three smaller protocols on ejabberd, namely:<br>
XEP-0133: Service Administration<br>
XEP-0157: Contact Addresses for XMPP Services<br>
XEP-0203: Delayed Delivery<br>
<br>
With this project, ejabberd will provide more features and the existing features will be better protocol-compliant. Jabber as a whole will benefit with ejabberd support of extended stanza addressing. And finally, I'll get valuable experience on protocol implementation and knowledge on XMPP internals.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Encrypted Sessions Test Suite and Implementation</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Brendan Taylor</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Le Boulanger Yann</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 While much of the XMPP network's traffic is encrypted using SSL, a plaintext message can still be intercepted at a server or on a non-SSL connection. This makes XMPP unsuitable for sensitive (eg. financial) applications.<br>
<br>
XEP 116 (Encrypted Session Negotiation) and XEP 200 (Stanza Encryption) are protocol extensions which define a method of end-to-end encryption suitable for XMPP.<br>
<br>
I will develop a set of tools for testing XEP 116 and 200 implementations and use it to implement end-to-end encryption in the Gajim XMPP client.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Data Form Designer Suite for XMPP</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Tobias Markmann</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Kevin Smith</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The XMPP Standards Foundation provides official extensions to the XMPP protocol. Two of them Data Forms (XEP-0004) and Ad-Hoc Commands (XEP-0050) are used to provide forms to users in a XMPP network which send back the filled forms.<br>
<br>
This project is a suite for creating forms using a graphical user interface and provide those forms to other users in a standard compliant way. Any user, who may want to start a poll or survey, can create his own form within minutes and provide it to hundreds of users who won't need any special software, just a XMPP client which supports XEP-0050 and XEP-0004, to display, fill out and send back the form.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Jingle Audio/Video for Gajim</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Tomasz Melcer</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Le Boulanger Yann</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 One of major features that Gajim lacks to be competitive with IM clients currently used is making voice and video calls. Voice is a natural way of communicating for people, and video transmission makes chatting more attractive. The goal is to provide means to allow these kinds of interaction in Gajim by implementing Jingle Audio and (if time will allow) Jingle Video.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Implement Bidirectional-streams Over Synchronous HTTP (BOSH) support in gloox</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Matthew James Wild</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Jakob Schröter</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 gloox is a cross-platform, high-level XMPP library written in C++.<br>
<br>
The aim of my project is to implement a standard protocol for XMPP over  Bidirectional-streams Over Synchronous HTTP (BOSH) in gloox.<br>
<br>
BOSH is a technique that allows clients to communicate with the server using HTTP requests/responses. This allows bi-directional communications with the server from behind firewalls, proxies, or anywhere that a persistent TCP connection is not possible and/or feasible.<br>

	</div>
 </td>
 </tr>
</table>
<a name='xorg' />
<h2> xorg </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Generating the XCB c-code in Python</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Thomas Hunger</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Anselm R. Garbe</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 I propose a rewrite of the c-code generator for the XCB library [1] in Python. I hope that using Python instead of XSLT makes it simpler for others to get started with XCB development. In addition to the rewrite I want to use the gained experience for a prototype generator which generates the server side protocol stubs.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Moving the mouse handling code into a separate thread</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Tiago Vignatti</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Daniel Stone</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 A properly multi-threaded X Server implementation could respond to high-priority user events without being blocked on drawing operations or even low-priority I/O events. The proposed project intends to move the mouse handling code of X Server into a separate thread.<br>

	</div>
 </td>
 </tr>
</table>
<a name='xwiki' />
<h2> xwiki </h2>
<table>
 <tr>
 <th>Title</th>
 <td>XWiki Storage Improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Artem Melentyev</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sergiu Gabriel Dumitriu</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 There are various improvements needed for the way XWiki stores it's data:<br>
&nbsp;&nbsp;&nbsp;* recycle bin mechanism. jira tasks XWIKI-543, XWIKI-850<br>
&nbsp;&nbsp;&nbsp;* version control:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* add support for minor edit and edit comment fields. XWIKI-687<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* keep document history in a separate table.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* ability to alter the document history. XWIKI-962<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* pseudoversions. XWIKI-500<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* support JCR native version control in JcrStore.<br>
&nbsp;&nbsp;&nbsp;* query plugin:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* move query plugin to new JackRabbit 1.2.x engine with child axis support<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* supporting custom mapping in the query plugin<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* support join queries in the query plugin<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* revise xwiki security in query plugin (security is working only for hibernate, and very slow for now)<br>
&nbsp;&nbsp;&nbsp;* update JcrStore to support eXoJCR and JackRabbit 1.2.x, move to separate maven2 project.<br>
&nbsp;&nbsp;&nbsp;* store attachments in a WebDAV/JCR repository (separate from JCR Store)<br>
&nbsp;&nbsp;&nbsp;* increase the default size of some table fields<br>
&nbsp;&nbsp;&nbsp;* increase the maximum size of some properties<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Functional Test Suite</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Catalin Hritcu</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Vincent Massol</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Building a functional test suite covering the most important features of XWiki. The tests will be fully automated, and will use the Selenium XWiki application built for this purpose. Since the Selenium XWiki application is still experimental, additional work will be needed on enhancing the testing framework itself. Some parts of the XWiki user interface will also have to be enhanced to allow easier testing.<br>
<br>
http://www.xwiki.org/xwiki/bin/view/GoogleSummerOfCode/FunctionalTestSuite<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>New: AJAX Interface Improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Evelina Petronela Slatineanu</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Sergiu Gabriel Dumitriu</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The current skin was written with accessibility in mind, meaning that it works well without javascript.<br>
<br>
The next step is to add AJAX functionality on top of the existing code, minimizing the number of page reloads, adding new sliding effect to the interface elements, etc.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Collaborative tools on top of xwiki</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Boureanu Ioana Cristina</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>jérémi Joslin</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 In Wiki environments, there is a need for interactive communication. Thus, this grows to imply a realtime collaborative support. The aim of this project is to develop this support on top of XWiki and , at the same time, offer a demo application as XWiki plugin. This would be a collaborative svg whiteboard with full drawing functionality and a replay feature.<br>
<br>
It will be developed in Java as a XWiki plugin. It will contain the server side that must provide the realtime interaction feature and the client side that must extend the XWiki editor into a svg whiteboard. Together with the final whiteboard, a chat–enabled doodler shall be provided and the ability for a user to review (replay) the evolution of one drawing. The development shall make use of all needed APIs and features already included in the XWiki and maintain the character of CMS of the whole platform. (thus, the usage of JCR, Velocity macros and other XWiki embedded technologies is evident)<br>
<br>
The novelty in terms of XWiki is precisely the realtime collaborative feature and the fact that is provides interactive drawing. Being designed in such a way that it would easily be extended to other features (UML editing, board game playing, etc.), this project makes a big step towards a learning/educative tool or a software team helpful environment. Taking into account that a picture speaks out for one thousand words, this appears even more as a need for XWiki.<br>
<br>
To sum up, I see this as a must-have plugin for the XWiki community and I am most willing and motivated to develop it.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>IDE Editor Integration project</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>J.A.D.T. Jayasuriya</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Vincent Massol</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 People always thought of a method of sharing details Project Management, Collaborative Writing and Efficient Document Sharing and I found out XWIKI as a great choice for document sharing. Normally as software developers we mostly involve in team work. To become a good team all the members should carry the responsibilities and everybody should communicate efficiently. The communication will reduce the duplication of work and increase the efficiency of a team work and increase the responsiveness to changes.<br>
<br>
XWIKI can play a key role in communication and sharing documentation. XWIKI has capabilities of online presentations that will make the life of the user easy to understand there work.  Event calendar can have the schedules of the activity of the projects explaining milestones deliverables and deadlines. Adding RSS feeds will provides the recent changes to RSS readers.<br>
<br>
Most software developers hate to do documentation. Using XWIKI developer can document the work and publish it easily. More importantly if this can be done on your favorite IDE then that will ease this task more. Most of our developers prefer to work using Eclipse as it has quite a lot of plugins. So developing a plugin for Eclipse that can edit XWiki pages directly from the IDE will be a great choice for a developer to share the details progress of work done regarding the assigned task.<br>
<br>
The ultimate goal this plugin is to provide the following basic features as requested by the XWIKI.  By using the plugin the user will be able to edit, save, rename, delete, and add comments. I will also like to add the advanced features of grabbing a wiki site locally so that one can work offline. Since most of the JAVA developers uses Eclipse as there favorite IDE and if XWIKI and Eclipse can get tide with this plugin that will increase the usage of XWIKI also. The increasing number of users of XWIKI will strengthen the community around it and help to improve with new features.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Google Docs Integration</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Radu DANCIU</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Ludovic Dubost</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The objective of the project is integrating Google Docs into xWiki - making it possible to seamlessly view and edit spreadsheets using the Google Docs interface.<br>
&nbsp;<br>
&nbsp;This would very much contribute to the ease of use of pages, removing the need to download - edit - upload spreadsheets.<br>

	</div>
 </td>
 </tr>
</table>
<a name='zope' />
<h2> zope </h2>
<table>
 <tr>
 <th>Title</th>
 <td>Run Zope 3 using Python 2.5</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Nikhil N</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Baiju Muthukadan</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 The idea of this project is to run Zope3 on Python 2.5. There are extensive changes in many modules and the exception class hierarchy which are causing errors in the Zope code.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Application for SoC: Zope Grok improvements</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Ulrich Fouquet</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Philipp von Weitershausen</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 Grok is a new project that aims to make Zope 3 application development more agile and easier to get started with. There are many things that need improving with Grok.<br>
<br>
This project's aim is to...<br>
<br>
&nbsp;&nbsp;- implement an admin UI for Grok (which is less ambitious than the<br>
&nbsp;&nbsp;&nbsp;&nbsp;traditional Zope ZMI; it only allows application installation and<br>
&nbsp;&nbsp;&nbsp;&nbsp;inspection, not through the web application construction)<br>
<br>
&nbsp;&nbsp;- expand the Grok reference and tutorial.<br>
<br>
&nbsp;&nbsp;- integrate more existing Zope 3 components and extensions with<br>
&nbsp;&nbsp;&nbsp;&nbsp;Grok.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Zope3 Support for AJAX enhanced forms and widgets</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Paul Carduner</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Martijn Pieters</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 AJAX is one of the not so new buzzword people have been throwing around when talking about what their web application can do.  For a while now, I have wanted to be one of those people.  Unfortunately, Zope does not make it brain-dead simple to use javascript to enhance your web application - at least when it comes to the kind of asynchronous and sometimes complex data transmission you get when you work with AJAX style technologies.  I would like to add support for javascript enhanced forms to Zope, via formlib, widgets, and a json namespace for data transfer.<br>

	</div>
 </td>
 </tr>
 <tr>
 <th>Title</th>
 <td>Wandering Books in Grok (v.2)</td>
 </tr>
 <tr>
 <th>Student</th>
 <td>Luciano Ramalho</td>
 </tr>
 <tr>
 <th>Mentor</th>
 <td>Martijn Faassen</td>
 </tr>
 <tr>
 <th colspan=2>Abstract</th>
 </tr>
 <tr>
 <td colspan=2>
	<div class="app_text">
 PROJECT PROPOSAL<br>
<br>
To implement Wandering Books in Grok, helping extend and document Grok as we go along.<br>
<br>
Wandering Books is a web application to allow groups to turn their personal book collections into a circulating library. A prototype of Wandering Books was implemented in Horde/PHP during GSoC 2006 [1]<br>
<br>
[1] http://wanderingbooks.org/<br>
<br>
Specifically, the goal is to develop Wandering Books as an example of a non-trivial web application, benefiting Grok in several ways:<br>
- extracting features from a real world web app<br>
- providing use cases for new features or enhancements<br>
- highlighting limitations, misfeatures and problem areas<br>
- identifying voids in the documentation<br>
- providing a significant case study<br>
<br>
Contributing directly to the Grok codebase and it's documentation is an integral part of this proposal.<br>
<br>
WHY DO IT<br>
<br>
As a library sciences student, I designed Wandering Books to increase the reuse of books, foster the exchange of reading experiences, and make books more accessible to all, particularly in developing countries.<br>
<br>
As a web application developer, I've been using Wandering Books as a benchmark for evaluating agile web frameworks. In the past few months I've assembled a group of fellow developers and together we have prototyped parts of Wandering Books in Plone, Django and Ruby on Rails. Implementing Wandering Books in Grok at this time will provide the application with a solid and flexible foundation, and the framework with a valuable case study.<br>
<br>
WHY ME<br>
<br>
I fit squarely in the target user base for Grok. I am an experienced web developer who has used several languages and frameworks, but so far have not been motivated to use Zope 3 even though Python is my favorite language. Most of my current work revolves around Zope 2 and Plone. I see Zope 3 as a solid foundation, but would like to see that foundation supporting a more agile style of development. I'm excited about Grok and would like to see it succeed as the entry level framework for Zope 3. I am fluent in Python and OO programming, I've attended Zope 3 classes, but have no experience developing with it or Grok. However, I am willing to learn and my inexperience with Grok means I'll be sensitive to it's pitfalls and rough edges, allowing me to report and help fix those issues. I am addicted to unit testing. I've written many technical articles professionally (in English and Portuguese) and I am an instructor with very positive student evaluations, so I can write clear documentation.<br>

	</div>
 </td>
 </tr>
</body></table>
